# From User Request to LLM Response: Latency, Sequence Diagram: 

##

### Conversation Screenshot
![Application](../../../../_static/projects/genai_talk_to_characters/latency/conv_screenshot.png)


### Tracing: User Request to LLM Response
<img src="../../../../_static/projects/genai_talk_to_characters/latency/trace.svg" style="background-color: white;">


### Latency
<img src="../../../../_static/projects/genai_talk_to_characters/latency/latency.svg" style="background-color: white;">

![Latency](../../../../_static/projects/genai_talk_to_characters/latency/timing.png)


### Request Headers
![Headers](../../../../_static/projects/genai_talk_to_characters/latency/request_headers.png)


### Request Payload
![Payload](../../../../_static/projects/genai_talk_to_characters/latency/request_payload.png)


### LLM Conversation Memory
![LLM Memory](../../../../_static/projects/genai_talk_to_characters/latency/llm_memory.png)


### Response Streaming
![Streaming](../../../../_static/projects/genai_talk_to_characters/latency/response_streaming.png)