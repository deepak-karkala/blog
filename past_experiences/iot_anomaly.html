<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Energy Demand Forecasting in Time Series IoT Data" href="iot_forecasting.html" /><link rel="prev" title="Past Experiences" href="index.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><!-- Generated with Sphinx 7.1.2 and Furo 2024.05.06 -->
        <title>Anomaly Detection in Time Series IoT Data - Home</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/style.css?v=8a7ff5ee" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Home</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">Home</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Past Experiences</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Past Experiences</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Anomaly Detection in Time Series IoT Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="iot_forecasting.html">Energy Demand Forecasting in Time Series IoT Data</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="adas_engine/index.html">ADAS: Data Engine</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of ADAS: Data Engine</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch0_business_challenge.html">Business Challenge and Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch1_ml_problem_framing.html">ML Problem Framing</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch2_operational_strategy.html">Planning, Operational Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch3_pipelines_workflows.html">Workflows, Team, Roles</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch4_testing_strategy.html">Testing Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch6_data_ingestion_workflows.html">Data Ingestion Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch7_scene_understanding_data_mining.html">Scene Understanding &amp; Data Mining</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch8_model_training.html">Model Training &amp; Experimentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch9_packaging_promotion.html">Packaging, Evaluation &amp; Promotion Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch10_deployment_serving.html">Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch11_monitoring_continual_learning.html">Monitoring &amp; Continual Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch12_cost_lifecycle_compliance.html">Cost, Lifecycle, Compliance</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch13_reliability_capacity_maps.html">Reliability, Capacity, Maps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ecom_cltv.html">Customer Lifetime Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_propensity.html">Real-Time Purchase Intent Scoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_summarisation.html">Reviews Summarisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_rag.html">RAG-Based Product Discovery</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/index.html">Projects</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Projects</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/nlp/index.html">Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/airbnb_alternate_search/about/index.html">Airbnb Listing description based Semantic Search</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/cv/index.html">Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Computer Vision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/ecommerce_image_segmentation/about/index.html">Image Segmentation for Ecommerce Products</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/airbnb_price_modeling/about/index.html">Predictive Price Modeling for Airbnb listings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../publications/index.html">Patents, Papers, Thesis</a></li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../agents/index.html">AI Agents: A Lead Engineer’s Handbook</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of AI Agents: A Lead Engineer’s Handbook</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch1_intro.html">Agent Fundamentals: What, Why, and When?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch2_patterns.html">Agentic Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch5_context_engineering.html">Context Engineering for AI Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch6_case_studies.html">The State of the Industry: Insights from the Field</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch7_conclusion.html"><strong>Conclusion: The Lead Engineer’s Mental Model for Building Agents</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_cost.html">Cost Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_data.html">Data Management and Knowledge Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_deploy.html">Deployment and Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_guardrails.html">Guardrails</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_hitl.html">Human-in-the-Loop (HITL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_latency.html">Latency Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_llm.html">LLM – Prompts, Goals, and Persona</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_memory.html">Managing Agent Memory (Short-Term and Long-Term)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_monitor.html">Monitoring and Observability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_orchestration.html">Orchestration and Task Decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_prod.html">Production Challenges and Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_security.html">Securing AI Agents and Preventing Abuse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_tool.html">Tool Use and Integration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_trust.html">Building Trustworthy and Ethical AI Agents</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mlops/index.html">MLOps</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of MLOps</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch1_problem_framing.html">ML Problem framing</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of ML Problem framing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch2_blueprint_operational_strategy.html">The MLOps Blueprint &amp; Operational Strategy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch2a_platform/index.html">ML Platforms</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of ML Platforms</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/ml_platforms.html">ML Platforms: How to</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/uber.html">Uber Michelangelo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/linkedin.html">LinkedIn DARWIN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/netflix.html">Netflix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/shopify.html">Shopify Merlin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/zomato.html">Zomato: Real-time ML</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/coveo.html">Coveo: MLOPs at reasonable scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/monzo.html">Monzo ML Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/didact.html">Didact AI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch3_project_planning/index.html">Project Planning</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Project Planning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/prd.html">Project Requirements Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/tech_stack.html">Tech Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/config_management.html">Config Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/pipeline_design.html">Pipeline Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/environment_strategy.html">Environment Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/cicd_branching_model.html">CI/CD Strategy and Branching Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/directory_structure.html">Directory Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/env_branchind_cicd_deployment.html">Environments, Branching, CI/CD, and Deployments Explained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/project_management.html">Project Management for MLOps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch4_data_discovery/index.html">Data Sourcing, Discovery</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Data Sourcing, Discovery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/data_sourcing_discovery.html">Data Sourcing, Discovery &amp; Understanding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/ch4_project.html">Project-Trending Now: Implementing Web Scraping, Ingestion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/industry_case_studies.html">Data Discovery Platforms: Industry Case Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/facebook_nemo.html">Facebook: Nemo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/netflix_metacat.html">Netflix Metacat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/uber_databook.html">Uber Databook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/linkedin_datahub.html">LinkedIn Datahub</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch5_data_pipelines/index.html">Data Engineering, Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Data Engineering, Pipelines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/data_pipelines.html">Data Engineering for Reliable ML Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/data_engineering_pipelines.html">Data Engineering &amp; Pipelines: A Lead’s Compendium</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/streaming_pipelines.html">Real-Time &amp; Streaming Data Pipelines: Challenges, Solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/netflix_keystone.html">Netflix Keystone</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/doordash_riviera.html">Doordash Riviera</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch6_feature_engg/index.html">Feature Engineering, Feature Stores</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Feature Engineering, Feature Stores</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/feature_engineering_store.html">Feature Engineering and Feature Stores</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/feature_engineering.html">Feature Engineering for MLOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/explained_feature_stores.html">Feature Stores for MLOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/point_in_time.html">Point-in-Time Correctness &amp; Time Travel in ML Data Pipelines</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/index.html">Feast Feature Store</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Feast Feature Store</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_architecture.html">Feast Architecture: A Technical Deep Dive for MLOps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_concepts.html">Feast Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_components.html">Feast Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_usecases.html">Feast Use Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_aws.html">Running Feast with AWS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/run_in_prod.html">Running Feast in Production</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/validate_historical_with_gx.html">Validating Historical Features with Great Expectations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/add_reuse_tests.html">Adding or Reusing Tests in Feast</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch7_model_development/index.html">Model Development, Tuning, Selection, Ensembles, Calibration</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Model Development, Tuning, Selection, Ensembles, Calibration</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/ch7_model_development.html">Chapter 7: Model Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/dl_training_playbook.html">How to train DL Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/development.html">Model Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/industry_lessons.html">Model Development: Lessons from production systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/ensembles.html"><strong>Model Ensembles</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/selection.html">Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/tuning_hypopt.html">Hyperparameter Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/expt_tracking.html">ML Expt tracking, Data Lineage, Model Registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/calibration.html">Model Calibration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch8_ml_pipelines.html">ML Training Pipelines</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch9_ml_testing/index.html">Testing in ML Systems</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Testing in ML Systems</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/ch9_ml_testing.html">Testing in ML Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/data_testing_validation.html">Data Testing &amp; Validation in Production</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/ml_testing.html">Testing ML Systems: Ensuring Reliability from Code to Production</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch10_deployment_serving/index.html">Model Deployment &amp; Serving</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Model Deployment &amp; Serving</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/ch10_deployment_serving.html">Chapter 10: Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/guide_deployment_serving.html">Guide: Model Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/guide_inference_stack.html">Deep Dive: Inference Stack</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/index.html">Monitoring, Observability, Drift, Interpretability</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Monitoring, Observability, Drift, Interpretability</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/ch11_monitor_observe_drift.html">Chapter 11: Monitoring, Observability, Drifts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_monitor_observe_drift.html">Guide: ML System Failures, Data Distribution Shifts, Monitoring, and Observability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_interpretability_shap_lime.html">Interpretability, SHAP, LIME</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_stack.html">Prometheus + Grafana and ELK Stacks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/index.html">Continual learning, Retraining, A/B Testing</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Continual learning, Retraining, A/B Testing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/ch12_continual_learning_prod_testing.html">Chapter 12: Continual Learning &amp; Production Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_continual_learning.html">Continual Learning &amp; Model Retraining</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_ab_testing.html">A/B Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_ab_testing_industry_lessons.html">A/B Testing &amp; Experimentation: Industry lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_prod_testing_expt.html">Guide: Production Testing &amp; Experimentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/dr_prod_testing_expt.html">Deep Research: Production Testing &amp; Experimentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch13_governance_ethics_human.html">Governance, Ethics &amp; The Human Element</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pytorch/index.html">PyTorch</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of PyTorch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/general.html">General</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/state_dict.html">state_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/distributed_data_parallel.html">Distributed Data Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/ddp_under_the_hood.html">DDP: Under the Hood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/dp_ddp.html">DP vs DDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/fsdp.html">FSDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/tensor_parallelism.html">Tensor parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/pipeline_parallelism.html">Pipeline Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/device_mesh.html">Device Mesh</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lld/index.html">Low Level Design</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Low Level Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../lld/parking_lot.html">Parking Lot</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../visualization/index.html">Data Visualization Projects</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/past_experiences/iot_anomaly.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="anomaly-detection-in-time-series-iot-data">
<h1>Anomaly Detection in Time Series IoT Data<a class="headerlink" href="#anomaly-detection-in-time-series-iot-data" title="Permalink to this heading">¶</a></h1>
<!-- ## Anomaly Detection in Heating Energy Consumption using IoT Data for Predictive Maintenance -->
<section id="id1">
<h2><a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<hr class="docutils" />
<section id="tl-dr-predictive-maintenance-for-smart-heating-systems">
<h3>TL;DR: Predictive Maintenance for Smart Heating Systems<a class="headerlink" href="#tl-dr-predictive-maintenance-for-smart-heating-systems" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Challenge:</strong> A home automation company faced high operational costs and resident dissatisfaction due to reactive maintenance of apartment heating systems. Failures were only addressed after residents reported discomfort, leading to expensive emergency call-outs and a poor customer experience. The goal was to shift from this reactive model to a proactive, predictive maintenance strategy.</p></li>
<li><p><strong>My Role &amp; Solution:</strong> As the sole Data Scientist and MLOps Engineer, I designed and built the end-to-end Machine Learning system to proactively detect heating anomalies. My contributions spanned the entire ML lifecycle:</p>
<ul>
<li><p><strong>Strategic Approach:</strong> I developed a phased ML strategy, starting with unsupervised models (like Isolation Forest) to provide immediate value in the absence of labeled data, and establishing a human-in-the-loop feedback system with maintenance technicians. This data flywheel was crucial for collecting labels, which enabled the transition to a high-performing supervised XGBoost model.</p></li>
<li><p><strong>Feature Engineering:</strong> I designed and implemented robust data pipelines in AWS Glue to process raw IoT sensor data (heating energy, room/setpoint temperatures) and external weather data, creating crucial temporal features like lags and rolling averages that captured the system’s dynamic behavior.</p></li>
<li><p><strong>MLOps Infrastructure:</strong> Using Terraform and Bitbucket Pipelines, I built and automated the entire MLOps workflow on AWS. This included containerized model training (Docker/ECR), orchestrated by AWS Step Functions, and a serverless inference pipeline using SageMaker Batch Transform.</p></li>
<li><p><strong>Production Lifecycle Management:</strong> I implemented a complete model lifecycle using SageMaker Model Registry for versioning and governance, with automated integration tests to validate deployments. I also established a monitoring and retraining framework to address model drift and ensure long-term performance.</p></li>
</ul>
</li>
<li><p><strong>Impact:</strong> The deployed system successfully transitioned the company to a data-driven maintenance approach. Within the first six months of operation, the solution achieved:</p>
<ul>
<li><p><strong>A 20% reduction in emergency maintenance call-outs</strong> for heating systems, by identifying developing issues before they became critical failures.</p></li>
<li><p><strong>A 75% precision rate (Precision&#64;50)</strong> on the highest-priority alerts, ensuring that technician time was focused on investigating real, actionable issues.</p></li>
<li><p><strong>An estimated 15-20% improvement in operational efficiency</strong> for the maintenance team through better planning and prioritization of tasks.</p></li>
</ul>
</li>
<li><p><strong>System Architecture:</strong> I architected and implemented the entire AWS-based solution, focusing on serverless, scalable, and automated components.</p></li>
</ul>
<p><img alt="" src="_static/past_experiences/iot_anomaly/contributions.png" /></p>
</section>
<section id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h3>
<section id="purpose">
<h4>Purpose<a class="headerlink" href="#purpose" title="Permalink to this heading">¶</a></h4>
<p>This document provides detailed technical information about the Machine Learning (ML) based Anomaly Detection system. It serves as a guide for developers, MLOps engineers, and operations teams involved in maintaining, operating, and further developing the system.</p>
</section>
<section id="business-goal">
<h4>Business Goal<a class="headerlink" href="#business-goal" title="Permalink to this heading">¶</a></h4>
<p>The primary goal is to transition from reactive to predictive maintenance for apartment heating systems. By detecting anomalies indicative of potential malfunctions <em>before</em> they cause resident discomfort or system failure, the system aims to:</p>
<ul class="simple">
<li><p>Reduce operational costs associated with emergency maintenance.</p></li>
<li><p>Optimize maintenance scheduling and resource allocation.</p></li>
<li><p>Improve heating system reliability and uptime.</p></li>
<li><p>Enhance overall resident satisfaction.</p></li>
</ul>
</section>
<section id="key-technologies">
<h4>Key Technologies<a class="headerlink" href="#key-technologies" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Cloud Platform:</strong> AWS (Amazon Web Services)</p></li>
<li><p><strong>Data Lake:</strong> Amazon S3</p></li>
<li><p><strong>Data Processing/ETL:</strong> AWS Glue (PySpark), AWS Lambda (Python), SageMaker Processing Jobs (PySpark/Scikit-learn)</p></li>
<li><p><strong>Feature Management:</strong> Amazon SageMaker Feature Store (Offline Store)</p></li>
<li><p><strong>Model Training:</strong> Amazon SageMaker Training Jobs (using custom Docker containers)</p></li>
<li><p><strong>Model Inference:</strong> Amazon SageMaker Batch Transform</p></li>
<li><p><strong>Model Registry:</strong> Amazon SageMaker Model Registry</p></li>
<li><p><strong>Orchestration:</strong> AWS Step Functions</p></li>
<li><p><strong>Scheduling:</strong> Amazon EventBridge Scheduler</p></li>
<li><p><strong>Alert Storage:</strong> Amazon DynamoDB</p></li>
<li><p><strong>Infrastructure as Code:</strong> Terraform</p></li>
<li><p><strong>CI/CD:</strong> Bitbucket Pipelines</p></li>
<li><p><strong>Containerization:</strong> Docker</p></li>
<li><p><strong>Core Libraries:</strong> PySpark, Pandas, Scikit-learn, Boto3, Joblib, PyYAML</p></li>
</ul>
</section>
</section>
<section id="table-of-contents">
<h3>Table of Contents<a class="headerlink" href="#table-of-contents" title="Permalink to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#introduction"><span class="xref myst">Introduction</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#purpose"><span class="xref myst">Purpose</span></a></p></li>
<li><p><a class="reference internal" href="#business-goal"><span class="xref myst">Business Goal</span></a></p></li>
<li><p><a class="reference internal" href="#scope"><span class="xref myst">Scope</span></a></p></li>
<li><p><a class="reference internal" href="#key-technologies"><span class="xref myst">Key Technologies</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#discovery-and-scoping"><span class="xref myst">Discovery and Scoping</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#use-case-evaluation"><span class="xref myst">Use Case Evaluation</span></a></p></li>
<li><p><a class="reference internal" href="#product-strategies"><span class="xref myst">Product Strategies</span></a></p></li>
<li><p><a class="reference internal" href="#features"><span class="xref myst">Features</span></a></p></li>
<li><p><a class="reference internal" href="#product-requirements-document"><span class="xref myst">Product Requirements Document</span></a></p></li>
<li><p><a class="reference internal" href="#milestones-and-timelines"><span class="xref myst">Milestones and Timelines</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#system-architecture"><span class="xref myst">System Architecture</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#overall-data-flow"><span class="xref myst">Overall Data Flow</span></a></p></li>
<li><p><a class="reference internal" href="#training-workflow-diagram"><span class="xref myst">Training Workflow Diagram</span></a></p></li>
<li><p><a class="reference internal" href="#inference-workflow-diagram"><span class="xref myst">Inference Workflow Diagram</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#challenges-and-learnings"><span class="xref myst">Challenges and learnings</span></a></p></li>
<li><p><a class="reference internal" href="#configuration-management"><span class="xref myst">Configuration Management</span></a></p></li>
<li><p><a class="reference internal" href="#infrastructure-as-code-terraform"><span class="xref myst">Infrastructure as Code (Terraform)</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#stacks-overview"><span class="xref myst">Stacks Overview</span></a></p></li>
<li><p><a class="reference internal" href="#key-resources"><span class="xref myst">Key Resources</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#cost-analysis"><span class="xref myst">Cost Analysis</span></a></p></li>
<li><p><a class="reference internal" href="#cicd-pipeline-bitbucket"><span class="xref myst">CI/CD Pipeline (Bitbucket)</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#ci-workflow"><span class="xref myst">CI Workflow</span></a></p></li>
<li><p><a class="reference internal" href="#training-cd-workflow"><span class="xref myst">Training CD Workflow</span></a></p></li>
<li><p><a class="reference internal" href="#inference-cd-workflow"><span class="xref myst">Inference CD Workflow</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#deployment--execution"><span class="xref myst">Deployment &amp; Execution</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#prerequisites"><span class="xref myst">Prerequisites</span></a></p></li>
<li><p><a class="reference internal" href="#initial-deployment"><span class="xref myst">Initial Deployment</span></a></p></li>
<li><p><a class="reference internal" href="#running-training"><span class="xref myst">Running Training</span></a></p></li>
<li><p><a class="reference internal" href="#running-inference"><span class="xref myst">Running Inference</span></a></p></li>
<li><p><a class="reference internal" href="#model-approval"><span class="xref myst">Model Approval</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#monitoring--alerting"><span class="xref myst">Monitoring &amp; Alerting</span></a></p></li>
<li><p><a class="reference internal" href="#troubleshooting-guide"><span class="xref myst">Troubleshooting Guide</span></a></p></li>
<li><p><a class="reference internal" href="#security-considerations"><span class="xref myst">Security Considerations</span></a></p></li>
<li><p><a class="reference internal" href="#roadmap--future-enhancements"><span class="xref myst">Roadmap &amp; Future Enhancements</span></a></p></li>
<li><p><a class="reference internal" href="#appendices"><span class="xref myst">Appendices</span></a></p>
<ul class="simple">
<li><p><a class="reference internal" href="#configuration-file-example"><span class="xref myst">Configuration File Example</span></a></p></li>
</ul>
</li>
</ol>
</section>
<section id="discovery-and-scoping">
<h3>Discovery and Scoping<a class="headerlink" href="#discovery-and-scoping" title="Permalink to this heading">¶</a></h3>
<section id="use-case-evaluation">
<h4>Use Case Evaluation<a class="headerlink" href="#use-case-evaluation" title="Permalink to this heading">¶</a></h4>
<p><img alt="" src="_static/past_experiences/iot_anomaly/use_case.png" /></p>
</section>
<section id="product-strategies">
<h4>Product Strategies<a class="headerlink" href="#product-strategies" title="Permalink to this heading">¶</a></h4>
<p><img alt="" src="_static/past_experiences/iot_anomaly/strategy.png" /></p>
</section>
<section id="features">
<h4>Features<a class="headerlink" href="#features" title="Permalink to this heading">¶</a></h4>
<p><img alt="" src="_static/past_experiences/iot_anomaly/features.png" /></p>
</section>
<section id="product-requirements-document">
<h4>Product Requirements Document<a class="headerlink" href="#product-requirements-document" title="Permalink to this heading">¶</a></h4>
<p><img alt="" src="_static/past_experiences/iot_anomaly/prd.png" /></p>
</section>
<section id="development-stages">
<h4>Development Stages<a class="headerlink" href="#development-stages" title="Permalink to this heading">¶</a></h4>
<!--![](../_static/past_experiences/iot_anomaly/stages.png)-->
<p align="center">
    <img src="../_static/past_experiences/iot_anomaly/stages.png" width="75%"> 
</p>
</section>
</section>
<section id="system-architecture">
<h3>System Architecture<a class="headerlink" href="#system-architecture" title="Permalink to this heading">¶</a></h3>
<section id="overview">
<h4>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h4>
<p>The system follows a modular, event-driven, and batch-oriented architecture on AWS. It consists of distinct pipelines for data ingestion, model training, and daily inference. Orchestration relies heavily on AWS Step Functions, with SageMaker providing core ML capabilities.</p>
<!--![](../_static/past_experiences/iot_anomaly/pipelines.png)-->
<p align="center">
	<img src="../_static/past_experiences/iot_anomaly/arch.png" width="100%"> 
</p>
<!--
#### Data Characteristics

*   **Buildings:** 10 dozen = **120 buildings**.
*   **Apartments:** **3,000 apartments**.
*   **Sensors/Readings per Apartment:** ~8 (1 Energy, 1 Hot Water, 3 rooms * [1 Temp + 1 Setpoint]). Total sensors/readings ~24,000.
*   **Base Frequency:** Potential reading every 15 minutes.
*   **Storage Optimization:** Data is only recorded on change. We'll assume a **change rate of 10-20%** on average for sensor readings per interval, as temperatures, setpoints, and consumption are not constantly fluctuating dramatically. This is a crucial factor for volume estimation.
*   **Weather Data:** Fetched per building or per small geographical cluster of buildings.


| Data Type | Daily Volume (Average) | Data Velocity | Data Profile & Governance Notes |
| :--- | :--- | :--- | :--- |
| **IoT Sensor Data (Time Series)** | **150 - 300 MB per day.** <br>This is the highest volume data. Calculated from ~3,000 apartments with ~8 readings each, potentially every 15 mins. Volume is significantly reduced by only storing changed values (assuming 10-20% avg change rate per interval). Spikes in volume can occur during coordinated events (e.g., building-wide heating adjustments, morning rush hour). | **Near Real-Time Events, Processed in Batch.** <br>Individual sensor readings are generated continuously, collected by in-apartment tablets, and sent periodically to the central database. Data is ingested into the analytical platform via **daily or hourly batch jobs** (e.g., using AWS Glue). | **Semi-Structured (JSON/DB Rows).** <br>Each record contains `apartment_id`, `building_id`, `timestamp`, `sensor_type` (e.g., `heating_energy_kwh`, `room_temp_c`, `setpoint_temp_c`, `hot_water_litres`), and `value`. <br>**Governance:** Data is linked to a specific apartment/building, making it sensitive. While not direct PII, it reveals resident behavior patterns. Governed by **FADP/GDPR**. Anonymization or pseudonymization is required for non-operational analysis. Data quality monitoring for sensor drift/failure is critical. |
| **Aggregated Consumption Data** | **< 10 MB per day.** <br>This data is derived from the raw IoT sensor data. Volume is low as it contains one aggregated record per building per hour. | **Batch-Generated.** <br>Created by a **daily AWS Glue ETL job** that processes the previous day's IoT sensor data. Not a direct stream from a source. | **Highly Structured (Parquet).** <br>Consists of a table with a well-defined schema: `building_id`, `timestamp_hour`, `total_consumption_kwh`, `total_solar_kwh`, etc. <br>**Governance:** Aggregation provides a layer of privacy compared to raw sensor data. Serves as the primary source of truth for building-level forecasting. Data lineage from raw sensor data must be maintained. |
| **External Weather Data** | **< 5 MB per day.** <br>Data is fetched for ~120 building locations (or geographical clusters). Volume depends on API response format and fetch frequency (hourly for history, more frequently for forecasts). | **Scheduled API Polling (Batch).** <br>Historical data is fetched via a **daily AWS Lambda job**. Future forecast data is fetched via a **Lambda job running several times a day** to ensure freshness. | **Semi-Structured (JSON from API).** <br>Contains `location` (lat/lon or city), `timestamp`, and various weather metrics (`temperature_c`, `humidity`, `cloud_cover`, `solar_irradiance_ghi_forecast`, etc.). <br>**Governance:** Dependent on a third-party provider (e.g., MeteoSwiss). Requires monitoring for API availability, changes, and rate limits. Caching strategies may be needed to manage costs and dependencies. |
| **Building & Apartment Topology** | **< 1 MB per day (on average).** <br>This is very low volume, consisting primarily of updates when new buildings/apartments are commissioned or structural changes are made. | **Low / On-Change.** <br>Synchronized via **daily or triggered batch jobs** from the main operational database or commissioning system. | **Highly Structured.** <br>Contains `building_id`, `apartment_id`, and potentially metadata like `building_size_sqm`, `num_rooms`, `building_age`, `insulation_type`. <br>**Governance:** The source of truth for the physical hierarchy. Data consistency is critical for correct aggregation and for potentially creating building "archetypes" for transfer learning (cold starts). |
| **System & User Feedback** | **< 1 MB per day.** <br>Generated when maintenance technicians label an anomaly alert (True/False Positive) or when residents report issues. | **Low / Event-Driven.** <br>Captured via the internal maintenance dashboard or resident support application. Ingested via API calls or **event-driven Lambda functions**. | **Highly Structured & High Value.** <br>Contains `alert_id`, `technician_id`, `feedback_label` (`True Positive`, `False Positive`, `Root Cause`), `timestamp`. <br>**Governance:** The primary source of labeled data for model evaluation and future supervised retraining. The quality and consistency of this feedback are critical for the ML lifecycle. |

-->
</section>
<section id="data-flow">
<h4>Data Flow<a class="headerlink" href="#data-flow" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>Ingestion:</strong> Meter, Weather, and Topology data land in a raw S3 bucket via appropriate methods (batch, API fetch). A specific Lambda handles late-arriving meter data.</p></li>
<li><p><strong>Processing:</strong> A daily AWS Glue ETL job reads raw data, cleans it, performs transformations (e.g., daily aggregations, temp vs. setpoint diff), joins datasets, and engineers features required by the AD models. Processed features are stored in Parquet format in the Processed S3 zone. The Glue Data Catalog is updated.</p></li>
<li><p><strong>Model Training:</strong> A scheduled Step Functions workflow orchestrates training. It uses Glue to prepare a training dataset from the processed features, then triggers a SageMaker Training Job using the selected algorithms. The trained model is registered in the SageMaker Model Registry.</p></li>
<li><p><strong>Batch Inference:</strong> A daily Step Functions workflow prepares the latest features (Glue), then runs a SageMaker Batch Transform job using the latest registered model to score each apartment/room.</p></li>
<li><p><strong>Results Storage:</strong> Raw scores/flags are stored in S3. A subsequent Lambda/Glue job loads actionable <em>alerts</em> (where scores exceed thresholds) into a DynamoDB table or RDS instance for efficient dashboard querying.</p></li>
<li><p><strong>Serving:</strong> The internal dashboard queries the Alert Database via API Gateway/Lambda. Data Analysts can use Athena to query both processed features and raw data directly via the Glue Data Catalog.</p></li>
</ol>
</section>
<section id="ingestion-workflow">
<h4>Ingestion Workflow<a class="headerlink" href="#ingestion-workflow" title="Permalink to this heading">¶</a></h4>
<p>The Ingestion pipeline processes raw data into a structured, partitioned format (Parquet) in the S3 Processed Zone and updates the Glue Data Catalog.</p>
<ul class="simple">
<li><p><strong>Responsibility:</strong> Separate pipeline/process</p></li>
<li><p><strong>Output:</strong> Partitioned Parquet data with corresponding Glue Data Catalog tables.</p></li>
</ul>
<!--![](../_static/past_experiences/iot_anomaly/why_glue.png)-->
<p align="center">
	<img src="../_static/past_experiences/iot_anomaly/why_glue.png" width="80%"> 
</p>
</section>
<section id="training-workflow">
<h4>Training Workflow<a class="headerlink" href="#training-workflow" title="Permalink to this heading">¶</a></h4>
<p><strong>Summary:</strong> Triggered manually or by CI/CD/schedule -&gt; Validates Schema -&gt; Engineers Features (to Feature Store) -&gt; Trains Model (using custom container) -&gt; Evaluates Model -&gt; Conditionally Registers Model (Pending Approval).</p>
<ol class="arabic simple">
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">ValidateSchema</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Processing Job (Spark)</p></li>
<li><p><strong>Action:</strong> Reads sample/metadata from <code class="docutils literal notranslate"><span class="pre">processed_meter_data</span></code> for the input date range. Compares schema against predefined definition. Fails workflow on critical mismatch.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">FeatureEngineering</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Processing Job (Spark) / AWS Glue ETL Job</p></li>
<li><p><strong>Action:</strong> Reads <code class="docutils literal notranslate"><span class="pre">processed_meter_data</span></code> and <code class="docutils literal notranslate"><span class="pre">processed_weather_data</span></code> for input date range. Calculates features (aggregations, lags, rolling windows, joins). Ingests features into SageMaker Feature Store (<code class="docutils literal notranslate"><span class="pre">ad-apartment-features</span></code> group).</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">ModelTraining</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Training Job</p></li>
<li><p><strong>Action:</strong> Reads features for the training period from Feature Store Offline S3 location. Instantiates selected model strategy (e.g., <code class="docutils literal notranslate"><span class="pre">LR_LOF_Model</span></code>). Fits model components (Scaler, LR, LOF). Saves fitted artifacts as <code class="docutils literal notranslate"><span class="pre">model.joblib</span></code> within <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> to S3 output path.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">ModelEvaluation</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Processing Job (Python/Scikit-learn)</p></li>
<li><p><strong>Action:</strong> Loads <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> artifact. Reads evaluation features (hold-out set) from Feature Store Offline S3 location. Calculates performance metrics (e.g., backtesting precision/recall if labels available, score distributions). Estimates training throughput. Writes <code class="docutils literal notranslate"><span class="pre">evaluation_report.json</span></code> to S3.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">CheckEvaluation</span></code> (Choice)</p>
<ul class="simple">
<li><p><strong>Service:</strong> Step Functions Choice State</p></li>
<li><p><strong>Action:</strong> Compares key metrics from <code class="docutils literal notranslate"><span class="pre">evaluation_report.json</span></code> (requires parsing, possibly via an intermediate Lambda) against configured thresholds. Transitions to <code class="docutils literal notranslate"><span class="pre">RegisterModelLambda</span></code> or <code class="docutils literal notranslate"><span class="pre">EvaluationFailed</span></code>.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">RegisterModelLambda</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> AWS Lambda</p></li>
<li><p><strong>Action:</strong> Reads evaluation report URI and model artifact URI from state. Gathers metadata (git hash, params, metrics, data lineage). Creates a new Model Package version in the target SageMaker Model Package Group with status <code class="docutils literal notranslate"><span class="pre">PendingManualApproval</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Terminal States:</strong> <code class="docutils literal notranslate"><span class="pre">WorkflowSucceeded</span></code>, <code class="docutils literal notranslate"><span class="pre">EvaluationFailed</span></code>, <code class="docutils literal notranslate"><span class="pre">WorkflowFailed</span></code>.</p></li>
</ol>
</section>
<section id="inference-workflow">
<h4>Inference Workflow<a class="headerlink" href="#inference-workflow" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">GetApprovedModelPackage</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> AWS Lambda</p></li>
<li><p><strong>Action:</strong> Queries SageMaker Model Registry for the latest Model Package with <code class="docutils literal notranslate"><span class="pre">Approved</span></code> status in the configured group. Returns its ARN. Fails if none found.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">CreateModelResource</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> AWS Lambda</p></li>
<li><p><strong>Action:</strong> Creates a SageMaker <code class="docutils literal notranslate"><span class="pre">Model</span></code> resource using the approved Model Package ARN from the previous step and a unique name. This <code class="docutils literal notranslate"><span class="pre">Model</span></code> resource links the artifacts and container for Batch Transform. Returns the created <code class="docutils literal notranslate"><span class="pre">ModelName</span></code>.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">FeatureEngineeringInference</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Processing Job (Spark) / AWS Glue ETL Job</p></li>
<li><p><strong>Action:</strong> Reads processed data for the inference date + lookback period. Calculates features using the <em>exact same logic</em> as training feature engineering. Outputs features (e.g., CSV format without headers) required by the model to a unique S3 path for this execution.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">BatchTransform</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> SageMaker Batch Transform Job</p></li>
<li><p><strong>Action:</strong> Uses the <code class="docutils literal notranslate"><span class="pre">ModelName</span></code> created earlier. SageMaker launches the container, mounts the model artifact to <code class="docutils literal notranslate"><span class="pre">/opt/ml/model</span></code>, and provides input features from S3. The script loads the model, generates anomaly scores, and outputs scores (e.g., CSV format with identifiers and scores) to the specified S3 output path.</p></li>
</ul>
</li>
<li><p><strong>State:</strong> <code class="docutils literal notranslate"><span class="pre">ProcessResults</span></code></p>
<ul class="simple">
<li><p><strong>Service:</strong> AWS Lambda</p></li>
<li><p><strong>Action:</strong> Triggered after Batch Transform. Reads raw score files from the S3 output path. Applies the configured alert threshold. Formats alert data (ApartmentID, Date, Score, Status=’Unseen’, etc.). Writes alerts to the DynamoDB Alert Table using <code class="docutils literal notranslate"><span class="pre">BatchWriteItem</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Terminal States:</strong> <code class="docutils literal notranslate"><span class="pre">WorkflowSucceeded</span></code>, <code class="docutils literal notranslate"><span class="pre">WorkflowFailed</span></code>.</p></li>
</ol>
</section>
</section>
<section id="model-development-iteration">
<h3>Model Development &amp; Iteration<a class="headerlink" href="#model-development-iteration" title="Permalink to this heading">¶</a></h3>
<p><strong>Models for Anomaly Detection</strong></p>
<p><img alt="" src="_static/past_experiences/iot_anomaly/models1.png" />
<img alt="" src="_static/past_experiences/iot_anomaly/models2.png" /></p>
<p><img alt="" src="_static/past_experiences/iot_anomaly/model_development.png" /></p>
<!--

**Context:** The goal is to detect anomalous heating energy consumption at the apartment level. The initial phase is entirely unsupervised due to a lack of labels. As a feedback loop is established with maintenance technicians, we begin to collect "ground truth" labels, allowing for more quantitative evaluation and the use of supervised models.

**Evaluation Metric:**
*   **Phase 1 (Unsupervised):** Qualitative assessment and **Anomaly Yield @ Top K**. This measures the percentage of the top `k` most anomalous flagged apartments per week that, upon manual inspection, are deemed "interesting" or "suspicious" enough for a follow-up. Let's assume `k=50`.
*   **Phase 2 (Supervised):** **Precision & Recall @ Top K**. Once we have labels, we can measure what percentage of the top `k` flagged anomalies are true positives (Precision) and what percentage of all known true positives we successfully identified in our top `k` flags (Recall). This is crucial because the maintenance team can only investigate a limited number (`k`) of alerts per day/week.


Here is a list of the experiments performed:

| Experiment / Iteration | Model/Technique | Features Used | Evaluation Metric & Hypothetical Result | Key Learnings & Rationale |
| :--- | :--- | :--- | :--- | :--- |
| **Phase 1: Unsupervised Baselines & Initial Models** |
| **1. Heuristic Baseline** | Simple Rule-Based | - `heating_kwh`<br>- `room_temp_c`<br>- `setpoint_temp_c` | **Qualitative:** High False Positive Rate. | **Rationale:** Establish a basic performance floor. The rule (`heating_kwh > X` while `room_temp_c < setpoint_temp_c - 2°C`) caught obvious issues (e.g., non-stop heating) but was extremely noisy, flagging normal start-up cycles and poorly insulated rooms. Confirmed the need for more context-aware models. |
| **2. Statistical Baseline** | STL Decomposition | - `heating_kwh` (univariate) | **Anomaly Yield @ Top 50:** ~15% | **Rationale:** Decompose the energy signal to see if anomalies reside in the residual. It successfully identified unusual spikes and drops by removing seasonality but failed to account for weather or user behavior, leading to many false alarms when the weather was unexpectedly cold or warm. Showed that a univariate approach is insufficient. |
| **3. Simple Multivariate ML** | Linear Regression (Residuals) | - `heating_kwh` (target)<br>- `temp_diff` (setpoint - room)<br>- `outdoor_temp`<br>- `hour_of_day` | **Anomaly Yield @ Top 50:** 25% <br>*(Improvement: +67%)* | **Rationale:** Replicate and validate the success of the prior thesis. This model was significantly better as it contextualized energy usage against key drivers. Anomalies were now "unexplained energy use" rather than just "high energy use". Still struggled with non-linear relationships. |
| **4. Unsupervised Density-Based** | Local Outlier Factor (LOF) | - `heating_kwh`<br>- `temp_diff`<br>- `outdoor_temp`<br>- `hour_of_day` | **Anomaly Yield @ Top 50:** 30% <br>*(Improvement: +20%)* | **Rationale:** Test a non-parametric, density-based approach. LOF proved effective at finding apartments that behaved unusually compared to their *own* past behavior, catching subtle, persistent issues that regression residuals missed. It became a strong candidate model. |
| **5. Unsupervised Ensemble** | Isolation Forest | - `heating_kwh`<br>- `temp_diff`<br>- `outdoor_temp`<br>- `hour_of_day`<br>- `day_of_week` | **Anomaly Yield @ Top 50:** 32% <br>*(Improvement: +7%)* | **Rationale:** Test a modern, scalable unsupervised method. Isolation Forest performed slightly better than LOF, was faster to train, and handled additional features like `day_of_week` well. It showed strong potential for identifying globally rare anomalies across all apartments. |
| **6. Forecasting-Based Anomaly Detection** | Prophet | - `heating_kwh` (target)<br>- `outdoor_temp` (regressor)<br>- Holidays/Weekends | **Anomaly Yield @ Top 50:** 28% | **Rationale:** Use a state-of-the-art forecasting model to see if "what the model couldn't predict" is a good anomaly signal. Prophet was excellent at modeling seasonality and holidays but its uncertainty intervals (`yhat_upper`) were often too wide, missing more subtle anomalies that LOF or Isolation Forest could find. |
| **Phase 2: Introduction of Labeled Data & Supervised Models** |
| **7. First Supervised Model** | XGBoost | All features from Exp #5 +<br>- `is_weekend` | **(Labels Collected: ~500 True Positives)**<br>**Precision@50:** 55%<br>**Recall@50:** 45% | **Rationale:** With a small but valuable set of labels from the feedback loop, we can train a supervised classifier. XGBoost immediately outperformed the unsupervised methods by learning the specific patterns of labeled failures. The model was good but limited by the small label set. |
| **8. Advanced Feature Engineering** | XGBoost | All previous features +<br>- **Lag features** (e.g., energy 24h ago)<br>- **Rolling averages** (e.g., 3h avg temp_diff)<br>- **Interaction terms** (e.g., outdoor_temp * hour_of_day) | **Precision@50:** 70% <br>*(Improvement: +27%)*<br>**Recall@50:** 58% <br>*(Improvement: +29%)* | **Rationale:** Provide the model with richer temporal context. Lag and rolling window features gave the model a sense of recent history, dramatically improving its ability to distinguish between normal fluctuations and developing faults. This was the single biggest performance jump. |
| **9. Hyperparameter Optimization** | XGBoost (Tuned) | Same as Exp #8 | **Precision@50:** 75% <br>*(Improvement: +7%)*<br>**Recall@50:** 62% <br>*(Improvement: +7%)* | **Rationale:** Fine-tune the champion model (XGBoost with advanced features). Using SageMaker's Automatic Model Tuning (Bayesian optimization) provided a solid incremental gain by optimizing parameters like `max_depth`, `learning_rate`, and `n_estimators`. |
| **Phase 3: Exploration of Advanced Models** |
| **10. Deep Learning Exploration** | LSTM Autoencoder | Sequence of features from Exp #8 | **(Compared on reconstruction error)**<br>**Precision@50:** 72%<br>**Recall@50:** 65% | **Rationale:** Investigate if DL can capture complex temporal sequences that XGBoost might miss. The LSTM Autoencoder showed slightly better recall (found a few unique anomalies) but lower precision and was significantly more complex to train and tune. It did not justify replacing XGBoost as the champion model *at this stage* but remains a candidate for future improvements as more data and complex faults are recorded. |


**Summary of Model Development Path**

The experiments followed a logical progression from simple, interpretable baselines to more complex, data-driven models. The key takeaways from the development process were:

1.  **Context is King:** Simple univariate methods were insufficient. Incorporating external factors like outdoor temperature and user setpoints (multivariate approach) was the first major breakthrough.
2.  **Unsupervised Methods are Effective Starters:** In the absence of labels, unsupervised models like **Isolation Forest** and **LOF** provided significant value and a strong foundation for the initial alert system.
3.  **The Feedback Loop is Transformative:** The introduction of even a small amount of labeled data from maintenance technicians allowed the use of supervised models (**XGBoost**), which immediately surpassed unsupervised performance.
4.  **Feature Engineering Drives Performance:** The most significant leap in supervised model performance came from **advanced feature engineering** (lags and rolling windows), which provided the model with critical temporal context.
5.  **Start Simple, Optimize Later:** A well-featured XGBoost model, properly tuned, provided an excellent balance of performance, training speed, and scalability, outperforming a more complex LSTM Autoencoder for this specific problem at this stage.

---
-->
</section>
<section id="challenges-and-learnings">
<h3>Challenges and learnings<a class="headerlink" href="#challenges-and-learnings" title="Permalink to this heading">¶</a></h3>
<p><img alt="" src="_static/past_experiences/iot_anomaly/challenges1.png" /></p>
<p><img alt="" src="_static/past_experiences/iot_anomaly/challenges2.png" /></p>
<p><img alt="" src="_static/past_experiences/iot_anomaly/challenges3.png" /></p>
<!--

---

### Challenge 1: The Silent Drift - Training-Serving Skew from a Data Pipeline Bug

**Chronological Events:**

1.  **Initial Success (Weeks 1-4):** The supervised XGBoost model (Exp #8) is deployed. The daily inference pipeline runs, and the initial feedback from the maintenance team is positive. They confirm several alerts as true positives related to faulty valves and sensor misconfigurations. Precision metrics, calculated from their feedback, are close to the offline evaluation estimates (~70%).

2.  **The Slow Decline (Weeks 5-8):** Over the next month, the MLOps team notices a gradual decline in the feedback quality. The proportion of alerts marked as "False Positive" by technicians slowly increases. The marketing team, which has started promoting the "Proactive Maintenance" feature, reports a slight uptick in customer complaints about heating issues that were *not* flagged by the system, indicating a drop in recall.

3.  **Initial Investigation (Week 9):** The ML team suspects **concept drift**. The hypothesis is that as winter deepens, "normal" heating patterns are changing, and the model, trained on early winter data, is becoming stale. The team triggers a manual retraining of the model on the most recent data. After deploying the new model, performance metrics show a minor improvement for a few days before declining again. This makes simple model staleness less likely to be the root cause.

4.  **Lack of Observability (Week 10):** The team decides to dig deeper. They check the CloudWatch logs for the inference Step Function, but the logs only show that all jobs (Feature Eng, Batch Transform, Process Results) completed successfully. They look at the raw anomaly scores being produced, but without a clear baseline, it's hard to tell if the *distribution* of scores is wrong. **It becomes painfully evident that the existing observability setup is insufficient.** They can see pipeline *execution* status but have no insight into the *quality of the data* flowing through it.

5.  **Implementing Data Monitoring (Week 11):** As a direct response, the MLOps team implements a data monitoring step using **Deequ on a SageMaker Processing Job**. They create a monitoring job that runs daily on the output of the *inference* feature engineering step and the *training* feature engineering step (using a stored historical profile). The job calculates and compares statistical properties (mean, std dev, completeness, distribution distance like KL Divergence) for key features like `outdoor_temp`, `temp_diff`, and `heating_kwh`.

6.  **The "Aha!" Moment (Week 11, Day 3):** The first run of the new monitoring system raises a high-severity drift alert. The feature `outdoor_temp` in the inference data has a mean of `null` and 100% missing values. **This is the smoking gun.** The team traces the issue upstream.
    *   The Lambda function that ingests historical weather data from the external API works fine.
    *   However, the *Ingestion Glue Job* that processes raw IoT data and joins it with the raw weather data has a subtle bug. A recent change to gracefully handle missing weather data for a single building (by nullifying the column for that row) was implemented with a bug that caused it to nullify the `outdoor_temp` column for the *entire batch* if even one building's weather was missing for that day.

7.  **The Silent Failure Cascade:** The downstream `feature_engineering_inference.py` script saw the `null` `outdoor_temp` column and, as per its `fillna(0)` logic, replaced all nulls with `0.0`. The XGBoost model, trained on data where `outdoor_temp` was a valid and highly important feature, received an input where this feature was always zero. It continued to produce predictions, but they were effectively based on other, less predictive features, leading to a silent, gradual degradation of performance. **This was a classic, hard-to-debug training-serving skew caused by a data pipeline bug.**

8.  **Resolution & Aftermath (Week 12):** The Glue ETL bug is fixed and patched. The data monitoring job is made a permanent, blocking step in the CI/CD deployment validation. The incident triggered significant stress as the marketing campaign was already live. The team had to present a post-mortem to stakeholders, explaining the technical root cause and emphasizing that this was a failure in data observability, not a failure of the ML model's concept. They used this to justify allocating more resources to building out a comprehensive MLOps monitoring suite, including feature-level drift detection.

**Lessons & Retrospective:**

*   **"What would you change?":** "I would implement data quality and drift monitoring as a **Day 1 requirement**, not an afterthought. We should have had statistical checks on critical features in both the training and inference pipelines from the very beginning. A bug in an upstream data pipeline should never have been allowed to silently degrade the model's performance for weeks."
*   **"Production bugs you regret?":** "The `fillna(0)` in the feature engineering script was a dangerous shortcut. While it prevented the pipeline from crashing, it masked the upstream data integrity problem. A better approach would have been to have a stricter contract: the feature engineering job should have failed loudly if a critical input feature like `outdoor_temp` had an unexpectedly high null rate (e.g., >5%). This 'fail fast' philosophy would have alerted us to the problem immediately."

---

### Challenge 2: The "Normal Anomaly" - Unsupervised Model Evaluation and Alert Fatigue

**Chronological Events:**

1.  **Initial Launch (Unsupervised):** The system first goes live with the unsupervised **Isolation Forest** model (Exp #5). The model's `contamination` parameter is set to the default of "auto" or a heuristic guess (e.g., 1%). The daily inference pipeline starts flagging the top 1% of apartments with the highest anomaly scores.

2.  **Alert Overload (Weeks 1-3):** The maintenance team is immediately flooded with alerts. Their dashboard lights up with dozens of new potential issues every day. They investigate the top few and find that most are not equipment failures. Instead, the alerts correspond to:
    *   **Vacation Behavior:** An apartment that was consistently using energy suddenly uses none for a week. The model flags this significant deviation as an anomaly. When the residents return and turn the heating on, that's flagged too.
    *   **Unusual Schedules:** A resident who starts working night shifts and changes their heating schedule is flagged.
    *   **New Construction Oddities:** A newly commissioned building with very few residents shows erratic, low-consumption patterns that the model, trained on established buildings, flags as anomalous.

3.  **Loss of Trust & Alert Fatigue (Weeks 4-6):** The maintenance team quickly becomes disillusioned. They declare the system "too noisy" and start ignoring the alerts, reverting to their old reactive process. The project is at risk of being shelved due to a lack of operational adoption. The core problem is that the model is correctly identifying *statistical* anomalies, but these are not correlating with *operationally significant* anomalies (i.e., equipment faults).

4.  **Stakeholder Pressure (Week 7):** Management, having invested in the project, wants to know why it isn't working. The ML team has to explain that the unsupervised model is functioning as designed but lacks the business context to differentiate between "a resident on vacation" and "a broken heating valve".

5.  **Reframing the Problem: The Human-in-the-Loop (Week 8):** The team realizes they cannot solve this with a purely unsupervised model. They need human intelligence. They propose a **Phase 2** focused on creating a **data flywheel**.
    *   **UI/UX Overhaul:** They work with the maintenance team to redesign the alert dashboard. Instead of a raw list, alerts are now presented with more context (plots of energy vs. temperature, recent history).
    *   **Feedback First:** Crucially, they add simple feedback buttons: "True Positive (Investigate)", "False Positive (Known Cause)", with a dropdown for common causes like "Resident Away", "Guest Stay", "Manual Override".
    *   **Active Learning:** They change the model's role from "detector" to "screener". The model's output is now used to *prioritize* which apartments a technician should review, rather than being a definitive alert.

6.  **Iterative Threshold Tuning (Weeks 9-16):** With the feedback mechanism in place, the team starts collecting labels. They now have the data to tune the anomaly score threshold. Using the initial labeled data, they perform an analysis to find a threshold that maximizes precision (minimizes false positives for the techs) while maintaining a reasonable recall. They discover the optimal threshold is much higher than the default top 1%. They also implement a rule to suppress alerts for apartments with zero consumption for more than 48 hours (a heuristic for "vacation mode").

7.  **Transition to Supervised Model (Months 5-6):** Once several hundred positive and negative labels are collected, the team transitions to the **XGBoost supervised model** (Exp #7). This model is explicitly trained to find the patterns associated with *confirmed equipment faults*, not just any statistical deviation. This is the turning point. The new model's alerts are far more relevant, and the maintenance team's trust in the system is slowly rebuilt.

**Lessons & Retrospective:**

*   **"What were the challenges?":** "Our biggest initial challenge was the disconnect between a statistical anomaly and a business-relevant anomaly. Our unsupervised model was technically correct but operationally useless. This led to severe alert fatigue and almost caused the project to fail due to a lack of user adoption. The root cause was underestimating the importance of the human-in-the-loop and designing the initial system as a fully automated detector instead of a decision-support tool."
*   **"How would you approach it differently?":** "I would introduce the human-in-the-loop and the feedback mechanism from Day 1, even with the first unsupervised model. I would frame the project to stakeholders not as an 'AI that finds failures' but as a 'smart assistant that helps our best technicians find failures faster'. Managing expectations and co-designing the workflow with the end-users (the maintenance team) from the start is non-negotiable."

---

### Challenge 3: The Multi-Building Dilemma - Model Generalization vs. Specificity

**Chronological Events:**

1.  **Initial Model Strategy:** The team starts by training a **single, global XGBoost model** on data from all apartments across all buildings. The `building_id` is included as a categorical feature (one-hot encoded). This seems efficient and allows the model to learn from the largest possible dataset.

2.  **Performance Discrepancy (First Month in Production):** After deployment, the team monitors performance metrics (Precision/Recall from feedback) broken down by building. They discover a significant disparity:
    *   The model performs well (e.g., 75% precision) for the largest, most common type of building in the dataset (e.g., "Standard 10-story, 2010s construction").
    *   Performance is poor (e.g., <40% precision) for a few specific buildings: one is a new, highly energy-efficient "Passive House" building, and another is an older, poorly insulated building from the 1980s.
    *   The global model is biased towards the majority class (the standard buildings) and fails to capture the unique thermal dynamics of the outlier buildings. Its feature importances show that `building_id` is highly ranked, but it's not enough to correct for the different physical behaviors.

3.  **Debugging the Bias (Second Month):** The team uses **SHAP (SHapley Additive exPlanations)** to analyze the model's predictions for the poorly performing buildings.
    *   For the "Passive House", they find the model consistently overestimates the "normal" energy consumption, causing it to miss subtle but critical anomalies where the heat recovery ventilation (HRV) system was underperforming. The model, trained on less efficient buildings, couldn't comprehend such low energy usage being normal.
    *   For the older building, the model's concept of a "normal" relationship between outdoor temperature and energy use was completely wrong. It constantly flagged apartments as anomalous during cold snaps because their (normal for that building) high energy consumption looked extreme compared to the average.

4.  **Exploring Solutions (Third Month):** The team realizes a single global model is not a viable solution. They debate several strategies:
    *   **Option A: One Model Per Building:** Train a separate XGBoost model for each of the 120 buildings. This would be perfectly tailored but creates a massive MLOps headache – managing, deploying, and monitoring 120 individual models. It also exacerbates the cold-start problem for new buildings.
    *   **Option B: One Model Per Building "Archetype":** Manually classify buildings into archetypes based on metadata (age, insulation type, size, heating system). Train one model per archetype. This is a good compromise but relies on having accurate metadata and someone to define the archetypes.
    *   **Option C: Feature Engineering Hack:** Keep the global model but add more features that describe the building's characteristics (e.g., `building_age`, `insulation_R_value`, `num_apartments`). Hope the model learns the interactions. This is complex and might not be enough.
    *   **Option D: A More Sophisticated Model:** Re-evaluate models that can handle this structure more gracefully. DeepAR, for example, can learn a global model but uses static features (like `building_archetype`) to condition its predictions for specific time series.

5.  **The Chosen Solution: A Hybrid Approach (Fourth Month):**
    *   The team decides on a hybrid strategy as the most pragmatic solution:
        1.  **Segment Buildings:** They use a simple clustering on building metadata (age, size) to create 3 distinct archetypes: "Modern High-Density", "Older Low-Density", and "High-Efficiency".
        2.  **Train Models per Archetype:** They train **three separate XGBoost models**, one for each archetype. This provides specificity without creating an unmanageable number of models.
        3.  **Update MLOps:** The training pipeline is parameterized to accept an `archetype` and train a model using only data from buildings in that group. The inference pipeline is updated to first look up a building's archetype, then select and load the corresponding model from the Model Registry to score its apartments. The Model Registry is organized to track models per archetype.

6.  **Results:** After deploying the three archetype-specific models, performance becomes much more uniform across all buildings. Precision for the previously problematic "Passive House" and "Older" buildings jumps to over 70%. This approach provides a scalable and effective balance between a single global model and one model per building.

**Lessons & Retrospective:**

*   **"What were some of the challenges?":** "A major challenge was dealing with heterogeneity in our building stock. Our initial 'one size fits all' global model was a classic example of a model that worked well on average but failed significantly for important minority segments. It taught us that fairness and bias in ML aren't just about people; they can apply to physical assets too. Debugging this required going beyond aggregate metrics and using tools like SHAP to understand *why* the model was failing for specific buildings."
*   **"What lessons will you take forward?":** "I learned to be extremely skeptical of global models unless the underlying entities are truly homogeneous or the model is explicitly designed to handle heterogeneity (like DeepAR with static features). Always segment your evaluation metrics across meaningful business categories—in our case, building types. And finally, architect your MLOps pipelines (training and inference) to be flexible enough to support multiple models from the start. Our inference pipeline needed a significant refactor to dynamically select a model based on the building being processed, something we should have anticipated."



-->
</section>
<section id="configuration-management">
<h3>Configuration Management<a class="headerlink" href="#configuration-management" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Primary Method:</strong> Version-controlled configuration files (e.g., <code class="docutils literal notranslate"><span class="pre">config/ad_config.yaml</span></code>) stored in Git. These define non-sensitive parameters like hyperparameters, feature lists, thresholds, instance types.</p></li>
<li><p><strong>Distribution:</strong> Config files are uploaded to a designated S3 location (e.g., <code class="docutils literal notranslate"><span class="pre">s3://[scripts-bucket]/config/</span></code>) by the CI/CD pipeline.</p></li>
<li><p><strong>Loading:</strong> Scripts (Glue, SM Processing, Lambda) receive the S3 URI of the relevant config file via an environment variable (<code class="docutils literal notranslate"><span class="pre">CONFIG_S3_URI</span></code>) or argument. They use <code class="docutils literal notranslate"><span class="pre">boto3</span></code> to download and parse the file at runtime. Libraries like <code class="docutils literal notranslate"><span class="pre">PyYAML</span></code> are needed.</p></li>
<li><p><strong>Runtime Overrides:</strong> Step Function inputs or job arguments can override specific parameters from the config file for execution-specific needs (e.g., <code class="docutils literal notranslate"><span class="pre">inference_date</span></code>, experimental hyperparameters).</p></li>
<li><p><strong>Secrets:</strong> Sensitive information MUST be stored in AWS Secrets Manager or SSM Parameter Store (SecureString) and fetched by the application code using its IAM role. Do NOT store secrets in Git config files.</p></li>
<li><p><strong>Environment Variables:</strong> Used primarily for passing S3 URIs (config file, data paths), resource names (table names, feature group), and potentially secrets fetched from secure stores.</p></li>
</ul>
</section>
<section id="infrastructure-as-code-terraform">
<h3>Infrastructure as Code (Terraform)<a class="headerlink" href="#infrastructure-as-code-terraform" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Tool:</strong> Terraform manages all AWS infrastructure.</p></li>
<li><p><strong>State Management:</strong> Configure a remote backend (e.g., S3 with DynamoDB locking) for Terraform state files.</p></li>
<li><p><strong>Stacks:</strong> Infrastructure is divided into logical stacks:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ingestion</span></code>: S3 buckets (Raw, Processed), Glue DB/Tables, Ingestion Glue Job, associated IAM roles.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">training</span></code>: S3 buckets (Scripts, Artifacts, Reports - potentially reused/shared), ECR Repo, Feature Group, Model Package Group, specific IAM roles, Lambdas (Register Model), Step Function (<code class="docutils literal notranslate"><span class="pre">ADTrainingWorkflow</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inference</span></code>: DynamoDB Table (Alerts), specific IAM roles, Lambdas (Get Model, Create Model, Process Results), Step Function (<code class="docutils literal notranslate"><span class="pre">ADInferenceWorkflow</span></code>), EventBridge Scheduler.</p></li>
</ul>
</li>
<li><p><strong>Variables &amp; Outputs:</strong> Stacks use input variables (defined in <code class="docutils literal notranslate"><span class="pre">variables.tf</span></code>) for configuration and expose key resource identifiers via outputs (defined in <code class="docutils literal notranslate"><span class="pre">outputs.tf</span></code>). Outputs from one stack (e.g., <code class="docutils literal notranslate"><span class="pre">processed_bucket_name</span></code> from ingestion) are passed as inputs to dependent stacks.</p></li>
</ul>
</section>
<section id="ci-cd-pipeline-bitbucket">
<h3>CI/CD Pipeline (Bitbucket)<a class="headerlink" href="#ci-cd-pipeline-bitbucket" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Tool:</strong> Bitbucket Pipelines (<code class="docutils literal notranslate"><span class="pre">bitbucket-pipelines.yml</span></code>).</p></li>
<li><p><strong>CI Workflow (Branches/PRs):</strong></p>
<ol class="arabic simple">
<li><p>Lint Python code (<code class="docutils literal notranslate"><span class="pre">flake8</span></code>).</p></li>
<li><p>Run Unit Tests (<code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">tests/unit/</span></code>).</p></li>
<li><p>Build Training/Inference Docker container.</p></li>
<li><p>Push container to AWS ECR (tagged with commit hash).</p></li>
<li><p>Validate Terraform code (<code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">validate</span></code>, <code class="docutils literal notranslate"><span class="pre">fmt</span> <span class="pre">-check</span></code>) for all stacks.</p></li>
</ol>
</li>
<li><p><strong>Training CD Workflow (<code class="docutils literal notranslate"><span class="pre">custom:deploy-and-test-ad-training</span></code>):</strong></p>
<ol class="arabic simple">
<li><p>(Manual Trigger Recommended)</p></li>
<li><p>Run CI steps (Lint, Unit Test, Build/Push).</p></li>
<li><p>Apply <code class="docutils literal notranslate"><span class="pre">training_ad</span></code> Terraform stack (using commit-specific image URI).</p></li>
<li><p>Prepare integration test data (trigger ingestion or verify pre-staged).</p></li>
<li><p>Run Training Integration Tests (<code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">tests/integration/test_training_workflow.py</span></code>).</p></li>
</ol>
</li>
<li><p><strong>Inference CD Workflow (<code class="docutils literal notranslate"><span class="pre">custom:deploy-and-test-ad-inference</span></code>):</strong></p>
<ol class="arabic simple">
<li><p>(Manual Trigger Recommended)</p></li>
<li><p>(Optional) Run CI checks.</p></li>
<li><p>Apply <code class="docutils literal notranslate"><span class="pre">inference_ad</span></code> Terraform stack.</p></li>
<li><p>Prepare integration test data (verify processed data, ensure approved model exists).</p></li>
<li><p>Run Inference Integration Tests (<code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">tests/integration/test_inference_workflow.py</span></code>).</p></li>
</ol>
</li>
<li><p><strong>Variables:</strong> Uses Bitbucket Repository Variables (CI) and Deployment Variables (CD) for AWS credentials and environment-specific parameters.</p></li>
</ul>
</section>
<section id="cost-analysis">
<h3>Cost Analysis<a class="headerlink" href="#cost-analysis" title="Permalink to this heading">¶</a></h3>
<!--
![](../_static/past_experiences/iot_anomaly/cost.png)
-->
<p>This is a high-level estimate based on the architecture we designed and the data volume assumptions made previously. Actual costs will vary.</p>
<p><strong>Assumptions:</strong></p>
<ul class="simple">
<li><p><strong>Environment:</strong> AWS <code class="docutils literal notranslate"><span class="pre">eu-central-1</span></code> (Frankfurt) region.</p></li>
<li><p><strong>Apartments:</strong> 3,000.</p></li>
<li><p><strong>Daily Processed Data:</strong> ~300 MB ingested into the Processed S3 Zone.</p></li>
<li><p><strong>Total Monthly Processed Data:</strong> 300 MB/day * 30 days = <strong>~9 GB</strong>.</p></li>
<li><p><strong>Model Training Frequency:</strong> 4 times per month (weekly).</p></li>
<li><p><strong>Batch Inference Frequency:</strong> 30 times per month (daily).</p></li>
</ul>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Pipeline Component</p></th>
<th class="head text-left"><p>AWS Service(s)</p></th>
<th class="head text-left"><p>Detailed Cost Calculation &amp; Rationale</p></th>
<th class="head text-left"><p>Estimated Cost (USD)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Data Ingestion &amp; Processing</strong></p></td>
<td class="text-left"><p><strong>AWS Glue</strong><br><strong>S3</strong></p></td>
<td class="text-left"><p><strong>AWS Glue ETL:</strong> Priced per DPU-hour. This covers the initial job to process raw IoT data into the <code class="docutils literal notranslate"><span class="pre">processed_meter_data</span></code> S3 zone. Assuming a daily run of a small-to-medium job.<br>- 1 job/day * 30 days * 0.25 hours/job * 5 DPUs * ~$0.44/DPU-hr = <strong>~$16.50</strong><br><br><strong>S3 (PUT Requests):</strong> Cost for ingestion jobs writing to the Processed bucket. Assuming ~100k PUT requests per day for all apartments.<br>- 100k req/day * 30 days * ~$0.005/1k req = <strong>~$15.00</strong><br>The cost is primarily driven by the daily processing compute and the volume of S3 writes.</p></td>
<td class="text-left"><p><strong>$30 - $50</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Feature Engineering</strong></p></td>
<td class="text-left"><p><strong>SageMaker Processing</strong><br><strong>SageMaker Feature Store</strong></p></td>
<td class="text-left"><p><strong>SageMaker Processing Jobs:</strong> Priced per instance-second. This covers the feature engineering steps in <em>both</em> the weekly training pipeline and the daily inference pipeline.<br>- Training: 4 runs/month * 1.5 hours/run * 1 <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> instance * ~$0.11/hr = <strong>~$0.66</strong><br>- Inference: 30 runs/month * 0.5 hours/run * 1 <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> instance * ~$0.11/hr = <strong>~$1.65</strong><br><br><strong>SageMaker Feature Store:</strong> Priced per GB-month (Offline), plus Write/Read units.<br>- Offline Store (S3): Covered under Storage cost. Assume ~50 GB of feature data.<br>- Write/Read Units: For batch-only workflows, this cost is typically low. Assuming minimal average usage. = <strong>~$1.00</strong> (buffer)</p></td>
<td class="text-left"><p><strong>$3 - $8</strong></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Model Training</strong></p></td>
<td class="text-left"><p><strong>SageMaker Training</strong><br><strong>Step Functions</strong></p></td>
<td class="text-left"><p><strong>SageMaker Training Jobs:</strong> Priced per instance-second. Assuming weekly retraining on a standard instance.<br>- 4 runs/month * 2.0 hours/run * 1 <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> instance * ~$0.11/hr = <strong>~$0.88</strong><br><br><strong>Step Functions:</strong> Priced per state transition. The training workflow is complex but runs infrequently.<br>- ~10 transitions/run * 4 runs/month = 40 transitions. This is well within the free tier. = <strong>~$0.00</strong></p></td>
<td class="text-left"><p><strong>$1 - $3</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Model Inference</strong></p></td>
<td class="text-left"><p><strong>SageMaker Batch Transform</strong><br><strong>Step Functions</strong></p></td>
<td class="text-left"><p><strong>SageMaker Batch Transform:</strong> Priced per instance-second. This is the daily job that scores all apartments.<br>- 30 runs/month * 1.0 hour/run * 1 <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> instance * ~$0.11/hr = <strong>~$3.30</strong><br><br><strong>Step Functions:</strong> The inference workflow runs daily.<br>- ~8 transitions/run * 30 runs/month = 240 transitions. Also well within the free tier. = <strong>~$0.00</strong></p></td>
<td class="text-left"><p><strong>$3 - $5</strong></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Alerting &amp; Orchestration</strong></p></td>
<td class="text-left"><p><strong>AWS Lambda</strong><br><strong>DynamoDB</strong></p></td>
<td class="text-left"><p><strong>Lambda:</strong> Priced per request and GB-second. Covers several functions in the workflows (Register Model, Get Approved Model, Process Results, etc.).<br>- ~40 total invocations/month * avg 10 sec duration * 256MB memory. All usage is well within the Lambda free tier. = <strong>~$0.00</strong><br><br><strong>DynamoDB:</strong> Priced per GB-month storage and per million RCU/WCU. Assuming Pay-Per-Request (On-Demand) mode.<br>- Storage: Assume ~1 GB of alert data stored. = <strong>~$0.25</strong><br>- Write/Read Units: Assume ~5k alerts generated/month (writes) and ~10k dashboard queries/month (reads). On-Demand cost is negligible at this scale. = <strong>~$0.10</strong></p></td>
<td class="text-left"><p><strong>$1 - $2</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Storage &amp; Logging</strong></p></td>
<td class="text-left"><p><strong>S3</strong><br><strong>ECR</strong><br><strong>CloudWatch</strong></p></td>
<td class="text-left"><p><strong>S3:</strong> Priced per GB-month. This is the largest continuous cost. Assumes total storage for Raw, Processed, Features, Artifacts, and Logs.<br>- Raw: 200 GB, Processed: 150 GB, Features: 50 GB, Artifacts/Other: 5 GB = ~405 GB<br>- 405 GB * ~$0.023/GB-month = <strong>~$9.32</strong><br>- Add ~$5 for GET/LIST requests from various jobs.<br><br><strong>ECR:</strong> Priced per GB-month. For storing the custom training/inference container images.<br>- 10 GB * ~$0.10/GB-month = <strong>~$1.00</strong><br><br><strong>CloudWatch:</strong> Logs from all jobs and Lambdas. Assuming usage stays within or slightly above the free tier.<br>- Assume ~10 GB log ingestion * ~$0.50/GB = <strong>~$5.00</strong></p></td>
<td class="text-left"><p><strong>$20 - $30</strong></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Total Estimated Monthly Cost</strong></p></td>
<td class="text-left"><p><strong>-</strong></p></td>
<td class="text-left"><p><strong>-</strong></p></td>
<td class="text-left"><p><strong>$60 - $100</strong></p></td>
</tr>
</tbody>
</table>
</div>
<p>This detailed breakdown reveals that the operational cost is dominated by <strong>Data Ingestion/Processing (Glue &amp; S3 PUTs)</strong> and <strong>persistent Storage (S3 &amp; ECR)</strong>. The actual ML compute costs for training and inference are relatively small due to their batch, on-demand nature. This highlights the efficiency of a serverless, batch-oriented architecture for this use case, as there are no 24/7 clusters or endpoints to maintain. Optimizing S3 storage with lifecycle policies will be the most effective long-term cost management strategy.</p>
<p><strong>Cost Optimisations</strong></p>
<ul class="simple">
<li><p>S3 Storage Dominates: The largest cost component by far is S3 storage. Implementing S3 Lifecycle policies to move older raw/processed data or feature versions to cheaper tiers (like Intelligent-Tiering or Glacier) is crucial for long-term cost management.</p></li>
<li><p>Compute is Relatively Low: The actual compute cost for running the training jobs weekly is quite low with these assumptions.</p></li>
<li><p>Assumptions Matter: If your training jobs run much longer, use more instances, or run more frequently, the SageMaker costs will increase proportionally. If your data volume is significantly larger, S3 costs increase.</p></li>
<li><p>Spot Instances: For SageMaker Processing and Training Jobs, using Spot Instances can potentially save up to 90% on compute costs, but requires designing the jobs to handle potential interruptions (checkpointing for Training, stateless design for Processing). This could significantly reduce the ~$1.45 compute estimate.</p></li>
<li><p>Instance Selection: Choosing the right instance type (e.g., ml.t3.medium for less demanding tasks can optimize compute cost.</p></li>
</ul>
</section>
<section id="deployment-execution">
<h3>Deployment &amp; Execution<a class="headerlink" href="#deployment-execution" title="Permalink to this heading">¶</a></h3>
<p><strong>Initial Deployment:</strong></p>
<ol class="arabic simple">
<li><p>Configure AWS credentials locally/in CI runner.</p></li>
<li><p>Configure Bitbucket variables (Repository &amp; Deployment).</p></li>
<li><p>Create <code class="docutils literal notranslate"><span class="pre">terraform.tfvars</span></code> files for each stack (<code class="docutils literal notranslate"><span class="pre">ingestion</span></code>, <code class="docutils literal notranslate"><span class="pre">training</span></code>, <code class="docutils literal notranslate"><span class="pre">inference</span></code>) providing required inputs (unique suffixes, potentially outputs from previous stacks).</p></li>
<li><p>Deploy Terraform stacks <strong>in order</strong>: <code class="docutils literal notranslate"><span class="pre">ingestion</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">training</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">inference</span></code>. Run <code class="docutils literal notranslate"><span class="pre">init</span></code>, <code class="docutils literal notranslate"><span class="pre">plan</span></code>, <code class="docutils literal notranslate"><span class="pre">apply</span></code> for each.</p></li>
<li><p>Build and push the initial Docker training/inference container to the ECR repository created by <code class="docutils literal notranslate"><span class="pre">training</span></code>. Ensure the <code class="docutils literal notranslate"><span class="pre">training_image_uri</span></code> variable used by Terraform deployments points to this image.</p></li>
<li><p>Place initial configuration files (<code class="docutils literal notranslate"><span class="pre">config.yaml</span></code>) in the designated S3 config location.</p></li>
<li><p>Prepare initial raw data and run the Ingestion Glue job once to populate the processed data zone.</p></li>
</ol>
<p><strong>Running Training:</strong></p>
<ul class="simple">
<li><p>Trigger the <code class="docutils literal notranslate"><span class="pre">ADTrainingWorkflow</span></code> Step Function manually or via its schedule.</p></li>
<li><p>Provide input JSON specifying date range, parameters, code version (via image URI/git hash).</p></li>
</ul>
<p><strong>Running Inference:</strong></p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">ADInferenceWorkflow</span></code> Step Function runs automatically based on the EventBridge schedule.</p></li>
<li><p>Ensure an <em>Approved</em> model package exists in the Model Registry for the workflow to succeed.</p></li>
</ul>
<p><strong>Model Approval:</strong></p>
<ul class="simple">
<li><p>After a successful <em>Training</em> run, navigate to SageMaker -&gt; Model Registry -&gt; Model Package Groups -&gt; [Your AD Group].</p></li>
<li><p>Select the latest version (<code class="docutils literal notranslate"><span class="pre">PendingManualApproval</span></code>).</p></li>
<li><p>Review Description, Metadata, Evaluation Metrics.</p></li>
<li><p>If satisfactory, update status to <code class="docutils literal notranslate"><span class="pre">Approved</span></code>.</p></li>
</ul>
</section>
<section id="monitoring-alerting">
<h3>Monitoring &amp; Alerting<a class="headerlink" href="#monitoring-alerting" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>CloudWatch Logs:</strong> Central location for logs from Lambda, Glue, SageMaker Jobs. Implement structured logging within Python scripts for easier parsing.</p></li>
<li><p><strong>CloudWatch Metrics:</strong> Monitor key metrics:</p>
<ul>
<li><p>Step Functions: <code class="docutils literal notranslate"><span class="pre">ExecutionsFailed</span></code>, <code class="docutils literal notranslate"><span class="pre">ExecutionsTimedOut</span></code>.</p></li>
<li><p>Lambda: <code class="docutils literal notranslate"><span class="pre">Errors</span></code>, <code class="docutils literal notranslate"><span class="pre">Throttles</span></code>, <code class="docutils literal notranslate"><span class="pre">Duration</span></code>.</p></li>
<li><p>SageMaker Jobs: <code class="docutils literal notranslate"><span class="pre">CPUUtilization</span></code>, <code class="docutils literal notranslate"><span class="pre">MemoryUtilization</span></code> (if needed), Job Status (via Logs/Events).</p></li>
<li><p>DynamoDB: <code class="docutils literal notranslate"><span class="pre">ThrottledWriteRequests</span></code>, <code class="docutils literal notranslate"><span class="pre">ThrottledReadRequests</span></code>.</p></li>
</ul>
</li>
<li><p><strong>CloudWatch Alarms:</strong> <strong>REQUIRED:</strong> Set alarms on critical failure metrics (SFN <code class="docutils literal notranslate"><span class="pre">ExecutionsFailed</span></code>, Lambda <code class="docutils literal notranslate"><span class="pre">Errors</span></code>). Configure SNS topics for notifications.</p></li>
<li><p><strong>SageMaker Model Monitor (Future):</strong> Implement data quality and model quality monitoring to detect drift over time.</p></li>
<li><p><strong>Application-Level Monitoring:</strong> Track the number of alerts generated daily, processing times, etc.</p></li>
</ul>
</section>
<section id="troubleshooting-guide">
<h3>Troubleshooting Guide<a class="headerlink" href="#troubleshooting-guide" title="Permalink to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Workflow Failure (Step Functions):</strong> Check the Step Functions execution history in the AWS Console. Identify the failed state and examine its input, output, and error message.</p></li>
<li><p><strong>Job Failures (Glue/SageMaker):</strong> Go to the corresponding CloudWatch Log Group for the failed job (links often available in Step Function state details). Look for Python exceptions or service errors. Check job metrics for resource exhaustion.</p></li>
<li><p><strong>Lambda Failures:</strong> Check the Lambda function’s CloudWatch Log Group. Look for errors, timeouts, or permission issues. Verify environment variables and input payload.</p></li>
<li><p><strong>IAM Permissions:</strong> If errors indicate access denied, carefully review the IAM roles and policies associated with the failing service (SFN, Lambda, SageMaker Job roles) ensuring necessary permissions to other services (S3, SageMaker API, DynamoDB, ECR, etc.).</p></li>
<li><p><strong>Data Issues:</strong></p>
<ul class="simple">
<li><p><strong>Schema Mismatch:</strong> Check <code class="docutils literal notranslate"><span class="pre">ValidateSchema</span></code> logs. Verify Glue Catalog definition matches actual data.</p></li>
<li><p><strong>Missing Features:</strong> Ensure feature engineering script runs correctly and produces all columns needed by the model. Check Feature Store ingestion if used.</p></li>
<li><p><strong>Empty Data:</strong> Check upstream processes; ensure ingestion ran and data exists for the target dates.</p></li>
</ul>
</li>
<li><p><strong>Configuration Errors:</strong> Verify config files in S3 are correct and accessible. Check environment variables passed to jobs/lambdas.</p></li>
<li><p><strong>Model Artifact Issues:</strong> Ensure the <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> exists, is not corrupted, and contains all necessary files (<code class="docutils literal notranslate"><span class="pre">model.joblib</span></code>, etc.). Verify the <code class="docutils literal notranslate"><span class="pre">inference.py</span></code> script loads it correctly.</p></li>
<li><p><strong>Batch Transform Failures:</strong> Check Batch Transform job logs in CloudWatch. Common issues include container errors (script failures, dependency issues), data format errors, or IAM permission problems for the model’s execution role.</p></li>
</ol>
</section>
<section id="security-considerations">
<h3>Security Considerations<a class="headerlink" href="#security-considerations" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>IAM Least Privilege:</strong> Regularly review and tighten IAM roles assigned to Step Functions, Lambdas, Glue, and SageMaker jobs. Grant only necessary permissions.</p></li>
<li><p><strong>Data Encryption:</strong></p>
<ul>
<li><p><strong>At Rest:</strong> Enable server-side encryption (SSE-S3, SSE-KMS) on all S3 buckets. Enable encryption for DynamoDB tables. Ensure EBS volumes attached to SageMaker jobs are encrypted.</p></li>
<li><p><strong>In Transit:</strong> AWS services use TLS for communication by default. Ensure any custom external connections also use TLS.</p></li>
</ul>
</li>
<li><p><strong>Secret Management:</strong> Use AWS Secrets Manager or SSM Parameter Store (SecureString) for any sensitive credentials or API keys.</p></li>
<li><p><strong>Network Security:</strong> For enhanced security, consider deploying resources within a VPC using VPC Endpoints for AWS service access, minimizing exposure to the public internet. Configure Security Groups appropriately.</p></li>
<li><p><strong>Container Security:</strong> Regularly scan the custom Docker container image for vulnerabilities using ECR Image Scanning or third-party tools. Keep base images and libraries updated.</p></li>
<li><p><strong>Input Validation:</strong> Sanitize and validate inputs to Lambda functions and Step Function executions, especially if triggered externally.</p></li>
<li><p><strong>Access Control:</strong> Restrict access to the SageMaker Model Registry and approval workflows to authorized personnel.</p></li>
</ul>
</section>
<section id="roadmap-future-enhancements">
<h3>Roadmap &amp; Future Enhancements<a class="headerlink" href="#roadmap-future-enhancements" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Implement SageMaker Model Monitor for data quality and model drift detection.</p></li>
<li><p>Set up automated retraining triggers based on schedule or drift detection.</p></li>
<li><p>Explore more sophisticated anomaly detection algorithms (e.g., Autoencoders, Isolation Forests) via the Strategy Pattern.</p></li>
<li><p>Implement A/B testing for different model versions using SageMaker Inference Pipelines.</p></li>
<li><p>Enhance the Internal Dashboard for better alert visualization and diagnostics.</p></li>
<li><p>Integrate alerts directly with maintenance ticketing systems.</p></li>
</ul>
</section>
<section id="appendices">
<h3>Appendices<a class="headerlink" href="#appendices" title="Permalink to this heading">¶</a></h3>
<section id="data-schemas">
<h4>Data Schemas<a class="headerlink" href="#data-schemas" title="Permalink to this heading">¶</a></h4>
<p>This appendix provides the formal schema definitions for the primary data entities used across the Anomaly Detection and Energy Demand Forecasting workflows.</p>
</section>
<section id="raw-meter-data">
<h4>1. Raw Meter Data<a class="headerlink" href="#raw-meter-data" title="Permalink to this heading">¶</a></h4>
<p>This represents the logical structure of data as it arrives from the central database into the S3 Raw Zone for processing. It’s often in a semi-structured format like JSON Lines.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Field Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">timestamp_str</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>ISO 8601 formatted timestamp (e.g., “2024-10-27T10:30:05Z”) of when the readings were recorded by the tablet.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">building_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Unique identifier for the building (e.g., “bldg_A123”).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">apartment_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Unique identifier for the apartment (e.g., “apt_404”).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">readings</span></code></p></td>
<td class="text-left"><p>Array[Object]</p></td>
<td class="text-left"><p>An array of sensor reading objects from the apartment.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">readings.sensor_type</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>The type of measurement (e.g., <code class="docutils literal notranslate"><span class="pre">heating_energy_kwh</span></code>, <code class="docutils literal notranslate"><span class="pre">room_temp_c</span></code>).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">readings.value</span></code></p></td>
<td class="text-left"><p>Double/Int</p></td>
<td class="text-left"><p>The numerical value of the sensor reading.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">readings.room_name</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>(Optional) The specific room for the reading, if applicable (e.g., “living_room”).</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Example (JSON Lines):</strong></p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;timestamp_str&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2024-10-27T10:30:00Z&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;building_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;bldg_A123&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;apartment_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;apt_404&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;readings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="nt">&quot;sensor_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;heating_energy_kwh&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">15432.7</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;sensor_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hot_water_litres&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">89541.2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;sensor_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;room_temp_c&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;room_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;living_room&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">21.5</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;sensor_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;setpoint_temp_c&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;room_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;living_room&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">22.0</span><span class="p">}]}</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="processed-meter-data-for-anomaly-detection">
<h4>2. Processed Meter Data (for Anomaly Detection)<a class="headerlink" href="#processed-meter-data-for-anomaly-detection" title="Permalink to this heading">¶</a></h4>
<p>This is the output of the initial Ingestion Glue ETL job, stored in the S3 Processed Zone. It’s a flattened, structured table optimized for analytical queries and as the source for feature engineering.</p>
<p><strong>Format:</strong> Apache Parquet
<strong>Partitioned by:</strong> <code class="docutils literal notranslate"><span class="pre">year</span></code>, <code class="docutils literal notranslate"><span class="pre">month</span></code>, <code class="docutils literal notranslate"><span class="pre">day</span></code></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Column Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">apartment_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Unique identifier for the apartment.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">building_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Unique identifier for the building.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">event_ts</span></code></p></td>
<td class="text-left"><p>Timestamp</p></td>
<td class="text-left"><p>The timestamp of the reading, cast to a proper timestamp type.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">heating_energy_kwh</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The cumulative heating energy consumption in kilowatt-hours.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hot_water_litres</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The cumulative hot water consumption in litres.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">room_temp_c</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The measured temperature in Celsius for a specific room (or average).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">setpoint_temp_c</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The user-defined target temperature in Celsius for a specific room.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">outdoor_temp_c</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The outdoor temperature at the time of the reading, joined from weather data.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>year</strong></p></td>
<td class="text-left"><p>Integer</p></td>
<td class="text-left"><p><strong>Partition Key:</strong> Year derived from <code class="docutils literal notranslate"><span class="pre">event_ts</span></code>.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>month</strong></p></td>
<td class="text-left"><p>Integer</p></td>
<td class="text-left"><p><strong>Partition Key:</strong> Month derived from <code class="docutils literal notranslate"><span class="pre">event_ts</span></code>.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>day</strong></p></td>
<td class="text-left"><p>Integer</p></td>
<td class="text-left"><p><strong>Partition Key:</strong> Day derived from <code class="docutils literal notranslate"><span class="pre">event_ts</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="weather-data">
<h4>3. Weather Data<a class="headerlink" href="#weather-data" title="Permalink to this heading">¶</a></h4>
<p><strong>3.1 Raw Weather Forecast Data (from API)</strong></p>
<p>This is the raw JSON structure ingested from the external weather forecast API into the S3 Raw Zone.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Field Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">latitude</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>Latitude of the forecast location.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">longitude</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>Longitude of the forecast location.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">generationtime_ms</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>Time taken by the API to generate the forecast.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">utc_offset_seconds</span></code></p></td>
<td class="text-left"><p>Integer</p></td>
<td class="text-left"><p>UTC offset for the location.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hourly</span></code></p></td>
<td class="text-left"><p>Object</p></td>
<td class="text-left"><p>An object containing arrays of hourly forecast values.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hourly.time</span></code></p></td>
<td class="text-left"><p>Array[String]</p></td>
<td class="text-left"><p>Array of ISO 8601 timestamps for the forecast horizon.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hourly.temperature_2m</span></code></p></td>
<td class="text-left"><p>Array[Double]</p></td>
<td class="text-left"><p>Array of corresponding forecasted temperatures (°C).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hourly.cloudcover</span></code></p></td>
<td class="text-left"><p>Array[Integer]</p></td>
<td class="text-left"><p>Array of corresponding forecasted cloud cover (%).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hourly.shortwave_radiation</span></code></p></td>
<td class="text-left"><p>Array[Double]</p></td>
<td class="text-left"><p>Array of corresponding forecasted solar irradiance (W/m²).</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>3.2 Processed Weather Data (Joined in <code class="docutils literal notranslate"><span class="pre">processed_edf_data</span></code>)</strong></p>
<p>This represents the clean, hourly weather data after being processed and joined to the consumption data.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Column Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">building_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Unique identifier for the building the weather corresponds to.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">timestamp_hour</span></code></p></td>
<td class="text-left"><p>Timestamp</p></td>
<td class="text-left"><p>The specific hour for which the weather data is valid, truncated.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">temperature_c</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The average temperature in Celsius for that hour.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">humidity</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The average relative humidity (%) for that hour.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">solar_irradiance_ghi</span></code></p></td>
<td class="text-left"><p>Double</p></td>
<td class="text-left"><p>The average Global Horizontal Irradiance (W/m²) for that hour.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">is_holiday_flag</span></code></p></td>
<td class="text-left"><p>Integer</p></td>
<td class="text-left"><p>A binary flag (1 or 0) indicating if the date is a public holiday.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="feature-store-features-anomaly-detection">
<h4>4. Feature Store Features (Anomaly Detection)<a class="headerlink" href="#feature-store-features-anomaly-detection" title="Permalink to this heading">¶</a></h4>
<p>This defines the schema of the <code class="docutils literal notranslate"><span class="pre">ad-apartment-features</span></code> Feature Group in SageMaker Feature Store. These are the inputs to the AD model.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Feature Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>apartment_record_id</strong></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p><strong>Record Identifier:</strong> Unique ID for the record (e.g., <code class="docutils literal notranslate"><span class="pre">[apartment_id]_[date]</span></code>).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>event_time</strong></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p><strong>Event Time:</strong> Timestamp when the features were computed/ingested.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">event_date</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>The specific date (YYYY-MM-DD) these daily features correspond to.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">building_id</span></code></p></td>
<td class="text-left"><p>String</p></td>
<td class="text-left"><p>Identifier for the building.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">avg_temp_diff</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>The average difference between the setpoint and actual room temperature for the day.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">daily_energy_kwh</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>The total heating energy consumed on that day.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">hdd</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>Heating Degree Days, a measure of how cold the day was.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">energy_lag_1d</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>The value of <code class="docutils literal notranslate"><span class="pre">daily_energy_kwh</span></code> from the previous day.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">energy_roll_avg_7d</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>The 7-day rolling average of <code class="docutils literal notranslate"><span class="pre">daily_energy_kwh</span></code>.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">temp_diff_roll_std_3d</span></code></p></td>
<td class="text-left"><p>Fractional</p></td>
<td class="text-left"><p>The 3-day rolling standard deviation of <code class="docutils literal notranslate"><span class="pre">avg_temp_diff</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="alert-table-schema-dynamodb">
<h4>5. Alert Table Schema (DynamoDB)<a class="headerlink" href="#alert-table-schema-dynamodb" title="Permalink to this heading">¶</a></h4>
<p>This defines the structure of the <code class="docutils literal notranslate"><span class="pre">ad-alerts</span></code> table in Amazon DynamoDB, where the inference pipeline stores actionable alerts.</p>
<p><strong>Table Name:</strong> <code class="docutils literal notranslate"><span class="pre">hometech-ml-ad-alerts-[env]</span></code></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Attribute Name</p></th>
<th class="head text-left"><p>Data Type</p></th>
<th class="head text-left"><p>Key Type / Index</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>AlertID</strong></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p><strong>Partition Key (PK)</strong></p></td>
<td class="text-left"><p>Unique identifier for the alert. <strong>Format:</strong> <code class="docutils literal notranslate"><span class="pre">[ApartmentID]#[EventDate]</span></code>.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ApartmentID</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>GSI-1 Partition Key</p></td>
<td class="text-left"><p>The unique identifier of the apartment that triggered the alert.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">BuildingID</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>GSI-2 Partition Key</p></td>
<td class="text-left"><p>The unique identifier of the building.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">EventDate</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>-</p></td>
<td class="text-left"><p>The date (YYYY-MM-DD) for which the anomaly was detected.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">AlertTimestamp</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>GSI-2 Sort Key</p></td>
<td class="text-left"><p>ISO 8601 timestamp of when the alert was created by the pipeline.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">AnomalyScore</span></code></p></td>
<td class="text-left"><p>Number (N)</p></td>
<td class="text-left"><p>-</p></td>
<td class="text-left"><p>The raw numerical score from the ML model. Higher means more anomalous.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Threshold</span></code></p></td>
<td class="text-left"><p>Number (N)</p></td>
<td class="text-left"><p>-</p></td>
<td class="text-left"><p>The score threshold that was breached to create this alert.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Status</strong></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>GSI-1 Sort Key</p></td>
<td class="text-left"><p>The current state of the alert. <strong>Values:</strong> <code class="docutils literal notranslate"><span class="pre">Unseen</span></code>, <code class="docutils literal notranslate"><span class="pre">Investigating</span></code>, <code class="docutils literal notranslate"><span class="pre">Resolved-True</span> <span class="pre">Positive</span></code>, <code class="docutils literal notranslate"><span class="pre">Resolved-False</span> <span class="pre">Positive</span></code>.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ModelVersion</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>-</p></td>
<td class="text-left"><p>Version of the model package that generated the score (for lineage).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">FeedbackNotes</span></code></p></td>
<td class="text-left"><p>String (S)</p></td>
<td class="text-left"><p>-</p></td>
<td class="text-left"><p>(Optional) Notes entered by the maintenance technician during review.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Global Secondary Indexes (GSIs):</strong></p>
<ul class="simple">
<li><p><strong>GSI-1 (<code class="docutils literal notranslate"><span class="pre">ApartmentStatusIndex</span></code>):</strong> Allows efficiently querying for alerts of a specific <code class="docutils literal notranslate"><span class="pre">Status</span></code> within a given <code class="docutils literal notranslate"><span class="pre">ApartmentID</span></code>.</p>
<ul>
<li><p><strong>Partition Key:</strong> <code class="docutils literal notranslate"><span class="pre">ApartmentID</span></code></p></li>
<li><p><strong>Sort Key:</strong> <code class="docutils literal notranslate"><span class="pre">Status</span></code></p></li>
</ul>
</li>
<li><p><strong>GSI-2 (<code class="docutils literal notranslate"><span class="pre">BuildingAlertsIndex</span></code>):</strong> Allows efficiently querying for all alerts in a <code class="docutils literal notranslate"><span class="pre">BuildingID</span></code>, sorted by time.</p>
<ul>
<li><p><strong>Partition Key:</strong> <code class="docutils literal notranslate"><span class="pre">BuildingID</span></code></p></li>
<li><p><strong>Sort Key:</strong> <code class="docutils literal notranslate"><span class="pre">AlertTimestamp</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="configuration-file-example">
<h4>Configuration File Example<a class="headerlink" href="#configuration-file-example" title="Permalink to this heading">¶</a></h4>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">feature_engineering</span><span class="p">:</span>
<span class="w">  </span><span class="nt">lookback_days</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">7</span>
<span class="w">  </span><span class="nt">weather_feature_cols</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;hdd&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;avg_temp_c&quot;</span><span class="p p-Indicator">]</span>

<span class="nt">training</span><span class="p">:</span>
<span class="w">  </span><span class="nt">model_strategy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;LR_LOF&quot;</span>
<span class="w">  </span><span class="nt">hyperparameters</span><span class="p">:</span>
<span class="w">    </span><span class="nt">lof_neighbors</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
<span class="w">    </span><span class="nt">lof_contamination</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
<span class="w">  </span><span class="nt">feature_columns</span><span class="p">:</span><span class="w"> </span><span class="c1"># List of features model actually uses</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">daily_energy_kwh</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">avg_temp_diff</span>
<span class="w">    </span><span class="c1"># ... etc</span>
<span class="w">  </span><span class="nt">instance_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;ml.m5.large&quot;</span>

<span class="nt">evaluation</span><span class="p">:</span>
<span class="w">  </span><span class="nt">metrics_thresholds</span><span class="p">:</span>
<span class="w">    </span><span class="nt">min_f1_score</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.6</span><span class="w"> </span><span class="c1"># Example if using labels</span>
<span class="w">    </span><span class="nt">max_throughput_deviation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span><span class="w"> </span><span class="c1"># Example</span>
<span class="w">  </span><span class="nt">holdout_data_path</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;s3://...&quot;</span><span class="w"> </span><span class="c1"># Path to specific eval data</span>

<span class="nt">inference</span><span class="p">:</span>
<span class="w">  </span><span class="nt">alert_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5.0</span>
<span class="w">  </span><span class="nt">batch_transform_instance_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;ml.m5.large&quot;</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="iot_forecasting.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Energy Demand Forecasting in Time Series IoT Data</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Past Experiences</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Deepak Karkala
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Anomaly Detection in Time Series IoT Data</a><ul>
<li><a class="reference internal" href="#id1"></a><ul>
<li><a class="reference internal" href="#tl-dr-predictive-maintenance-for-smart-heating-systems">TL;DR: Predictive Maintenance for Smart Heating Systems</a></li>
<li><a class="reference internal" href="#introduction">Introduction</a><ul>
<li><a class="reference internal" href="#purpose">Purpose</a></li>
<li><a class="reference internal" href="#business-goal">Business Goal</a></li>
<li><a class="reference internal" href="#key-technologies">Key Technologies</a></li>
</ul>
</li>
<li><a class="reference internal" href="#table-of-contents">Table of Contents</a></li>
<li><a class="reference internal" href="#discovery-and-scoping">Discovery and Scoping</a><ul>
<li><a class="reference internal" href="#use-case-evaluation">Use Case Evaluation</a></li>
<li><a class="reference internal" href="#product-strategies">Product Strategies</a></li>
<li><a class="reference internal" href="#features">Features</a></li>
<li><a class="reference internal" href="#product-requirements-document">Product Requirements Document</a></li>
<li><a class="reference internal" href="#development-stages">Development Stages</a></li>
</ul>
</li>
<li><a class="reference internal" href="#system-architecture">System Architecture</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#data-flow">Data Flow</a></li>
<li><a class="reference internal" href="#ingestion-workflow">Ingestion Workflow</a></li>
<li><a class="reference internal" href="#training-workflow">Training Workflow</a></li>
<li><a class="reference internal" href="#inference-workflow">Inference Workflow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-development-iteration">Model Development &amp; Iteration</a></li>
<li><a class="reference internal" href="#challenges-and-learnings">Challenges and learnings</a></li>
<li><a class="reference internal" href="#configuration-management">Configuration Management</a></li>
<li><a class="reference internal" href="#infrastructure-as-code-terraform">Infrastructure as Code (Terraform)</a></li>
<li><a class="reference internal" href="#ci-cd-pipeline-bitbucket">CI/CD Pipeline (Bitbucket)</a></li>
<li><a class="reference internal" href="#cost-analysis">Cost Analysis</a></li>
<li><a class="reference internal" href="#deployment-execution">Deployment &amp; Execution</a></li>
<li><a class="reference internal" href="#monitoring-alerting">Monitoring &amp; Alerting</a></li>
<li><a class="reference internal" href="#troubleshooting-guide">Troubleshooting Guide</a></li>
<li><a class="reference internal" href="#security-considerations">Security Considerations</a></li>
<li><a class="reference internal" href="#roadmap-future-enhancements">Roadmap &amp; Future Enhancements</a></li>
<li><a class="reference internal" href="#appendices">Appendices</a><ul>
<li><a class="reference internal" href="#data-schemas">Data Schemas</a></li>
<li><a class="reference internal" href="#raw-meter-data">1. Raw Meter Data</a></li>
<li><a class="reference internal" href="#processed-meter-data-for-anomaly-detection">2. Processed Meter Data (for Anomaly Detection)</a></li>
<li><a class="reference internal" href="#weather-data">3. Weather Data</a></li>
<li><a class="reference internal" href="#feature-store-features-anomaly-detection">4. Feature Store Features (Anomaly Detection)</a></li>
<li><a class="reference internal" href="#alert-table-schema-dynamodb">5. Alert Table Schema (DynamoDB)</a></li>
<li><a class="reference internal" href="#configuration-file-example">Configuration File Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=4e2eecee"></script>
    </body>
</html>