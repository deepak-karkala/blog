<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Real-Time Purchase Intent Scoring" href="ecom_propensity.html" /><link rel="prev" title="Reliability, Capacity, Maps" href="adas_engine/ch13_reliability_capacity_maps.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><!-- Generated with Sphinx 7.1.2 and Furo 2024.05.06 -->
        <title>Customer Lifetime Value - Home</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/style.css?v=8a7ff5ee" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Home</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">Home</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Past Experiences</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Past Experiences</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="iot_anomaly.html">Anomaly Detection in Time Series IoT Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="iot_forecasting.html">Energy Demand Forecasting in Time Series IoT Data</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="adas_engine/index.html">ADAS: Data Engine</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of ADAS: Data Engine</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch0_business_challenge.html">Business Challenge and Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch1_ml_problem_framing.html">ML Problem Framing</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch2_operational_strategy.html">Planning, Operational Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch3_pipelines_workflows.html">Workflows, Team, Roles</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch4_testing_strategy.html">Testing Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch6_data_ingestion_workflows.html">Data Ingestion Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch7_scene_understanding_data_mining.html">Scene Understanding &amp; Data Mining</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch8_model_training.html">Model Training &amp; Experimentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch9_packaging_promotion.html">Packaging, Evaluation &amp; Promotion Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch10_deployment_serving.html">Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch11_monitoring_continual_learning.html">Monitoring &amp; Continual Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch12_cost_lifecycle_compliance.html">Cost, Lifecycle, Compliance</a></li>
<li class="toctree-l3"><a class="reference internal" href="adas_engine/ch13_reliability_capacity_maps.html">Reliability, Capacity, Maps</a></li>
</ul>
</li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Customer Lifetime Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_propensity.html">Real-Time Purchase Intent Scoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_summarisation.html">Reviews Summarisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="ecom_rag.html">RAG-Based Product Discovery</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/index.html">Projects</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Projects</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/nlp/index.html">Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/airbnb_alternate_search/about/index.html">Airbnb Listing description based Semantic Search</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/cv/index.html">Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Computer Vision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/ecommerce_image_segmentation/about/index.html">Image Segmentation for Ecommerce Products</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://www.deepakkarkala.com/docs/articles/machine_learning/airbnb_price_modeling/about/index.html">Predictive Price Modeling for Airbnb listings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../publications/index.html">Patents, Papers, Thesis</a></li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../agents/index.html">AI Agents: A Lead Engineer’s Handbook</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of AI Agents: A Lead Engineer’s Handbook</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch1_intro.html">Agent Fundamentals: What, Why, and When?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch2_patterns.html">Agentic Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch5_context_engineering.html">Context Engineering for AI Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch6_case_studies.html">The State of the Industry: Insights from the Field</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch7_conclusion.html"><strong>Conclusion: The Lead Engineer’s Mental Model for Building Agents</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_cost.html">Cost Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_data.html">Data Management and Knowledge Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_deploy.html">Deployment and Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_guardrails.html">Guardrails</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_hitl.html">Human-in-the-Loop (HITL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_latency.html">Latency Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_llm.html">LLM – Prompts, Goals, and Persona</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_memory.html">Managing Agent Memory (Short-Term and Long-Term)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_monitor.html">Monitoring and Observability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_orchestration.html">Orchestration and Task Decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_prod.html">Production Challenges and Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_security.html">Securing AI Agents and Preventing Abuse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_tool.html">Tool Use and Integration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agents/ch_trust.html">Building Trustworthy and Ethical AI Agents</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mlops/index.html">MLOps</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of MLOps</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch1_problem_framing.html">ML Problem framing</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of ML Problem framing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch2_blueprint_operational_strategy.html">The MLOps Blueprint &amp; Operational Strategy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch2a_platform/index.html">ML Platforms</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of ML Platforms</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/ml_platforms.html">ML Platforms: How to</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/uber.html">Uber Michelangelo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/linkedin.html">LinkedIn DARWIN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/netflix.html">Netflix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/shopify.html">Shopify Merlin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/zomato.html">Zomato: Real-time ML</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/coveo.html">Coveo: MLOPs at reasonable scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/monzo.html">Monzo ML Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch2a_platform/didact.html">Didact AI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch3_project_planning/index.html">Project Planning</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Project Planning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/prd.html">Project Requirements Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/tech_stack.html">Tech Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/config_management.html">Config Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/pipeline_design.html">Pipeline Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/environment_strategy.html">Environment Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/cicd_branching_model.html">CI/CD Strategy and Branching Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/directory_structure.html">Directory Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/env_branchind_cicd_deployment.html">Environments, Branching, CI/CD, and Deployments Explained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch3_project_planning/project_management.html">Project Management for MLOps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch4_data_discovery/index.html">Data Sourcing, Discovery</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Data Sourcing, Discovery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/data_sourcing_discovery.html">Data Sourcing, Discovery &amp; Understanding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/ch4_project.html">Project-Trending Now: Implementing Web Scraping, Ingestion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/industry_case_studies.html">Data Discovery Platforms: Industry Case Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/facebook_nemo.html">Facebook: Nemo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/netflix_metacat.html">Netflix Metacat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/uber_databook.html">Uber Databook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch4_data_discovery/linkedin_datahub.html">LinkedIn Datahub</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch5_data_pipelines/index.html">Data Engineering, Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Data Engineering, Pipelines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/data_pipelines.html">Data Engineering for Reliable ML Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/data_engineering_pipelines.html">Data Engineering &amp; Pipelines: A Lead’s Compendium</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/streaming_pipelines.html">Real-Time &amp; Streaming Data Pipelines: Challenges, Solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/netflix_keystone.html">Netflix Keystone</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch5_data_pipelines/doordash_riviera.html">Doordash Riviera</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch6_feature_engg/index.html">Feature Engineering, Feature Stores</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Feature Engineering, Feature Stores</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/feature_engineering_store.html">Feature Engineering and Feature Stores</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/feature_engineering.html">Feature Engineering for MLOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/explained_feature_stores.html">Feature Stores for MLOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch6_feature_engg/point_in_time.html">Point-in-Time Correctness &amp; Time Travel in ML Data Pipelines</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/index.html">Feast Feature Store</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Feast Feature Store</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_architecture.html">Feast Architecture: A Technical Deep Dive for MLOps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_concepts.html">Feast Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_components.html">Feast Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_usecases.html">Feast Use Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/feast_aws.html">Running Feast with AWS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/run_in_prod.html">Running Feast in Production</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/validate_historical_with_gx.html">Validating Historical Features with Great Expectations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mlops/ch6_feature_engg/feast/add_reuse_tests.html">Adding or Reusing Tests in Feast</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch7_model_development/index.html">Model Development, Tuning, Selection, Ensembles, Calibration</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Model Development, Tuning, Selection, Ensembles, Calibration</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/ch7_model_development.html">Chapter 7: Model Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/dl_training_playbook.html">How to train DL Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/development.html">Model Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/industry_lessons.html">Model Development: Lessons from production systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/ensembles.html"><strong>Model Ensembles</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/selection.html">Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/tuning_hypopt.html">Hyperparameter Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/expt_tracking.html">ML Expt tracking, Data Lineage, Model Registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch7_model_development/calibration.html">Model Calibration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch8_ml_pipelines.html">ML Training Pipelines</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch9_ml_testing/index.html">Testing in ML Systems</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Testing in ML Systems</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/ch9_ml_testing.html">Testing in ML Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/data_testing_validation.html">Data Testing &amp; Validation in Production</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch9_ml_testing/ml_testing.html">Testing ML Systems: Ensuring Reliability from Code to Production</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch10_deployment_serving/index.html">Model Deployment &amp; Serving</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Model Deployment &amp; Serving</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/ch10_deployment_serving.html">Chapter 10: Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/guide_deployment_serving.html">Guide: Model Deployment &amp; Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch10_deployment_serving/guide_inference_stack.html">Deep Dive: Inference Stack</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/index.html">Monitoring, Observability, Drift, Interpretability</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Monitoring, Observability, Drift, Interpretability</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/ch11_monitor_observe_drift.html">Chapter 11: Monitoring, Observability, Drifts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_monitor_observe_drift.html">Guide: ML System Failures, Data Distribution Shifts, Monitoring, and Observability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_interpretability_shap_lime.html">Interpretability, SHAP, LIME</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch11_monitor_observe_drift/guide_stack.html">Prometheus + Grafana and ELK Stacks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/index.html">Continual learning, Retraining, A/B Testing</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Continual learning, Retraining, A/B Testing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/ch12_continual_learning_prod_testing.html">Chapter 12: Continual Learning &amp; Production Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_continual_learning.html">Continual Learning &amp; Model Retraining</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_ab_testing.html">A/B Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_ab_testing_industry_lessons.html">A/B Testing &amp; Experimentation: Industry lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/guide_prod_testing_expt.html">Guide: Production Testing &amp; Experimentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mlops/ch12_retrain_online_testing/dr_prod_testing_expt.html">Deep Research: Production Testing &amp; Experimentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/ch13_governance_ethics_human.html">Governance, Ethics &amp; The Human Element</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pytorch/index.html">PyTorch</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of PyTorch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/general.html">General</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/state_dict.html">state_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/distributed_data_parallel.html">Distributed Data Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/ddp_under_the_hood.html">DDP: Under the Hood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/dp_ddp.html">DP vs DDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/fsdp.html">FSDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/tensor_parallelism.html">Tensor parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/pipeline_parallelism.html">Pipeline Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/device_mesh.html">Device Mesh</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lld/index.html">Low Level Design</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Low Level Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../lld/parking_lot.html">Parking Lot</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../visualization/index.html">Data Visualization Projects</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/past_experiences/ecom_cltv.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="customer-lifetime-value">
<h1>Customer Lifetime Value<a class="headerlink" href="#customer-lifetime-value" title="Permalink to this heading">¶</a></h1>
<section id="how-i-built-a-customer-lifetime-value-model-for-an-e-commerce-business">
<h2>How I Built a Customer Lifetime Value Model for an E-commerce Business<a class="headerlink" href="#how-i-built-a-customer-lifetime-value-model-for-an-e-commerce-business" title="Permalink to this heading">¶</a></h2>
<hr class="docutils" />
<section id="tldr-building-a-production-grade-clv-prediction-system">
<h3><strong>TLDR: Building a Production-Grade CLV Prediction System</strong><a class="headerlink" href="#tldr-building-a-production-grade-clv-prediction-system" title="Permalink to this heading">¶</a></h3>
<p>This project details the end-to-end design and implementation of an automated MLOps system to predict Customer Lifetime Value (CLV) for a mid-sized e-commerce business.</p>
<section id="challenge">
<h4><strong>Challenge</strong><a class="headerlink" href="#challenge" title="Permalink to this heading">¶</a></h4>
<p>Our e-commerce business struggled to move beyond reactive marketing. We lacked a forward-looking way to identify high-value customers, leading to inefficient ad spend, generic campaigns, and missed retention opportunities. The core challenge was to build a system that could accurately predict future customer value, enabling a fundamental shift to data-driven, proactive personalization and budget allocation.</p>
</section>
<section id="my-role-solution">
<h4><strong>My Role &amp; Solution</strong><a class="headerlink" href="#my-role-solution" title="Permalink to this heading">¶</a></h4>
<p>As the <strong>ML Engineer and Data Scientist</strong> on a lean, three-person team (alongside a Product Manager and Data Engineer), I owned the design and implementation of the complete end-to-end MLOps system on AWS.</p>
<p>My solution involved architecting a series of automated, event-driven pipelines:</p>
<ul class="simple">
<li><p><strong>Data &amp; Feature Engineering:</strong> I built robust data ingestion and validation pipelines using <strong>AWS Glue</strong> and <strong>Great Expectations</strong>, and a scalable feature engineering pipeline with <strong>Spark on EMR</strong> to generate rich, time-aware customer features for the model.</p></li>
<li><p><strong>Model Development &amp; Training:</strong> I developed and iterated on the core <strong>XGBoost</strong> prediction model, established experiment tracking with <strong>MLflow</strong>, and designed the automated training and evaluation pipeline using <strong>SageMaker Pipelines</strong>. This included conditional model registration based on performance, fairness, and robustness checks.</p></li>
<li><p><strong>Deployment &amp; Operations:</strong> I then built the weekly <strong>batch inference pipeline</strong> using SageMaker Batch Transform and established a full-circle monitoring and observability stack with <strong>CloudWatch</strong> and <strong>SHAP</strong> for explainability to track data drift and model performance.</p></li>
<li><p><strong>Continual Learning &amp; Testing:</strong> Finally, I designed the continual learning framework with automated retraining triggers and a phased production testing strategy (<strong>Shadow Deployment</strong> and <strong>Canary Releases</strong>) to ensure the model evolves safely and effectively over time.</p></li>
</ul>
<p><strong>Tech Stack:</strong> AWS (SageMaker, S3, Glue, EMR, Kinesis, MWAA), Airflow, MLflow, DVC, Great Expectations, Spark, XGBoost, Terraform.</p>
</section>
<section id="impact">
<h4><strong>Impact</strong><a class="headerlink" href="#impact" title="Permalink to this heading">¶</a></h4>
<p>The system provided a significant, measurable lift by enabling proactive, data-informed marketing strategies. It moved our ML operations from a quarterly manual effort to a fully automated weekly cycle.</p>
<ul class="simple">
<li><p><strong>+18% Marketing ROI</strong> by focusing ad spend and promotions on predicted high-value customer segments.</p></li>
<li><p><strong>-12% Churn Rate</strong> in top-tier customer cohorts due to targeted, proactive retention campaigns.</p></li>
<li><p><strong>+7% Conversion Rate</strong> on marketing campaigns that used the CLV-based segments.</p></li>
<li><p><strong>95% Reduction in Manual Effort</strong> by fully automating the model lifecycle from data ingestion to retraining and deployment.</p></li>
</ul>
</section>
<section id="system-architecture">
<h4><strong>System Architecture</strong><a class="headerlink" href="#system-architecture" title="Permalink to this heading">¶</a></h4>
<p>The diagram below illustrates the complete MLOps system. The components within the highlighted area represent the core systems I personally designed and built.</p>
<img src="../_static/past_experiences/ecom_cltv/contributions.svg" style="background-color: #FCF1EF;"/>
</section>
</section>
<section id="the-business-challenge-moving-from-hindsight-to-foresight">
<h3>The Business Challenge: Moving from Hindsight to Foresight<a class="headerlink" href="#the-business-challenge-moving-from-hindsight-to-foresight" title="Permalink to this heading">¶</a></h3>
<p>The core challenge was to move beyond simple historical metrics and accurately predict the future <strong>Customer Lifetime Value (CLV)</strong>. We needed to transition from merely looking at past revenue to forecasting future profitability, enabling us to make smarter, data-driven decisions.</p>
<p>This initiative was driven by the need to answer critical business questions:</p>
<ul class="simple">
<li><p><strong>Optimized Customer Acquisition:</strong> How much should we strategically invest to acquire a new customer? Where can we find more prospects who resemble our current high-value customers?</p></li>
<li><p><strong>Personalized Retention:</strong> Which of our high-value customers are at risk of churning? How can we proactively and efficiently tailor retention efforts to keep them engaged?</p></li>
<li><p><strong>Smarter Budget Allocation:</strong> How should we allocate marketing spend, discounts, and promotions across different customer segments to maximize long-term return on investment (ROI)?</p></li>
</ul>
<p>The financial stakes were clear and compelling. Industry benchmarks show that:</p>
<ul class="simple">
<li><p>A <strong>5% increase</strong> in customer retention can boost profitability by <strong>25-95%</strong>.</p></li>
<li><p>It costs <strong>5 times more</strong> to acquire a new customer than to retain an existing one.</p></li>
<li><p>The probability of selling to an existing customer is <strong>60-70%</strong>, compared to just <strong>5-20%</strong> for a new prospect.</p></li>
</ul>
<p>The objective was to build a system that could reliably identify our most valuable customers—both existing and future—and empower the business to focus resources where they would generate the greatest impact.</p>
</section>
<hr class="docutils" />
<section id="problem-framing-translating-business-needs-into-a-technical-blueprint">
<h3>Problem Framing: Translating Business Needs into a Technical Blueprint<a class="headerlink" href="#problem-framing-translating-business-needs-into-a-technical-blueprint" title="Permalink to this heading">¶</a></h3>
<p>With a clear business objective, the next critical step is to translate that goal into a precise, solvable machine learning problem. This framing process dictates our data requirements, model choice, and ultimately, how the final output can be actioned by the business.</p>
<section id="is-machine-learning-the-right-approach">
<h4>Is Machine Learning the Right Approach?<a class="headerlink" href="#is-machine-learning-the-right-approach" title="Permalink to this heading">¶</a></h4>
<p>Before committing to a complex ML system, we first validated if it was necessary. While a simple heuristic like <code class="docutils literal notranslate"><span class="pre">(Average</span> <span class="pre">Order</span> <span class="pre">Value)</span> <span class="pre">x</span> <span class="pre">(Average</span> <span class="pre">Customer</span> <span class="pre">Lifespan)</span></code> provides a basic CLV estimate, it suffers from critical flaws:</p>
<ul class="simple">
<li><p>It treats all customers as a single, homogenous group, failing to capture individual behavior.</p></li>
<li><p>It cannot identify high-value customers at risk or differentiate between promising new users and those likely to make only a single purchase.</p></li>
</ul>
<p>ML is the ideal approach here because:</p>
<ul class="simple">
<li><p><strong>Complex Patterns:</strong> Customer purchasing and churn behavior is driven by intricate, non-linear patterns that are difficult to define with simple rules.</p></li>
<li><p><strong>Predictive Nature:</strong> The core task is forecasting future behavior, which is a strength of ML.</p></li>
<li><p><strong>Scale and Adaptation:</strong> ML can process data for millions of customers and can be retrained to adapt to evolving market trends and customer habits.</p></li>
</ul>
</section>
<section id="defining-the-core-ml-task-from-business-goals-to-a-predictive-model">
<h4>Defining the Core ML Task: From Business Goals to a Predictive Model<a class="headerlink" href="#defining-the-core-ml-task-from-business-goals-to-a-predictive-model" title="Permalink to this heading">¶</a></h4>
<p>We framed this challenge primarily as a <strong>regression problem</strong>. This was a strategic choice to provide the most direct and actionable output for our business stakeholders.</p>
<ul class="simple">
<li><p><strong>Model Input:</strong> A rich set of features for each customer, calculated up to a specific “cutoff date” (e.g., today). This includes:</p>
<ul>
<li><p><strong>RFM Features:</strong> Recency, Frequency, and Monetary value.</p></li>
<li><p><strong>Purchase Pattern Features:</strong> Average time between orders, product diversity, return rates.</p></li>
<li><p><strong>Temporal Features:</strong> Spend and activity aggregated over rolling time windows (e.g., last 30, 90, 365 days).</p></li>
<li><p><strong>Engagement Features:</strong> Non-transactional data like website visits, session duration, and email click-through rates.</p></li>
</ul>
</li>
<li><p><strong>Model Output:</strong> A continuous numerical value representing the <strong>predicted total revenue a customer will generate in the next 12 months.</strong></p></li>
</ul>
<p>While regression was our primary task, we recognized its sensitivity to outliers (a few “whale” customers). Therefore, we also designed the system to support a secondary <strong>classification</strong> output, bucketing customers into ‘Low’, ‘Medium’, and ‘High’ value tiers. This provides an intuitive and robust output for marketing segmentation, complementing the precise financial forecast from the regression model.</p>
</section>
<section id="assessing-feasibility-risks-can-we-execute-this-vision">
<h4>Assessing Feasibility &amp; Risks (Can We Execute This Vision?)<a class="headerlink" href="#assessing-feasibility-risks-can-we-execute-this-vision" title="Permalink to this heading">¶</a></h4>
<p>Before committing to development, we conducted a rigorous feasibility assessment to identify potential risks and ensure the project was grounded in reality.</p>
<ul class="simple">
<li><p><strong>Data Feasibility:</strong></p>
<ul>
<li><p><strong>Availability:</strong> While core transactional data was abundant, integrating it with often sparse or inconsistent CRM and web behavioral data posed a significant data engineering challenge.</p></li>
<li><p><strong>Quality &amp; Privacy:</strong> We identified a need for robust data cleaning and validation pipelines. Handling Personally Identifiable Information (PII) under regulations like GDPR was a top priority, requiring careful data anonymization and governance.</p></li>
</ul>
</li>
<li><p><strong>Modeling &amp; Technical Feasibility:</strong></p>
<ul>
<li><p><strong>Problem Complexity:</strong> The core challenge was not the algorithm itself, but modeling the dynamic, non-stationary nature of customer behavior (i.e., concept drift). Customer tastes and spending habits change over time.</p></li>
<li><p><strong>Latency Requirements:</strong> Our primary use case (batch scoring for marketing campaigns) had relaxed latency needs. However, we acknowledged that a future real-time personalization use case would require building a more complex low-latency serving infrastructure and an online feature store.</p></li>
<li><p><strong>Interpretability:</strong> Gaining business trust was paramount. “Black box” predictions were unacceptable, making model explainability (e.g., using SHAP) a mandatory requirement to understand <em>why</em> a customer was flagged as high-value.</p></li>
</ul>
</li>
<li><p><strong>Business &amp; Operational Risks:</strong></p>
<ul>
<li><p><strong>Cost of Errors:</strong> The model’s predictions have a direct financial impact. Over-predicting CLV leads to wasted marketing spend, while under-predicting results in missed revenue opportunities from high-potential customers.</p></li>
<li><p><strong>Ethical Considerations:</strong> We identified a risk of creating negative feedback loops. If the model were biased against a certain customer segment, we might under-invest in them, reinforcing the initial bias. This required a commitment to continuous fairness monitoring.</p></li>
<li><p><strong>ROI Justification:</strong> The project required a significant upfront investment in data engineering and MLOps. However, the potential ROI—driven by more efficient marketing, improved retention, and higher long-term profitability—was substantial and clearly justified the investment.</p></li>
</ul>
</li>
</ul>
</section>
<section id="defining-success-from-technical-metrics-to-business-impact">
<h4>Defining Success: From Technical Metrics to Business Impact<a class="headerlink" href="#defining-success-from-technical-metrics-to-business-impact" title="Permalink to this heading">¶</a></h4>
<p>A model can be technically “correct” but fail to deliver business value. Therefore, we defined two distinct sets of success criteria:</p>
<ol class="arabic simple">
<li><p><strong>Model Evaluation Metrics (Offline):</strong> These are technical metrics used to assess the model’s performance on a held-out test dataset.</p>
<ul class="simple">
<li><p><strong>Primary Metrics:</strong> For our regression task, we used standard metrics like <strong>Root Mean Squared Error (RMSE)</strong> and <strong>Mean Absolute Error (MAE)</strong>.</p></li>
<li><p><strong>Business-Oriented Metric:</strong> Critically, we also used the <strong>Gini Coefficient</strong> and plotted the <strong>Lorenz Curve</strong>. This measures the model’s ability to accurately <em>rank</em> customers from least to most valuable, which is essential for targeting the top percentile of customers.</p></li>
<li><p><strong>Fairness Check:</strong> We evaluated performance across key customer segments (e.g., by acquisition channel, geography) to ensure the model wasn’t unfairly penalizing or misjudging a specific group.</p></li>
</ul>
</li>
<li><p><strong>Business Success Metrics (Online):</strong> These are the real-world KPIs we aimed to influence after deploying the model.</p>
<ul class="simple">
<li><p>Increase ROI on marketing spend by targeting high-CLV prospects.</p></li>
<li><p>Reduce churn rate among customers predicted to be high-value.</p></li>
<li><p>Increase average order value and purchase frequency through personalized upselling campaigns aimed at specific CLV tiers.</p></li>
</ul>
</li>
</ol>
<p>This dual-metric approach ensures our technical work remains directly tethered to tangible business outcomes.</p>
</section>
</section>
<hr class="docutils" />
<section id="mlops-end-to-end-project-planning-and-operational-strategy">
<h3>MLOps End-to-End Project Planning and Operational Strategy<a class="headerlink" href="#mlops-end-to-end-project-planning-and-operational-strategy" title="Permalink to this heading">¶</a></h3>
<p>A successful machine learning project is built on a foundation of solid engineering and operational planning. It’s not enough to build an accurate model; we must build a <em>reliable system</em> that can consistently deliver value. This section outlines the technical architecture, core workflows, and project management strategy for bringing the CLV prediction model to production.</p>
<section id="tech-stack">
<h4>Tech Stack<a class="headerlink" href="#tech-stack" title="Permalink to this heading">¶</a></h4>
<p>The technology stack was chosen to balance the power of best-in-class open-source tools with the scalability and manageability of a leading cloud provider (AWS). The primary goal was to create a robust, automated, and repeatable system.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Component</p></th>
<th class="head text-left"><p>Chosen Tool/Framework</p></th>
<th class="head text-left"><p>Rationale &amp; Key Trade-offs</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Cloud Platform</strong></p></td>
<td class="text-left"><p>Amazon Web Services (AWS)</p></td>
<td class="text-left"><p>A mature and comprehensive ecosystem of managed services for data and ML, allowing the team to focus on business logic rather than undifferentiated infrastructure management.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Data Lake &amp; Storage</strong></p></td>
<td class="text-left"><p>Amazon S3 &amp; Parquet</p></td>
<td class="text-left"><p>S3 provides virtually limitless, cost-effective, and durable object storage. Storing data in the open-source Parquet format ensures high performance and interoperability.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Data Versioning</strong></p></td>
<td class="text-left"><p>DVC (Data Version Control)</p></td>
<td class="text-left"><p>While Git is excellent for code, it’s not designed for large data files. DVC integrates with Git to provide versioning for datasets, making our data pipelines fully reproducible.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Workflow Orchestration</strong></p></td>
<td class="text-left"><p>Apache Airflow (on AWS MWAA)</p></td>
<td class="text-left"><p>The industry standard for orchestrating complex, dependency-aware workflows. While it has a learning curve, its power and flexibility are unmatched for managing our multi-step data and ML pipelines. AWS MWAA provides a managed service offering.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Data Processing</strong></p></td>
<td class="text-left"><p>Apache Spark (on AWS EMR)</p></td>
<td class="text-left"><p>The de facto standard for large-scale, distributed data transformation. Essential for efficiently computing customer-level RFM features and other aggregations across the entire dataset.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Feature Store</strong></p></td>
<td class="text-left"><p>Amazon SageMaker Feature Store</p></td>
<td class="text-left"><p>Chosen to solve the critical challenge of training-serving skew. It provides a central, governed repository for features, ensuring consistency between our training and inference pipelines and promoting feature reusability across future projects.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Experiment Tracking</strong></p></td>
<td class="text-left"><p>MLflow Tracking</p></td>
<td class="text-left"><p>A powerful open-source tool for logging and comparing all aspects of ML experiments (parameters, metrics, artifacts). It fosters a rigorous, scientific approach to model development.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Model Registry</strong></p></td>
<td class="text-left"><p>MLflow Model Registry</p></td>
<td class="text-left"><p>Provides a central, version-controlled repository for our trained model artifacts. It’s the critical hand-off point between model training and deployment, enabling robust governance and auditability.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>CI/CD Automation</strong></p></td>
<td class="text-left"><p>GitHub Actions</p></td>
<td class="text-left"><p>A modern, flexible CI/CD tool that integrates seamlessly with our source code repository on GitHub, allowing us to automate testing and deployment workflows.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Infrastructure as Code</strong></p></td>
<td class="text-left"><p>Terraform</p></td>
<td class="text-left"><p>The cloud-agnostic standard for defining and managing infrastructure programmatically. This ensures our environments are reproducible, version-controlled, and can be easily provisioned or torn down.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Model Deployment</strong></p></td>
<td class="text-left"><p>Amazon SageMaker Batch Transform</p></td>
<td class="text-left"><p>For our primary use case (weekly scoring of the customer base), batch inference is the most cost-effective and operationally simple deployment pattern. SageMaker provides a fully managed solution.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Monitoring</strong></p></td>
<td class="text-left"><p>Amazon SageMaker Model Monitor &amp; CloudWatch</p></td>
<td class="text-left"><p>SageMaker Model Monitor provides built-in capabilities to detect data and model quality drift. CloudWatch is used for monitoring the health and performance of all underlying AWS infrastructure.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="list-of-core-pipelines-workflows">
<h4>List of Core Pipelines/Workflows<a class="headerlink" href="#list-of-core-pipelines-workflows" title="Permalink to this heading">¶</a></h4>
<p>The entire MLOps system is composed of several distinct, automated pipelines, orchestrated by Airflow.</p>
<ol class="arabic simple">
<li><p><strong>Data Ingestion &amp; Validation Pipeline</strong></p>
<ul class="simple">
<li><p><strong>Trigger:</strong> Daily scheduled run.</p></li>
<li><p><strong>Inputs:</strong> Connection details for source transactional databases and CRM systems.</p></li>
<li><p><strong>Key Steps:</strong></p>
<ol class="arabic simple">
<li><p>Extract raw transactional and customer data from source systems.</p></li>
<li><p>Validate incoming data against a predefined schema and quality rules (using libraries like Great Expectations).</p></li>
<li><p>Land the validated, raw data in the S3 Data Lake.</p></li>
<li><p>Update the data catalog and trigger the Feature Engineering Pipeline.</p></li>
</ol>
</li>
<li><p><strong>Outputs:</strong> Versioned, validated raw data in S3.</p></li>
</ul>
</li>
<li><p><strong>Feature Engineering Pipeline</strong></p>
<ul class="simple">
<li><p><strong>Trigger:</strong> Successful completion of the Data Ingestion Pipeline.</p></li>
<li><p><strong>Inputs:</strong> Raw customer and transaction data from the S3 Data Lake.</p></li>
<li><p><strong>Key Steps:</strong></p>
<ol class="arabic simple">
<li><p>Launch a Spark job (on EMR) to perform customer-level aggregations.</p></li>
<li><p>Calculate RFM features, rolling time-window features, and other behavioral signals.</p></li>
<li><p>Populate (or update) the SageMaker Feature Store with the newly computed features.</p></li>
</ol>
</li>
<li><p><strong>Outputs:</strong> Updated and versioned features in the offline and online feature stores.</p></li>
</ul>
</li>
<li><p><strong>Model Training, Evaluation &amp; Registration Pipeline</strong></p>
<ul class="simple">
<li><p><strong>Trigger:</strong> Weekly scheduled run or on-demand by an ML engineer.</p></li>
<li><p><strong>Inputs:</strong> Features from the SageMaker Feature Store, model training configuration.</p></li>
<li><p><strong>Key Steps:</strong></p>
<ol class="arabic simple">
<li><p>Create a temporally correct training/test data split.</p></li>
<li><p>Train the CLV model (XGBoost) using the training data.</p></li>
<li><p>Evaluate the model on the test set using both technical (RMSE, MAE) and business-aligned (Gini Coefficient) metrics.</p></li>
<li><p>Compare the new model’s performance to the currently deployed production model.</p></li>
<li><p>If performance exceeds the threshold, register the new model version in the MLflow Model Registry with its associated metrics and artifacts.</p></li>
</ol>
</li>
<li><p><strong>Outputs:</strong> A newly registered model in MLflow, ready for deployment.</p></li>
</ul>
</li>
<li><p><strong>Batch Inference Pipeline</strong></p>
<ul class="simple">
<li><p><strong>Trigger:</strong> Weekly scheduled run, following the successful completion of the training pipeline.</p></li>
<li><p><strong>Inputs:</strong> The latest “approved for production” model from the MLflow Registry and a list of all active customers.</p></li>
<li><p><strong>Key Steps:</strong></p>
<ol class="arabic simple">
<li><p>Initiate a SageMaker Batch Transform job.</p></li>
<li><p>For each customer, retrieve the latest features from the SageMaker Feature Store.</p></li>
<li><p>Generate a 12-month CLV prediction.</p></li>
<li><p>Load the predictions into the downstream data warehouse and CRM system for use by business teams.</p></li>
</ol>
</li>
<li><p><strong>Outputs:</strong> Updated CLV scores for every customer in the business intelligence and marketing platforms.</p></li>
</ul>
</li>
</ol>
</section>
<section id="project-management-and-stages">
<h4>Project Management and Stages<a class="headerlink" href="#project-management-and-stages" title="Permalink to this heading">¶</a></h4>
<p>We adopted an iterative, phased approach to manage the project, ensuring we built a solid foundation before adding complexity.</p>
<ol class="arabic simple">
<li><p><strong>Ideation &amp; Planning (Weeks 1-2)</strong></p>
<ul class="simple">
<li><p>Align with business stakeholders on the primary goals and define success metrics.</p></li>
<li><p>Conduct the Problem Framing and Feasibility assessment.</p></li>
<li><p>Define the MLOps tech stack and high-level architecture.</p></li>
<li><p>Establish the cross-functional team and define roles.</p></li>
</ul>
</li>
<li><p><strong>Model Experimentation &amp; Baseline (Weeks 3-6)</strong></p>
<ul class="simple">
<li><p>Perform deep Exploratory Data Analysis (EDA) on the integrated dataset.</p></li>
<li><p>Engineer an initial set of robust RFM features.</p></li>
<li><p>Develop a simple baseline model (e.g., Linear Regression) to establish a performance floor.</p></li>
<li><p>Experiment with more advanced models (XGBoost) and track all runs in MLflow.</p></li>
<li><p>Conduct rigorous offline evaluation to select the champion model architecture.</p></li>
</ul>
</li>
<li><p><strong>End-to-End Pipeline Development (Weeks 7-12)</strong></p>
<ul class="simple">
<li><p>Develop the four core automated pipelines (Ingestion, Feature Engineering, Training, Batch Inference) as code.</p></li>
<li><p>Write Infrastructure as Code (Terraform) to provision the required AWS resources.</p></li>
<li><p>Implement robust unit and integration tests for all pipeline components.</p></li>
<li><p>Set up CI/CD workflows in GitHub Actions.</p></li>
</ul>
</li>
<li><p><strong>Deployment &amp; Serving (Week 13)</strong></p>
<ul class="simple">
<li><p>Deploy the production environment using Terraform.</p></li>
<li><p>Execute the first full run of the Batch Inference Pipeline in a staging environment.</p></li>
<li><p>Validate the output and, upon approval, promote to production.</p></li>
<li><p>Integrate the output CLV scores with downstream CRM and BI dashboards.</p></li>
</ul>
</li>
<li><p><strong>Monitoring &amp; Iteration (Ongoing)</strong></p>
<ul class="simple">
<li><p>Establish monitoring dashboards for infrastructure health and data/model drift.</p></li>
<li><p>Set up automated alerts for any detected anomalies.</p></li>
<li><p>Establish a formal A/B testing framework to evaluate the business impact of future model versions.</p></li>
<li><p>Schedule periodic reviews of model performance and plan for retraining and future iterations.</p></li>
</ul>
</li>
</ol>
</section>
<section id="cross-functional-team-roles">
<h4>Cross-Functional Team &amp; Roles<a class="headerlink" href="#cross-functional-team-roles" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>ML Engineer:</strong> Led the overall technical design, developed the core ML pipelines, and implemented the CI/CD and monitoring systems.</p></li>
<li><p><strong>Data Engineer:</strong> Focused on building the robust data ingestion and validation pipelines from source systems and owned the data model in the lake.</p></li>
<li><p><strong>Business Analyst/Product Manager:</strong> Acted as the crucial link to business stakeholders, defining requirements, interpreting model outputs, and designing how the CLV scores would be used in marketing campaigns.</p></li>
</ul>
</section>
<section id="versioning-and-governance-strategy">
<h4>Versioning and Governance Strategy<a class="headerlink" href="#versioning-and-governance-strategy" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Code:</strong> All code (pipeline definitions, feature logic, model training scripts, IaC) is versioned in <strong>Git</strong>.</p></li>
<li><p><strong>Data:</strong> Large datasets and feature sets are versioned using <strong>DVC</strong>, with pointers checked into Git.</p></li>
<li><p><strong>Models:</strong> Every trained model is versioned and governed through the <strong>MLflow Model Registry</strong>, creating an auditable lineage from a prediction back to the exact code and data that produced it.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="data-sourcing-and-discovery">
<h3>Data Sourcing and Discovery<a class="headerlink" href="#data-sourcing-and-discovery" title="Permalink to this heading">¶</a></h3>
<p>The most sophisticated model is only as good as the data it’s trained on. For our CLV project, the initial and most critical phase was to source, understand, and validate the diverse datasets that capture the complete customer journey. This foundational work is the “mise en place” of our entire MLOps system—everything must be meticulously prepared before we begin modeling.</p>
<p>Following a structured framework, here is how we approached the data lifecycle for this project:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Framework Step</p></th>
<th class="head text-left"><p>Application to the CLV Project</p></th>
<th class="head text-left"><p>Key Rationale &amp; Chosen Tools</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>1. Identifying Data Requirements</strong></p></td>
<td class="text-left"><p>To predict future value, we needed a holistic customer view. <strong>Transactional Data:</strong> Order history, product details, prices, discounts. <br> • <strong>Customer/CRM Data:</strong> Demographics, acquisition channel, loyalty status. <br> • <strong>Behavioral Data:</strong> Web/app session logs, clicks, page views, and cart activity.</p></td>
<td class="text-left"><p>Transactional data is essential for baseline RFM features. CRM and behavioral data provide the rich, nuanced signals needed for a high-performance machine learning model to outperform simple heuristics.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>2. Exploring Data Sources</strong></p></td>
<td class="text-left"><p>• <strong>Production OLTP Database (PostgreSQL/MySQL):</strong> Source for real-time transactional data. <br> • <strong>CRM System (e.g., Salesforce):</strong> Source for customer demographic and marketing data. <br> • <strong>Event Streaming Platform :</strong> Source for high-volume behavioral data.</p></td>
<td class="text-left"><p>We tapped directly into the systems of record, ensuring data authenticity. The challenge was not finding data but integrating these disparate, siloed sources into a unified view.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>3. Data Collection &amp; Ingestion</strong></p></td>
<td class="text-left"><p>We established a <strong>daily batch ingestion</strong> strategy. <br> • An <strong>Airflow DAG</strong> extracts data from the production DB replica and CRM. <br> • Data is landed in its raw format in our <strong>AWS S3 Data Lake</strong>. <br> • Raw datasets are versioned using <strong>DVC</strong> to ensure every pipeline run is reproducible.</p></td>
<td class="text-left"><p>For CLV, daily batch processing provides sufficient data freshness while being more cost-effective and operationally simpler than a real-time streaming architecture.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>4. Exploratory Data Analysis (EDA)</strong></p></td>
<td class="text-left"><p>Before any feature engineering, we performed a thorough EDA in Jupyter notebooks. We focused on: <br> • Profiling RFM distributions to understand purchasing rhythms. <br> • Visualizing sales trends to identify seasonality. <br> • Quantifying data quality issues like missing <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code>s or negative <code class="docutils literal notranslate"><span class="pre">UnitPrice</span></code> values (returns).</p></td>
<td class="text-left"><p>This crucial step prevented a “garbage in, garbage out” scenario. It allowed us to identify data quality rules for our validation pipeline and informed our feature engineering strategy by uncovering key patterns and outliers.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>5. Data Documentation &amp; Discovery</strong></p></td>
<td class="text-left"><p>• Used the <strong>AWS Glue Data Catalog</strong> to make our S3 data lake’s schema discoverable and queryable via Athena. <br> • Created documentation (“Data Cards”) for key datasets, defining their schema, ownership, and update frequency.</p></td>
<td class="text-left"><p>A central catalog is critical for governance, trust, and enabling other teams to discover and reuse these valuable, curated data assets.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>6. Early Governance &amp; Security</strong></p></td>
<td class="text-left"><p>Given the sensitivity of customer data, governance was a day-one priority. <br> • We defined strict <strong>AWS IAM policies</strong> to enforce least-privilege access to S3 buckets. <br> • We created a PII (Personally Identifiable Information) transformation step in our data pipeline to hash or mask sensitive fields. <br> • We established clear data retention policies.</p></td>
<td class="text-left"><p>Security and privacy are non-negotiable. Building these governance controls directly into our data pipelines ensures compliance and builds trust with both our customers and internal stakeholders.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<!--
#### Data Characteristics

**Assumptions for this profile:**

*   **Company Size:** A multi-category retailer with an established online presence.
*   **Customer Base:** Approximately 1 million active customers.
*   **Daily Orders (Average):** ~4,000-6,000 orders per day. This can spike 3-5x during peak seasons (e.g., Black Friday, Christmas).
*   **Conversion Rate:** Assumed to be around 2%. This implies roughly 250,000 web sessions per day on average.

Here are the estimated data profiles in table format:

| Data Type | Daily Volume (Average) | Data Velocity | Data Profile & Governance Notes |
| :--- | :--- | :--- | :--- |
| **Transactional Data** | **50 - 200 MB per day.** <br>This includes new orders, returns, payments, and shipping status updates. | **Near Real-Time Events, Batch Processed.** <br>Individual transactions occur in real-time, but for analytics, this data is typically ingested in hourly or daily batches. | **Highly Structured.** <br>Consists of tables with well-defined schemas (`order_id`, `customer_id`, `sku`, `price`, `timestamp`). <br>**Governance:** Subject to financial auditing standards. Must handle multiple European currencies (€, £, CHF, etc.). GDPR compliance is critical for any customer-linked data. |
| **Customer / CRM Data** | **< 100 MB per day.** <br>Primarily updates to existing customer profiles and a smaller number of new customer sign-ups. | **Low / On-Change.** <br>Data changes are infrequent. Typically synchronized via daily batch jobs from the CRM system to the data lake. | **Highly Structured & Sensitive.** <br>Contains Personally Identifiable Information (PII) like names, emails, and physical addresses. <br>**Governance:** Strict GDPR rules apply. Must support data access, modification, and the "right to be forgotten." PII must be masked or hashed in analytical environments. |
| **Behavioral (Clickstream) Data** | **4 - 8 GB per day.** <br>This is the highest volume data, generated by user interactions on the website and mobile app. (Based on ~250k sessions/day with ~10 events/session). | **High-Velocity Event Streams.** <br>Data is generated continuously as users browse. Captured by event tracking platforms and ingested in near real-time. | **Semi-Structured (JSON).** <br>Events include `page_view`, `add_to_cart`, `search_query`, `product_view`. Contains anonymous `session_id` and `customer_id` (if logged in). <br>**Governance:** Requires explicit user consent for cookie-based tracking under GDPR. Data must be sessionized to reconstruct user journeys. |

-->
</section>
<section id="data-engineering-and-pipelines-building-the-foundation-for-accurate-predictions">
<h3>Data Engineering and Pipelines: Building the Foundation for Accurate Predictions<a class="headerlink" href="#data-engineering-and-pipelines-building-the-foundation-for-accurate-predictions" title="Permalink to this heading">¶</a></h3>
<p>The reliability of our entire CLV prediction system rests on the quality of its data foundation. This “mise en place” stage involves transforming raw, disparate data into clean, validated, and feature-rich inputs ready for model training. This is not a one-off task but a system of automated, repeatable, and robust pipelines.</p>
<p>Here’s how we applied core data engineering principles to build the data backbone for our CLV project:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Framework Step</p></th>
<th class="head text-left"><p>Application to the CLV Project</p></th>
<th class="head text-left"><p>Key Rationale &amp; Chosen Tools</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>1. Designing Data Processing Workflows</strong></p></td>
<td class="text-left"><p>The primary workflow is an <strong>ELT (Extract, Load, Transform)</strong> process. Raw data is extracted daily and loaded into the S3 data lake. Transformations and feature calculations are then performed as a separate, downstream step using Spark. The workflow is designed to be <strong>modular</strong> (Ingestion -&gt; Validation -&gt; Feature Engineering) and <strong>idempotent</strong>, ensuring that rerunning a pipeline on the same raw data produces the identical feature set.</p></td>
<td class="text-left"><p>An ELT approach leverages the power of the cloud data lake and a distributed engine like Spark, offering more flexibility than a rigid ETL process. Modularity and idempotency are core principles for building resilient, testable, and maintainable data pipelines that can recover from transient failures.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>2. Data Cleaning &amp; Wrangling</strong></p></td>
<td class="text-left"><p>Our automated pipeline systematically addresses data quality issues identified during EDA: <br>• <strong>Handling Nulls:</strong> Rows with a missing <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code> are discarded as they are unusable for CLV. <br>• <strong>Handling Returns:</strong> Transactions with negative <code class="docutils literal notranslate"><span class="pre">Quantity</span></code> or <code class="docutils literal notranslate"><span class="pre">UnitPrice</span></code> are processed to correctly adjust customer spending totals, preventing data contamination. <br>• <strong>Outlier Treatment:</strong> Extreme monetary values (e.g., transactions &gt; €50,000), which can skew model training, are automatically capped at a predefined threshold based on the 99.9th percentile of the training data.</p></td>
<td class="text-left"><p>This automated cleaning is the first line of defense for data quality. Explicitly handling outliers is crucial for regression models, which are highly sensitive to extreme values. These steps ensure that the data entering our feature engineering process is clean and consistent.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>3. Data Transformation &amp; Standardization</strong></p></td>
<td class="text-left"><p>To prepare data for the model, our pipeline performs two key transformations using a saved <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> Pipeline object: <br>• <strong>Standardization:</strong> Numerical features like <code class="docutils literal notranslate"><span class="pre">Monetary</span> <span class="pre">Value</span></code> and <code class="docutils literal notranslate"><span class="pre">Frequency</span></code> are scaled using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>. <br>• <strong>Encoding:</strong> Categorical features like <code class="docutils literal notranslate"><span class="pre">Acquisition</span> <span class="pre">Channel</span></code> are converted into numerical format using <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code>. <br>Crucially, the scaler and encoder are <strong>fit only on the training dataset</strong> and then saved as versioned artifacts.</p></td>
<td class="text-left"><p>Most machine learning algorithms perform better when numerical input features are on a standard scale. The “fit on train, transform on all” approach is a fundamental best practice to <strong>prevent data leakage</strong> from the test set into the training process, which would lead to overly optimistic and unrealistic performance metrics.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>4. Programmatic Data Labeling</strong></p></td>
<td class="text-left"><p>For our regression task, the target “label” is not manually created but <strong>programmatically generated</strong>. The pipeline calculates the ground truth for each customer by summing their total revenue in the 12 months <em>following</em> the specified cutoff date. This ensures a consistent and objective definition of the value we aim to predict.</p></td>
<td class="text-left"><p>There is no ambiguity in our target variable, removing the need for costly and slow human-in-the-loop labeling. This programmatic approach makes the entire label generation process fast, scalable, and perfectly reproducible.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>5. Data Splitting &amp; Sampling</strong></p></td>
<td class="text-left"><p>The pipeline enforces a strict <strong>temporal data split</strong>. To evaluate model performance, we train the model on one period (e.g., Months 1-9) and test it on a subsequent, unseen period (e.g., predictions for Months 10-12). We do not perform any over- or under-sampling on the test set to ensure it reflects the true distribution of customers in the real world.</p></td>
<td class="text-left"><p>This is the only correct way to validate a time-dependent forecasting model. Using a random split would leak information from the future into the training process, yielding a model that performs deceptively well in tests but fails in production.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>6. Data Validation as a Pipeline Stage</strong></p></td>
<td class="text-left"><p>We integrated <strong>Great Expectations</strong> as a dedicated validation task within our Airflow DAG. This task runs after data ingestion and before feature engineering. Key checks include: <code class="docutils literal notranslate"><span class="pre">expect_column_values_to_not_be_null</span></code> for <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code> and <code class="docutils literal notranslate"><span class="pre">expect_column_mean_to_be_between</span></code> for <code class="docutils literal notranslate"><span class="pre">Monetary</span> <span class="pre">Value</span></code> to detect significant data drift. A failure in this stage <strong>halts the entire pipeline</strong> and triggers an alert.</p></td>
<td class="text-left"><p>This automated quality gate is critical for building trust and reliability. It prevents “bad data” from silently propagating downstream, which is a common and costly source of production ML failures. It acts as a data contract, ensuring the data adheres to our expectations before we invest compute resources in processing it.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>7. Data Versioning &amp; Lineage</strong></p></td>
<td class="text-left"><p>Every dataset is versioned. <br>• <strong>DVC</strong> tracks the versions of our S3-based datasets. <br>• The Git commit hash versions the code. <br>• <strong>MLflow</strong> logs the specific DVC hash of the data used for each training run. This creates an immutable link between a model artifact, the code that generated it, and the precise version of the data it was trained on.</p></td>
<td class="text-left"><p>This practice provides complete, end-to-end lineage. If a model behaves unexpectedly in production, we can trace its exact origins, making debugging and auditing straightforward and reliable. It turns reproducibility from a manual best practice into a guaranteed property of the system.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>8. Orchestration &amp; Execution</strong></p></td>
<td class="text-left"><p>The entire multi-step data workflow is defined as a <strong>Directed Acyclic Graph (DAG)</strong> in <strong>Apache Airflow</strong>. Airflow manages the scheduling, dependencies (e.g., validation must complete before feature engineering begins), error handling, and retries for the entire data engineering process. Each complex step is containerized to ensure a consistent execution environment.</p></td>
<td class="text-left"><p>Using a dedicated orchestrator like Airflow transforms a collection of separate scripts into a single, robust, and observable system. It provides the operational control and visibility necessary to manage a production-grade data pipeline, which is far superior to relying on simple cron jobs.</p></td>
</tr>
</tbody>
</table>
</div>
<section id="planning-the-data-ingestion-pipeline">
<h4>Planning the Data Ingestion Pipeline<a class="headerlink" href="#planning-the-data-ingestion-pipeline" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Python Scripts (<code class="docutils literal notranslate"><span class="pre">src/</span></code>):</strong> For the core business logic.</p></li>
<li><p><strong>Unit Tests (<code class="docutils literal notranslate"><span class="pre">tests/</span></code>):</strong> To ensure the correctness of the Python scripts.</p></li>
<li><p><strong>Pipeline Code (<code class="docutils literal notranslate"><span class="pre">pipelines/</span></code>):</strong> The Airflow DAGs that define the workflow.</p></li>
<li><p><strong>Infrastructure as Code (<code class="docutils literal notranslate"><span class="pre">terraform/</span></code>):</strong> To provision the necessary AWS resources.</p></li>
<li><p><strong>Integration Tests (<code class="docutils literal notranslate"><span class="pre">tests/</span></code>):</strong> To verify that the different components and services work together as expected.</p></li>
<li><p><strong>Architecture Diagram:</strong> Essential for documentation and team alignment.</p></li>
</ul>
<p>Now, let’s address your excellent question about the choice of tooling.</p>
</section>
<section id="tool-compute-choice-spark-emr-vs-other-frameworks">
<h4>Tool &amp; Compute Choice: Spark/EMR vs. Other Frameworks<a class="headerlink" href="#tool-compute-choice-spark-emr-vs-other-frameworks" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>For Transactional Data (Pipeline 1):</strong> The daily volume (50-200 MB) is relatively small. Spinning up an EMR cluster (which can take several minutes and incurs costs for the duration it’s running) just to process this amount of data is inefficient and not cost-effective.</p>
<ul class="simple">
<li><p><strong>Better Choice: AWS Glue.</strong> Glue is a serverless ETL service on AWS. You only pay for the resources consumed during the job run, with no cluster management overhead. It is perfectly suited for this scale of data. Alternatively, a simple Python script using the Pandas library, running directly on the Airflow worker, would also be sufficient.</p></li>
</ul>
</li>
<li><p><strong>For Behavioral Data (Pipeline 2):</strong> This data arrives as a continuous stream. The most efficient AWS-native pattern here is to use <strong>Amazon Kinesis Data Firehose</strong>.</p>
<ul class="simple">
<li><p><strong>How it Works:</strong> Your website/app sends events to a Kinesis Data Stream. A Kinesis Firehose delivery stream subscribes to this data stream. Firehose automatically buffers the incoming events (e.g., for 5 minutes or until 128 MB of data is collected), batches them into files, and writes them directly to your S3 data lake.</p></li>
<li><p><strong>Benefit:</strong> This process is serverless, fully managed, and requires no processing engine like Spark. It’s the most cost-effective and operationally simple way to get high-volume streaming data into S3. Airflow’s role here would be to monitor this process or to trigger downstream pipelines <em>after</em> the data has landed in S3.</p></li>
</ul>
</li>
</ol>
<p><strong>When to use Spark on EMR?</strong></p>
<p>We will use Spark and EMR in the <strong>next major pipeline: Feature Engineering</strong>. After all the raw data (both transactional and behavioral) has been landed in S3, we will need a powerful, distributed engine to process the <em>entire historical dataset</em> at once to compute complex customer-level features (e.g., aggregations, rolling window calculations). That is where Spark’s capabilities are essential and cost-effective.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Pipeline</p></th>
<th class="head text-left"><p>Source</p></th>
<th class="head text-left"><p>Processing/Tools</p></th>
<th class="head text-left"><p>Destination</p></th>
<th class="head text-left"><p>Orchestration</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Data Ingestion 1 (Batch)</strong></p></td>
<td class="text-left"><p>Production DB (e.g., PostgreSQL)</p></td>
<td class="text-left"><p><strong>AWS Glue</strong> or <strong>Python/Pandas</strong> for extraction and transformation. <strong>Great Expectations</strong> for validation.</p></td>
<td class="text-left"><p>S3 Data Lake (Raw Zone)</p></td>
<td class="text-left"><p><strong>Apache Airflow (MWAA)</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Data Ingestion 2 (Stream)</strong></p></td>
<td class="text-left"><p><strong>Kinesis Data Streams</strong></p></td>
<td class="text-left"><p><strong>Kinesis Data Firehose</strong> for automated buffering and delivery.</p></td>
<td class="text-left"><p>S3 Data Lake (Raw Zone)</p></td>
<td class="text-left"><p><strong>Kinesis Firehose</strong> (Managed)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="data-ingestion-pipeline-implementation">
<h4>Data Ingestion Pipeline: Implementation<a class="headerlink" href="#data-ingestion-pipeline-implementation" title="Permalink to this heading">¶</a></h4>
<p><strong>Architecture Diagram</strong></p>
<img src="../_static/past_experiences/ecom_cltv/data_ingestion_validation.svg" style="background-color: #FCF1EF;"/>
<p><strong>Infrastructure as Code (Terraform)</strong></p>
<p>This defines the AWS Glue resources needed for the batch ingestion pipeline.</p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/aws_glue.tf</span>

<span class="c1"># IAM Role for the Glue job to access S3 and the DB connection</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role&quot;</span><span class="w"> </span><span class="nv">&quot;glue_job_role&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-glue-job-role-${var.environment}&quot;</span>
<span class="w">  </span><span class="na">assume_role_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">jsonencode</span><span class="p">({</span>
<span class="w">    </span><span class="na">Version</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2012-10-17&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">Statement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[{</span>
<span class="w">      </span><span class="na">Effect</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nb">Principal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="na">Service</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;glue.amazonaws.com&quot;</span><span class="w"> </span><span class="p">},</span>
<span class="w">      </span><span class="na">Action</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sts:AssumeRole&quot;</span>
<span class="w">    </span><span class="p">}]</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role_policy_attachment&quot;</span><span class="w"> </span><span class="nv">&quot;glue_s3_access&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">role</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.glue_job_role.name</span>
<span class="w">  </span><span class="na">policy_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;arn:aws:iam::aws:policy/AmazonS3FullAccess&quot;</span><span class="c1"> # Scope down in production</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role_policy_attachment&quot;</span><span class="w"> </span><span class="nv">&quot;glue_basic_execution&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">role</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.glue_job_role.name</span>
<span class="w">  </span><span class="na">policy_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole&quot;</span>
<span class="p">}</span>

<span class="c1"># The Glue job definition</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_glue_job&quot;</span><span class="w"> </span><span class="nv">&quot;ingest_transactional_job&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-ingest-transactional-job-${var.environment}&quot;</span>
<span class="w">  </span><span class="na">role_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.glue_job_role.arn</span>
<span class="w">  </span><span class="nb">command</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">script_location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;s3://${var.artifacts_bucket_name}/scripts/ingest_transactional_data.py&quot;</span>
<span class="w">    </span><span class="na">python_version</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;3&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="na">glue_version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;3.0&quot;</span>
<span class="w">  </span><span class="na">number_of_workers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span>
<span class="w">  </span><span class="na">worker_type</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;G.1X&quot;</span>
<span class="p">}</span>

<span class="c1"># The Glue connection to store DB credentials securely</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_glue_connection&quot;</span><span class="w"> </span><span class="nv">&quot;source_db_connection&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-source-db-connection-${var.environment}&quot;</span>
<span class="w">  </span><span class="na">connection_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;JDBC&quot;</span>

<span class="w">  </span><span class="nb">connection_properties</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">JDBC_CONNECTION_URL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;jdbc:postgresql://your-db-endpoint.rds.amazonaws.com:5432/ecommerce&quot;</span>
<span class="w">    </span><span class="na">USERNAME</span><span class="w">            </span><span class="o">=</span><span class="w"> </span><span class="nv">var.db_username</span>
<span class="w">    </span><span class="na">PASSWORD</span><span class="w">            </span><span class="o">=</span><span class="w"> </span><span class="nv">var.db_password</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This defines the Kinesis Stream and Firehose for handling behavioral events.</p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/aws_kinesis.tf</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_kinesis_stream&quot;</span><span class="w"> </span><span class="nv">&quot;behavioral_events_stream&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-behavioral-events-stream-${var.environment}&quot;</span>
<span class="w">  </span><span class="na">shard_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_kinesis_firehose_delivery_stream&quot;</span><span class="w"> </span><span class="nv">&quot;behavioral_stream_to_s3&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-behavioral-stream-to-s3-${var.environment}&quot;</span>
<span class="w">  </span><span class="na">destination</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;extended_s3&quot;</span>

<span class="w">  </span><span class="nb">extended_s3_configuration</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">role_arn</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.firehose_role.arn</span>
<span class="w">    </span><span class="na">bucket_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_s3_bucket.raw_data_bucket.arn</span><span class="c1"> # Assuming raw_data_bucket is defined elsewhere</span>
<span class="c1">    </span>
<span class="c1">    # Buffer hints: deliver every 5 minutes or when 64MB is reached</span>
<span class="w">    </span><span class="na">buffering_interval_in_seconds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">300</span>
<span class="w">    </span><span class="na">buffering_size_in_mb</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="m">64</span>

<span class="c1">    # Convert incoming JSON to Parquet for efficiency</span>
<span class="w">    </span><span class="nb">data_format_conversion_configuration</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="na">enabled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span>
<span class="w">      </span><span class="nb">input_format_configuration</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nb">deserializer</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="nb">hive_json_ser_de</span><span class="w"> </span><span class="p">{}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="nb">output_format_configuration</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nb">serializer</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="nb">parquet_ser_de</span><span class="w"> </span><span class="p">{}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="nb">kinesis_source_configuration</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">kinesis_stream_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_kinesis_stream.behavioral_events_stream.arn</span>
<span class="w">    </span><span class="na">role_arn</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.firehose_role.arn</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Role for Firehose to read from Kinesis and write to S3</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role&quot;</span><span class="w"> </span><span class="nv">&quot;firehose_role&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-firehose-role-${var.environment}&quot;</span>
<span class="c1">  # Assume role policy allows firehose.amazonaws.com</span>
<span class="p">}</span>

<span class="c1"># ... Attach necessary policies to firehose_role ...</span>
</pre></div>
</div>
<p><strong>Great Expectations Suite</strong></p>
<p>This JSON file defines our data quality rules. It would be generated by the GE CLI and stored in your Git repo.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;expectation_suite_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;transactional_data.warning&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;ge_cloud_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;meta&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;great_expectations_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0.15.0&quot;</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;expectations&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;expectation_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;expect_table_columns_to_match_ordered_list&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;kwargs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;column_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;InvoiceNo&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;StockCode&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Description&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Quantity&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;UnitPrice&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Country&quot;</span><span class="p">]</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;expectation_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;expect_column_values_to_not_be_null&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;kwargs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;column&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;CustomerID&quot;</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;expectation_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;expect_column_values_to_be_of_type&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;kwargs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;column&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Quantity&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type_&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int&quot;</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;expectation_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;expect_column_values_to_be_between&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;kwargs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;column&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;UnitPrice&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;min_value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Python Scripts</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/ingest_transactional_data.py</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">awsglue.transforms</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">awsglue.utils</span> <span class="kn">import</span> <span class="n">getResolvedOptions</span>
<span class="kn">from</span> <span class="nn">pyspark.context</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">awsglue.context</span> <span class="kn">import</span> <span class="n">GlueContext</span>
<span class="kn">from</span> <span class="nn">awsglue.job</span> <span class="kn">import</span> <span class="n">Job</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="c1"># Get job arguments</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">getResolvedOptions</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;JOB_NAME&quot;</span><span class="p">,</span> <span class="s2">&quot;output_path&quot;</span><span class="p">])</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">()</span>
<span class="n">glueContext</span> <span class="o">=</span> <span class="n">GlueContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">glueContext</span><span class="o">.</span><span class="n">spark_session</span>
<span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="p">(</span><span class="n">glueContext</span><span class="p">)</span>
<span class="n">job</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;JOB_NAME&quot;</span><span class="p">],</span> <span class="n">args</span><span class="p">)</span>

<span class="c1"># Read from the Glue Data Catalog using the specified connection</span>
<span class="n">source_dyf</span> <span class="o">=</span> <span class="n">glueContext</span><span class="o">.</span><span class="n">create_dynamic_frame</span><span class="o">.</span><span class="n">from_catalog</span><span class="p">(</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;ecommerce_db&quot;</span><span class="p">,</span>
    <span class="n">table_name</span><span class="o">=</span><span class="s2">&quot;transactions&quot;</span><span class="p">,</span>
    <span class="n">connection_name</span><span class="o">=</span><span class="s2">&quot;clv-source-db-connection-staging&quot;</span> <span class="c1"># Use connection name</span>
<span class="p">)</span>

<span class="c1"># Convert to Spark DataFrame for processing</span>
<span class="n">source_df</span> <span class="o">=</span> <span class="n">source_dyf</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>

<span class="c1"># Add a processing timestamp</span>
<span class="n">source_df</span> <span class="o">=</span> <span class="n">source_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;processing_timestamp&quot;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()))</span>

<span class="c1"># Write data to S3 in Parquet format</span>
<span class="n">glueContext</span><span class="o">.</span><span class="n">write_dynamic_frame</span><span class="o">.</span><span class="n">from_options</span><span class="p">(</span>
    <span class="n">frame</span><span class="o">=</span><span class="n">DynamicFrame</span><span class="o">.</span><span class="n">fromDF</span><span class="p">(</span><span class="n">source_df</span><span class="p">,</span> <span class="n">glueContext</span><span class="p">,</span> <span class="s2">&quot;source_df&quot;</span><span class="p">),</span>
    <span class="n">connection_type</span><span class="o">=</span><span class="s2">&quot;s3&quot;</span><span class="p">,</span>
    <span class="n">connection_options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;output_path&quot;</span><span class="p">]},</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span>
<span class="p">)</span>

<span class="n">job</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</pre></div>
</div>
<p>A simple script to simulate sending events to the Kinesis stream (for testing)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/produce_behavioral_events.py</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">STREAM_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-behavioral-events-stream-staging&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;kinesis&quot;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="s2">&quot;eu-west-1&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">send_event</span><span class="p">(</span><span class="n">event_data</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">put_record</span><span class="p">(</span>
            <span class="n">StreamName</span><span class="o">=</span><span class="n">STREAM_NAME</span><span class="p">,</span>
            <span class="n">Data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">event_data</span><span class="p">),</span>
            <span class="n">PartitionKey</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">event_data</span><span class="p">[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sent event for Customer </span><span class="si">{</span><span class="n">event_data</span><span class="p">[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">. SequenceNumber: </span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;SequenceNumber&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error sending event: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">event_type</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">&#39;page_view&#39;</span><span class="p">,</span> <span class="s1">&#39;add_to_cart&#39;</span><span class="p">,</span> <span class="s1">&#39;search&#39;</span><span class="p">])</span>
        <span class="n">customer_id</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
        
        <span class="n">event</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;event_type&quot;</span><span class="p">:</span> <span class="n">event_type</span><span class="p">,</span>
            <span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="n">customer_id</span><span class="p">,</span>
            <span class="s2">&quot;timestamp&quot;</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">(),</span>
            <span class="s2">&quot;session_id&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;sess_</span><span class="si">{</span><span class="n">customer_id</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">}</span>
        <span class="n">send_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Airflow DAG</strong></p>
<p>This DAG orchestrates the transactional ingestion and validation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_ingest_transactional.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.glue</span> <span class="kn">import</span> <span class="n">GlueJobOperator</span>
<span class="kn">from</span> <span class="nn">great_expectations_provider.operators.great_expectations</span> <span class="kn">import</span> <span class="n">GreatExpectationsOperator</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">GE_PROJECT_ROOT_DIR</span> <span class="o">=</span> <span class="s2">&quot;/path/to/your/great_expectations&quot;</span>
<span class="n">OUTPUT_S3_PATH</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-raw-data-bucket-staging/transactional/&quot;</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_ingest_transactional_data_with_validation&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;@daily&quot;</span><span class="p">,</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">ingest_dag</span><span class="p">():</span>
    
    <span class="n">ingest_job</span> <span class="o">=</span> <span class="n">GlueJobOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;run_glue_ingestion_job&quot;</span><span class="p">,</span>
        <span class="n">job_name</span><span class="o">=</span><span class="s2">&quot;clv-ingest-transactional-job-staging&quot;</span><span class="p">,</span>
        <span class="n">script_args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;--output_path&quot;</span><span class="p">:</span> <span class="n">OUTPUT_S3_PATH</span><span class="p">},</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">validation_task</span> <span class="o">=</span> <span class="n">GreatExpectationsOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;validate_raw_transactional_data&quot;</span><span class="p">,</span>
        <span class="n">data_context_root_dir</span><span class="o">=</span><span class="n">GE_PROJECT_ROOT_DIR</span><span class="p">,</span>
        <span class="n">checkpoint_name</span><span class="o">=</span><span class="s2">&quot;s3_raw_data_checkpoint&quot;</span><span class="p">,</span> <span class="c1"># Assumes a checkpoint is configured</span>
        <span class="n">fail_task_on_validation_failure</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">ingest_job</span> <span class="o">&gt;&gt;</span> <span class="n">validation_task</span>

<span class="n">ingest_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Unit Test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/unit/test_event_producer.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span><span class="p">,</span> <span class="n">MagicMock</span>
<span class="kn">from</span> <span class="nn">src.produce_behavioral_events</span> <span class="kn">import</span> <span class="n">send_event</span>

<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;boto3.client&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_send_event_success</span><span class="p">(</span><span class="n">mock_boto_client</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests the happy path of sending a Kinesis event.&quot;&quot;&quot;</span>
    <span class="n">mock_kinesis</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">mock_boto_client</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_kinesis</span>
    
    <span class="n">event_data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="mi">123</span><span class="p">,</span> <span class="s2">&quot;event_type&quot;</span><span class="p">:</span> <span class="s2">&quot;page_view&quot;</span><span class="p">}</span>
    
    <span class="k">with</span> <span class="n">patch</span><span class="p">(</span><span class="s1">&#39;src.produce_behavioral_events.client&#39;</span><span class="p">,</span> <span class="n">mock_kinesis</span><span class="p">):</span>
        <span class="n">send_event</span><span class="p">(</span><span class="n">event_data</span><span class="p">)</span>

    <span class="n">mock_kinesis</span><span class="o">.</span><span class="n">put_record</span><span class="o">.</span><span class="n">assert_called_once</span><span class="p">()</span>
    <span class="c1"># You can add more specific assertions on the call arguments</span>
</pre></div>
</div>
<p><strong>Integration Test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/integration/test_ingestion_pipelines.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">airflow.api.client.local_client</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">src.produce_behavioral_events</span> <span class="kn">import</span> <span class="n">send_event</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span> <span class="nf">test_transactional_ingestion_dag</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Triggers the transactional data DAG and checks for completion.&quot;&quot;&quot;</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;test_transactional_ingestion_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
    
    <span class="c1"># Trigger and wait for the DAG to complete</span>
    <span class="c1"># ... (polling logic similar to previous examples) ...</span>
    
    <span class="c1"># Assert that the final state is &#39;success&#39;</span>
    <span class="n">dag_run</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">get_dag_run</span><span class="p">(</span><span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_ingest_transactional_data_with_validation&quot;</span><span class="p">,</span> <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">dag_run</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="s1">&#39;success&#39;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span> <span class="nf">test_behavioral_ingestion_pipeline</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sends a test event and checks if it lands in S3 via Firehose.&quot;&quot;&quot;</span>
    <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;s3&quot;</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="s2">&quot;clv-raw-data-bucket-staging&quot;</span>
    <span class="n">prefix_before</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;behavioral/</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y/%m/</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># Send a test event</span>
    <span class="n">test_event</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="mi">9999</span><span class="p">,</span> <span class="s2">&quot;event_type&quot;</span><span class="p">:</span> <span class="s2">&quot;integration_test&quot;</span><span class="p">}</span>
    <span class="n">send_event</span><span class="p">(</span><span class="n">test_event</span><span class="p">)</span>

    <span class="c1"># Wait for Firehose buffer to flush (e.g., 60 seconds)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Waiting 65 seconds for Firehose to deliver...&quot;</span><span class="p">)</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">65</span><span class="p">)</span>
    
    <span class="c1"># Check S3 for a new object</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">list_objects_v2</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span> <span class="n">Prefix</span><span class="o">=</span><span class="n">prefix_before</span><span class="p">)</span>
    <span class="k">assert</span> <span class="s1">&#39;Contents&#39;</span> <span class="ow">in</span> <span class="n">response</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;Contents&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;No file was delivered to S3&quot;</span>
</pre></div>
</div>
<p><strong>CI/CD Workflow</strong></p>
<p>This workflow validates and deploys both ingestion pipelines.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># .github/workflows/cicd_data_ingestion.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;CI/CD</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">Data</span><span class="nv"> </span><span class="s">Ingestion</span><span class="nv"> </span><span class="s">Pipelines&quot;</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">paths</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;src/ingest_transactional_data.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;src/produce_behavioral_events.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_ingest_transactional.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;terraform/aws_glue.tf&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;terraform/aws_kinesis.tf&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;great_expectations/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;tests/**&#39;</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">ci-checks</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Static</span><span class="nv"> </span><span class="s">Checks</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">Unit</span><span class="nv"> </span><span class="s">Tests&quot;</span>
<span class="w">    </span><span class="c1"># ... (linting, unit tests, terraform validate) ...</span>
<span class="w">  </span>
<span class="w">  </span><span class="nt">cd-staging-and-test</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Deploy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">Staging</span><span class="nv"> </span><span class="s">&amp;</span><span class="nv"> </span><span class="s">Run</span><span class="nv"> </span><span class="s">Integration</span><span class="nv"> </span><span class="s">Tests&quot;</span>
<span class="w">    </span><span class="nt">needs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ci-checks</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;push&#39; &amp;&amp; github.ref == &#39;refs/heads/main&#39;</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">staging</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout Repository</span>
<span class="w">        </span><span class="c1"># ...</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Configure Staging AWS Credentials</span>
<span class="w">        </span><span class="c1"># ...</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deploy Infrastructure (Terraform Apply)</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">cd terraform</span>
<span class="w">          </span><span class="no">terraform apply -auto-approve -var-file=staging.tfvars</span>
<span class="w">      </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deploy DAG to Staging Airflow</span>
<span class="w">        </span><span class="c1"># ...</span>
<span class="w">        </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run Integration Tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest tests/integration/test_ingestion_pipelines.py</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="feature-engineering-pipeline">
<h3>Feature Engineering Pipeline<a class="headerlink" href="#feature-engineering-pipeline" title="Permalink to this heading">¶</a></h3>
<section id="planning">
<h4>Planning<a class="headerlink" href="#planning" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>Objective:</strong> Create a single, automated pipeline that takes the raw transactional and behavioral data from our S3 data lake and produces a comprehensive feature set for each customer. This feature set will be stored in the <strong>Amazon SageMaker Feature Store</strong> to ensure consistency between training and serving.</p></li>
<li><p><strong>Core Tooling:</strong> We will use <strong>Apache Spark on AWS EMR</strong> for this task. Given that we need to process the <em>entire historical dataset</em> and perform complex aggregations (like rolling time windows), Spark’s distributed processing capability is the right choice here. It’s both scalable and cost-effective for this type of heavy-lifting workload.</p></li>
<li><p><strong>Pipeline Implementation:</strong></p>
<ul class="simple">
<li><p><strong>Orchestration:</strong> The pipeline will be defined as an <strong>Airflow DAG</strong>. This DAG will be triggered upon the successful completion of the batch transactional data ingestion pipeline.</p></li>
<li><p><strong>Compute:</strong> The Airflow DAG will have a task that programmatically launches a temporary <strong>EMR cluster</strong>, submits the Spark job, waits for its completion, and then terminates the cluster to save costs.</p></li>
<li><p><strong>Logic:</strong> The core feature engineering logic will be encapsulated in a single, well-structured <strong>PySpark script</strong>.</p></li>
</ul>
</li>
<li><p><strong>Types of Features to Engineer:</strong> We will create a rich set of features that go beyond simple RFM to capture nuanced customer behavior:</p>
<ul class="simple">
<li><p><strong>Static RFM Features:</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">recency</span></code>: Days since last purchase.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">frequency</span></code>: Total number of distinct purchase days.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">monetary</span></code>: Average spend per purchase day.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">T</span></code>: Tenure of the customer (days since first purchase).</p></li>
</ul>
</li>
<li><p><strong>Time-Windowed Features:</strong> To capture trends, we’ll calculate key metrics over multiple rolling windows (e.g., last 30, 90, 365 days):</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">purchase_count_30d</span></code>, <code class="docutils literal notranslate"><span class="pre">purchase_count_90d</span></code>, <code class="docutils literal notranslate"><span class="pre">purchase_count_365d</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_spend_30d</span></code>, <code class="docutils literal notranslate"><span class="pre">total_spend_90d</span></code>, <code class="docutils literal notranslate"><span class="pre">total_spend_365d</span></code></p></li>
</ul>
</li>
<li><p><strong>Behavioral Features:</strong> Aggregations from the clickstream data:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">total_sessions_90d</span></code>: Number of website/app sessions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">avg_session_duration_90d</span></code>: Average time spent per session.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add_to_cart_count_90d</span></code>: Number of times items were added to the cart.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Artifacts to Generate:</strong></p>
<ul class="simple">
<li><p><strong>Python/PySpark Script (<code class="docutils literal notranslate"><span class="pre">src/</span></code>):</strong> The main feature engineering script.</p></li>
<li><p><strong>Unit Tests (<code class="docutils literal notranslate"><span class="pre">tests/</span></code>):</strong> Pytest unit tests for the Spark transformation functions using a local Spark session.</p></li>
<li><p><strong>Pipeline Code (<code class="docutils literal notranslate"><span class="pre">pipelines/</span></code>):</strong> The Airflow DAG that orchestrates the EMR cluster and Spark job.</p></li>
<li><p><strong>Infrastructure as Code (<code class="docutils literal notranslate"><span class="pre">terraform/</span></code>):</strong> Additions to our Terraform code to define IAM roles and permissions for EMR.</p></li>
<li><p><strong>Architecture Diagram (Mermaid Code):</strong></p></li>
</ul>
</li>
</ol>
</section>
<section id="implementation">
<h4>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading">¶</a></h4>
<img src="../_static/past_experiences/ecom_cltv/feature_engineering.svg" style="background-color: #FCF1EF;"/>
<p><strong>Airflow DAG Script to Orchestrate Feature Generation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.emr</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EmrCreateJobFlowOperator</span><span class="p">,</span>
    <span class="n">EmrAddStepsOperator</span><span class="p">,</span>
    <span class="n">EmrTerminateJobFlowOperator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">airflow.models.baseoperator</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="c1"># --- Constants ---</span>
<span class="n">S3_BUCKET</span> <span class="o">=</span> <span class="s2">&quot;airflow-bucket-name&quot;</span> <span class="c1"># Bucket for Airflow logs and scripts</span>
<span class="n">EMR_EC2_ROLE</span> <span class="o">=</span> <span class="s2">&quot;emr-ec2-instance-role&quot;</span>
<span class="n">EMR_SERVICE_ROLE</span> <span class="o">=</span> <span class="s2">&quot;emr-service-role&quot;</span>
<span class="n">FEATURE_GROUP_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-feature-group-v1&quot;</span>
<span class="n">AWS_REGION</span> <span class="o">=</span> <span class="s2">&quot;eu-west-1&quot;</span>

<span class="c1"># EMR cluster configuration</span>
<span class="n">JOB_FLOW_OVERRIDES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;clv-feature-engineering-cluster&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ReleaseLabel&quot;</span><span class="p">:</span> <span class="s2">&quot;emr-6.9.0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Applications&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;Spark&quot;</span><span class="p">}],</span>
    <span class="s2">&quot;Instances&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;InstanceGroups&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;Master node&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Market&quot;</span><span class="p">:</span> <span class="s2">&quot;ON_DEMAND&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceRole&quot;</span><span class="p">:</span> <span class="s2">&quot;MASTER&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="s2">&quot;m5.xlarge&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceCount&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;Core nodes&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Market&quot;</span><span class="p">:</span> <span class="s2">&quot;ON_DEMAND&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceRole&quot;</span><span class="p">:</span> <span class="s2">&quot;CORE&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="s2">&quot;m5.xlarge&quot;</span><span class="p">,</span>
                <span class="s2">&quot;InstanceCount&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">],</span>
        <span class="s2">&quot;KeepJobFlowAliveWhenNoSteps&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;TerminationProtected&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;JobFlowRole&quot;</span><span class="p">:</span> <span class="n">EMR_EC2_ROLE</span><span class="p">,</span>
    <span class="s2">&quot;ServiceRole&quot;</span><span class="p">:</span> <span class="n">EMR_SERVICE_ROLE</span><span class="p">,</span>
    <span class="s2">&quot;VisibleToAllUsers&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Spark job steps</span>
<span class="n">SPARK_STEPS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;Generate CLV Features&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ActionOnFailure&quot;</span><span class="p">:</span> <span class="s2">&quot;TERMINATE_JOB_FLOW&quot;</span><span class="p">,</span>
        <span class="s2">&quot;HadoopJarStep&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;Jar&quot;</span><span class="p">:</span> <span class="s2">&quot;command-runner.jar&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Args&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&quot;spark-submit&quot;</span><span class="p">,</span>
                <span class="s2">&quot;--deploy-mode&quot;</span><span class="p">,</span> <span class="s2">&quot;cluster&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;s3://</span><span class="si">{</span><span class="n">S3_BUCKET</span><span class="si">}</span><span class="s2">/scripts/generate_features.py&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;s3://clv-raw-data-bucket/transactional/&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;s3://clv-raw-data-bucket/behavioral/&quot;</span><span class="p">,</span>
                <span class="n">FEATURE_GROUP_NAME</span><span class="p">,</span>
                <span class="n">AWS_REGION</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_feature_generation_pipeline&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;@daily&quot;</span><span class="p">,</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;clv&quot;</span><span class="p">,</span> <span class="s2">&quot;feature-engineering&quot;</span><span class="p">],</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    <span class="c1"># Task to create a transient EMR cluster</span>
    <span class="n">create_emr_cluster</span> <span class="o">=</span> <span class="n">EmrCreateJobFlowOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;create_emr_cluster&quot;</span><span class="p">,</span>
        <span class="n">job_flow_overrides</span><span class="o">=</span><span class="n">JOB_FLOW_OVERRIDES</span><span class="p">,</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
        <span class="n">emr_conn_id</span><span class="o">=</span><span class="s2">&quot;emr_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Task to add the Spark job step</span>
    <span class="n">add_spark_step</span> <span class="o">=</span> <span class="n">EmrAddStepsOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;add_spark_step&quot;</span><span class="p">,</span>
        <span class="n">job_flow_id</span><span class="o">=</span><span class="s2">&quot;{{ task_instance.xcom_pull(task_ids=&#39;create_emr_cluster&#39;, key=&#39;return_value&#39;) }}&quot;</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">SPARK_STEPS</span><span class="p">,</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Task to terminate the EMR cluster</span>
    <span class="n">terminate_emr_cluster</span> <span class="o">=</span> <span class="n">EmrTerminateJobFlowOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;terminate_emr_cluster&quot;</span><span class="p">,</span>
        <span class="n">job_flow_id</span><span class="o">=</span><span class="s2">&quot;{{ task_instance.xcom_pull(task_ids=&#39;create_emr_cluster&#39;, key=&#39;return_value&#39;) }}&quot;</span><span class="p">,</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
        <span class="n">trigger_rule</span><span class="o">=</span><span class="s2">&quot;all_done&quot;</span><span class="p">,</span>  <span class="c1"># Ensures cluster is terminated even if the Spark job fails</span>
    <span class="p">)</span>

    <span class="c1"># Define task dependencies</span>
    <span class="n">chain</span><span class="p">(</span><span class="n">create_emr_cluster</span><span class="p">,</span> <span class="n">add_spark_step</span><span class="p">,</span> <span class="n">terminate_emr_cluster</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Python Script for Feature Generation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/generate_features.py</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">lit</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="n">countDistinct</span><span class="p">,</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">avg</span><span class="p">,</span> <span class="n">datediff</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">window</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">TimestampType</span>
<span class="kn">import</span> <span class="nn">boto3</span>

<span class="k">def</span> <span class="nf">get_sagemaker_feature_store_client</span><span class="p">(</span><span class="n">region</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes the SageMaker Feature Store runtime client.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">&#39;sagemaker-featurestore-runtime&#39;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="n">region</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_features</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">transactional_data_path</span><span class="p">,</span> <span class="n">behavioral_data_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reads raw data and generates a customer feature set.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load raw data</span>
    <span class="n">trans_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">transactional_data_path</span><span class="p">)</span>
    <span class="n">behav_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">behavioral_data_path</span><span class="p">)</span>

    <span class="c1"># --- Data Preparation ---</span>
    <span class="n">trans_df</span> <span class="o">=</span> <span class="n">trans_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">TimestampType</span><span class="p">()))</span>
    
    <span class="c1"># --- Feature Engineering ---</span>
    <span class="n">current_timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span>

    <span class="c1"># 1. RFM-T Features</span>
    <span class="n">customer_summary</span> <span class="o">=</span> <span class="n">trans_df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
        <span class="nb">max</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;last_purchase_date&quot;</span><span class="p">),</span>
        <span class="nb">min</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;first_purchase_date&quot;</span><span class="p">),</span>
        <span class="n">countDistinct</span><span class="p">(</span><span class="s2">&quot;InvoiceNo&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;frequency&quot;</span><span class="p">),</span>
        <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;SalePrice&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_spend&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">rfm_t_features</span> <span class="o">=</span> <span class="n">customer_summary</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;recency&quot;</span><span class="p">,</span> <span class="n">datediff</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;last_purchase_date&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;first_purchase_date&quot;</span><span class="p">)))</span> \
        <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">datediff</span><span class="p">(</span><span class="n">lit</span><span class="p">(</span><span class="n">current_timestamp</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;first_purchase_date&quot;</span><span class="p">)))</span> \
        <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;monetary&quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;total_spend&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;frequency&quot;</span><span class="p">))</span> \
        <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">,</span> <span class="s2">&quot;recency&quot;</span><span class="p">,</span> <span class="s2">&quot;frequency&quot;</span><span class="p">,</span> <span class="s2">&quot;monetary&quot;</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)</span>

    <span class="c1"># 2. Time-Windowed Features (Transactional)</span>
    <span class="n">window_spec_30d</span> <span class="o">=</span> <span class="n">window</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">),</span> <span class="s2">&quot;30 days&quot;</span><span class="p">)</span>
    <span class="n">window_spec_90d</span> <span class="o">=</span> <span class="n">window</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">),</span> <span class="s2">&quot;90 days&quot;</span><span class="p">)</span>

    <span class="n">time_window_features</span> <span class="o">=</span> <span class="n">trans_df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
        <span class="n">countDistinct</span><span class="p">(</span><span class="s2">&quot;InvoiceNo&quot;</span><span class="p">,</span> <span class="n">window_spec_30d</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;purchase_count_30d&quot;</span><span class="p">),</span>
        <span class="nb">sum</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;SalePrice&quot;</span><span class="p">),</span> <span class="n">window_spec_30d</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_spend_30d&quot;</span><span class="p">),</span>
        <span class="n">countDistinct</span><span class="p">(</span><span class="s2">&quot;InvoiceNo&quot;</span><span class="p">,</span> <span class="n">window_spec_90d</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;purchase_count_90d&quot;</span><span class="p">),</span>
        <span class="nb">sum</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;SalePrice&quot;</span><span class="p">),</span> <span class="n">window_spec_90d</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_spend_90d&quot;</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="c1"># 3. Behavioral Features (Aggregating last 90 days of behavioral data)</span>
    <span class="n">ninety_days_ago</span> <span class="o">=</span> <span class="n">current_timestamp</span> <span class="o">-</span> <span class="n">expr</span><span class="p">(</span><span class="s2">&quot;INTERVAL 90 DAYS&quot;</span><span class="p">)</span>
    <span class="n">behavioral_summary</span> <span class="o">=</span> <span class="n">behav_df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;event_timestamp&quot;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">ninety_days_ago</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
            <span class="n">countDistinct</span><span class="p">(</span><span class="s2">&quot;session_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_sessions_90d&quot;</span><span class="p">),</span>
            <span class="n">avg</span><span class="p">(</span><span class="s2">&quot;session_duration_seconds&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;avg_session_duration_90d&quot;</span><span class="p">),</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">expr</span><span class="p">(</span><span class="s2">&quot;case when event_type = &#39;add_to_cart&#39; then 1 else 0 end&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;add_to_cart_count_90d&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># --- Join all features ---</span>
    <span class="n">final_features</span> <span class="o">=</span> <span class="n">rfm_t_features</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">time_window_features</span><span class="p">,</span> <span class="s2">&quot;CustomerID&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">behavioral_summary</span><span class="p">,</span> <span class="s2">&quot;CustomerID&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Fill nulls from joins with 0</span>
    
    <span class="c1"># Add EventTime feature required by Feature Store</span>
    <span class="n">final_features</span> <span class="o">=</span> <span class="n">final_features</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;EventTime&quot;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="n">current_timestamp</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">TimestampType</span><span class="p">()))</span>

    <span class="k">return</span> <span class="n">final_features</span>

<span class="k">def</span> <span class="nf">write_to_feature_store</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">feature_group_name</span><span class="p">,</span> <span class="n">region</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Ingests a Spark DataFrame into a SageMaker Feature Store.</span>
<span class="sd">    This function would typically use the SageMaker Feature Store SDK.</span>
<span class="sd">    For a Spark job, a common pattern is to convert to Pandas and use boto3.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># NOTE: In a high-scale scenario, you might use a more direct Spark-to-FeatureStore connector.</span>
    <span class="c1"># For simplicity, this demonstrates the boto3 approach within a Spark context.</span>
    <span class="n">featurestore_client</span> <span class="o">=</span> <span class="n">get_sagemaker_feature_store_client</span><span class="p">(</span><span class="n">region</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">put_records</span><span class="p">(</span><span class="n">partition</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">partition</span><span class="p">:</span>
            <span class="n">record</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="s1">&#39;ValueAsString&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)}</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">row</span><span class="o">.</span><span class="n">asDict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">]</span>
            <span class="n">featurestore_client</span><span class="o">.</span><span class="n">put_record</span><span class="p">(</span>
                <span class="n">FeatureGroupName</span><span class="o">=</span><span class="n">feature_group_name</span><span class="p">,</span>
                <span class="n">Record</span><span class="o">=</span><span class="n">record</span>
            <span class="p">)</span>

    <span class="n">df</span><span class="o">.</span><span class="n">foreachPartition</span><span class="p">(</span><span class="n">put_records</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">5</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Usage: spark-submit generate_features.py &lt;transactional_data_path&gt; &lt;behavioral_data_path&gt; &lt;feature_group_name&gt; &lt;aws_region&gt;&quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;CLVFeatureGeneration&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

    <span class="n">transactional_data_path</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">behavioral_data_path</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">feature_group_name</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">aws_region</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting feature generation...&quot;</span><span class="p">)</span>
    <span class="n">features_df</span> <span class="o">=</span> <span class="n">generate_features</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">transactional_data_path</span><span class="p">,</span> <span class="n">behavioral_data_path</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Writing </span><span class="si">{</span><span class="n">features_df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">}</span><span class="s2"> records to Feature Group: </span><span class="si">{</span><span class="n">feature_group_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">write_to_feature_store</span><span class="p">(</span><span class="n">features_df</span><span class="p">,</span> <span class="n">feature_group_name</span><span class="p">,</span> <span class="n">aws_region</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature generation and ingestion complete.&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Unit Tests for Feature Generation script</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">src.generate_features</span> <span class="kn">import</span> <span class="n">generate_features</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;session&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">spark_session</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a Spark session for testing.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
        <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;CLVFeatureTests&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test_feature_generation_logic</span><span class="p">(</span><span class="n">spark_session</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests the end-to-end feature generation function.&quot;&quot;&quot;</span>
    <span class="c1"># Create mock transactional data</span>
    <span class="n">trans_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;CustomerID&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;InvoiceNo&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;A1&#39;</span><span class="p">,</span> <span class="s1">&#39;A2&#39;</span><span class="p">,</span> <span class="s1">&#39;B1&#39;</span><span class="p">,</span> <span class="s1">&#39;A3&#39;</span><span class="p">],</span>
        <span class="s1">&#39;InvoiceDate&#39;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
            <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
            <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="s1">&#39;SalePrice&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">50.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">]</span>
    <span class="p">})</span>
    <span class="c1"># Create mock behavioral data</span>
    <span class="n">behav_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;CustomerID&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="s1">&#39;session_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;s1&#39;</span><span class="p">,</span> <span class="s1">&#39;s2&#39;</span><span class="p">],</span>
        <span class="s1">&#39;event_timestamp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">15</span><span class="p">)],</span>
        <span class="s1">&#39;session_duration_seconds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
        <span class="s1">&#39;event_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;add_to_cart&#39;</span><span class="p">,</span> <span class="s1">&#39;page_view&#39;</span><span class="p">]</span>
    <span class="p">})</span>

    <span class="n">trans_df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">trans_pd</span><span class="p">)</span>
    <span class="n">behav_df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">behav_pd</span><span class="p">)</span>
    
    <span class="c1"># Create temporary paths for the test data</span>
    <span class="n">trans_path</span> <span class="o">=</span> <span class="s2">&quot;file:///tmp/test_trans_data&quot;</span>
    <span class="n">behav_path</span> <span class="o">=</span> <span class="s2">&quot;file:///tmp/test_behav_data&quot;</span>
    <span class="n">trans_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">trans_path</span><span class="p">)</span>
    <span class="n">behav_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">behav_path</span><span class="p">)</span>

    <span class="c1"># Run the feature generation function</span>
    <span class="n">features_df</span> <span class="o">=</span> <span class="n">generate_features</span><span class="p">(</span><span class="n">spark_session</span><span class="p">,</span> <span class="n">trans_path</span><span class="p">,</span> <span class="n">behav_path</span><span class="p">)</span>
    
    <span class="c1"># Collect results for validation</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">features_df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;recency&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">90</span>  <span class="c1"># 100 days ago to 10 days ago</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">100</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;frequency&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="nb">abs</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;monetary&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mf">20.0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.01</span> <span class="c1"># (10+20+30)/3</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;purchase_count_30d&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;add_to_cart_count_90d&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>
</div>
<p><strong>Integration Test for Feature Generation pipeline</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">sagemaker</span>
<span class="kn">from</span> <span class="nn">sagemaker.feature_store.feature_group</span> <span class="kn">import</span> <span class="n">FeatureGroup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Import the functions from our source script</span>
<span class="kn">from</span> <span class="nn">src.generate_features</span> <span class="kn">import</span> <span class="n">generate_features</span><span class="p">,</span> <span class="n">write_to_feature_store</span>

<span class="c1"># --- Fixtures for AWS Resource Management ---</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;session&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">spark_session</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provides a Spark session for the test.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[*]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;IntegrationTest&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">aws_region</span><span class="p">():</span>
    <span class="k">return</span> <span class="s2">&quot;eu-west-1&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sagemaker_session</span><span class="p">(</span><span class="n">aws_region</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provides a SageMaker session.&quot;&quot;&quot;</span>
    <span class="n">boto_session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">region_name</span><span class="o">=</span><span class="n">aws_region</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">boto_session</span><span class="o">=</span><span class="n">boto_session</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_s3_bucket</span><span class="p">(</span><span class="n">sagemaker_session</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a temporary S3 bucket for the test run and cleans it up afterward.&quot;&quot;&quot;</span>
    <span class="n">bucket_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;clv-test-bucket-integration-</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="mi">9999</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">s3</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">boto_session</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s2">&quot;s3&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">s3</span><span class="o">.</span><span class="n">create_bucket</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">CreateBucketConfiguration</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;LocationConstraint&#39;</span><span class="p">:</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">boto_region_name</span><span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created test bucket: </span><span class="si">{</span><span class="n">bucket_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">bucket_name</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cleaning up bucket: </span><span class="si">{</span><span class="n">bucket_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span>
        <span class="n">bucket</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>
        <span class="n">bucket</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">feature_group_name</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a unique feature group name for the test run.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;clv-test-fg-</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sagemaker_feature_group</span><span class="p">(</span><span class="n">sagemaker_session</span><span class="p">,</span> <span class="n">feature_group_name</span><span class="p">,</span> <span class="n">aws_region</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a SageMaker Feature Group for the test and cleans it up afterward.&quot;&quot;&quot;</span>
    <span class="n">feature_group</span> <span class="o">=</span> <span class="n">FeatureGroup</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">feature_group_name</span><span class="p">,</span> <span class="n">sagemaker_session</span><span class="o">=</span><span class="n">sagemaker_session</span><span class="p">)</span>
    
    <span class="c1"># Define the schema based on the output of our Spark job</span>
    <span class="n">feature_definitions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;CustomerID&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;String&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;recency&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;frequency&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;monetary&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Fractional&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;purchase_count_30d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;total_spend_30d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Fractional&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;purchase_count_90d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;total_spend_90d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Fractional&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;total_sessions_90d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;avg_session_duration_90d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Fractional&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;add_to_cart_count_90d&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;Integral&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;FeatureName&quot;</span><span class="p">:</span> <span class="s2">&quot;EventTime&quot;</span><span class="p">,</span> <span class="s2">&quot;FeatureType&quot;</span><span class="p">:</span> <span class="s2">&quot;String&quot;</span><span class="p">}</span>
    <span class="p">]</span>
    
    <span class="n">feature_group</span><span class="o">.</span><span class="n">feature_definitions</span> <span class="o">=</span> <span class="n">feature_definitions</span>
    <span class="n">feature_group</span><span class="o">.</span><span class="n">record_identifier_name</span> <span class="o">=</span> <span class="s2">&quot;CustomerID&quot;</span>
    <span class="n">feature_group</span><span class="o">.</span><span class="n">event_time_feature_name</span> <span class="o">=</span> <span class="s2">&quot;EventTime&quot;</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Creating Feature Group: </span><span class="si">{</span><span class="n">feature_group_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">feature_group</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">s3_uri</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;s3://</span><span class="si">{</span><span class="n">sagemaker_session</span><span class="o">.</span><span class="n">default_bucket</span><span class="p">()</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">feature_group_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">enable_online_store</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">role_arn</span><span class="o">=</span><span class="s2">&quot;arn:aws:iam::$</span><span class="si">{YOUR_ACCOUNT_ID}</span><span class="s2">:role/service-role/AmazonSageMaker-ExecutionRole-...&quot;</span> <span class="c1"># Replace with your actual SageMaker role ARN</span>
        <span class="p">)</span>
        <span class="c1"># Wait for the feature group to be created</span>
        <span class="k">while</span> <span class="n">feature_group</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;FeatureGroupStatus&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Creating&quot;</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Waiting for feature group creation...&quot;</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">feature_group_name</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleting Feature Group: </span><span class="si">{</span><span class="n">feature_group_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">feature_group</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error deleting feature group: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_data_on_s3</span><span class="p">(</span><span class="n">spark_session</span><span class="p">,</span> <span class="n">test_s3_bucket</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates mock raw data and uploads it to the test S3 bucket.&quot;&quot;&quot;</span>
    <span class="c1"># Create mock transactional data</span>
    <span class="n">trans_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;CustomerID&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;101&#39;</span><span class="p">,</span> <span class="s1">&#39;101&#39;</span><span class="p">,</span> <span class="s1">&#39;102&#39;</span><span class="p">],</span>
        <span class="s1">&#39;InvoiceNo&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;A1&#39;</span><span class="p">,</span> <span class="s1">&#39;A2&#39;</span><span class="p">,</span> <span class="s1">&#39;B1&#39;</span><span class="p">],</span>
        <span class="s1">&#39;InvoiceDate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">30</span><span class="p">)],</span>
        <span class="s1">&#39;SalePrice&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">15.50</span><span class="p">,</span> <span class="mf">25.00</span><span class="p">,</span> <span class="mf">100.00</span><span class="p">]</span>
    <span class="p">})</span>
    
    <span class="c1"># Create mock behavioral data</span>
    <span class="n">behav_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;CustomerID&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;101&#39;</span><span class="p">],</span>
        <span class="s1">&#39;session_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;s1&#39;</span><span class="p">],</span>
        <span class="s1">&#39;event_timestamp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">5</span><span class="p">)],</span>
        <span class="s1">&#39;session_duration_seconds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">180</span><span class="p">],</span>
        <span class="s1">&#39;event_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;add_to_cart&#39;</span><span class="p">]</span>
    <span class="p">})</span>
    
    <span class="n">trans_df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">trans_pd</span><span class="p">)</span>
    <span class="n">behav_df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">behav_pd</span><span class="p">)</span>

    <span class="n">trans_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;s3a://</span><span class="si">{</span><span class="n">test_s3_bucket</span><span class="si">}</span><span class="s2">/transactional/&quot;</span>
    <span class="n">behav_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;s3a://</span><span class="si">{</span><span class="n">test_s3_bucket</span><span class="si">}</span><span class="s2">/behavioral/&quot;</span>
    
    <span class="n">trans_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">trans_path</span><span class="p">)</span>
    <span class="n">behav_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">behav_path</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trans_path</span><span class="p">,</span> <span class="n">behav_path</span>

<span class="c1"># --- The Integration Test ---</span>

<span class="k">def</span> <span class="nf">test_spark_job_s3_to_feature_store</span><span class="p">(</span><span class="n">spark_session</span><span class="p">,</span> <span class="n">test_data_on_s3</span><span class="p">,</span> <span class="n">sagemaker_feature_group</span><span class="p">,</span> <span class="n">aws_region</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This test orchestrates the full feature engineering pipeline:</span>
<span class="sd">    1. Reads test data from a temporary S3 bucket.</span>
<span class="sd">    2. Runs the Spark feature generation logic.</span>
<span class="sd">    3. Writes the results to a temporary SageMaker Feature Group.</span>
<span class="sd">    4. Validates the data in the Feature Group.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># ARRANGE: Fixtures have already set up S3 data and the Feature Group.</span>
    <span class="n">transactional_path</span><span class="p">,</span> <span class="n">behavioral_path</span> <span class="o">=</span> <span class="n">test_data_on_s3</span>
    <span class="n">feature_group_name</span> <span class="o">=</span> <span class="n">sagemaker_feature_group</span>

    <span class="c1"># ACT: Run the feature generation and ingestion logic.</span>
    <span class="n">features_df</span> <span class="o">=</span> <span class="n">generate_features</span><span class="p">(</span><span class="n">spark_session</span><span class="p">,</span> <span class="n">transactional_path</span><span class="p">,</span> <span class="n">behavioral_path</span><span class="p">)</span>
    <span class="n">write_to_feature_store</span><span class="p">(</span><span class="n">features_df</span><span class="p">,</span> <span class="n">feature_group_name</span><span class="p">,</span> <span class="n">aws_region</span><span class="p">)</span>
    
    <span class="c1"># Give a few seconds for the records to be available in the online store</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>

    <span class="c1"># ASSERT: Query the Feature Store to verify the results.</span>
    <span class="n">featurestore_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">&#39;sagemaker-featurestore-runtime&#39;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="n">aws_region</span><span class="p">)</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">featurestore_client</span><span class="o">.</span><span class="n">get_record</span><span class="p">(</span>
        <span class="n">FeatureGroupName</span><span class="o">=</span><span class="n">feature_group_name</span><span class="p">,</span>
        <span class="n">RecordIdentifierValueAsString</span><span class="o">=</span><span class="s1">&#39;101&#39;</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="s1">&#39;Record&#39;</span> <span class="ow">in</span> <span class="n">response</span><span class="p">,</span> <span class="s2">&quot;Record for CustomerID 101 not found in Feature Store&quot;</span>
    
    <span class="c1"># Convert the returned record to a more usable dictionary</span>
    <span class="n">result_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">]:</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;ValueAsString&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;Record&#39;</span><span class="p">]}</span>
    
    <span class="k">assert</span> <span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;101&#39;</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;recency&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">50</span>  <span class="c1"># 60 days ago to 10 days ago</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;frequency&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="nb">abs</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;monetary&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mf">20.25</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.01</span>  <span class="c1"># (15.50 + 25.00) / 2</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;purchase_count_30d&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="c1"># one purchase 10 days ago</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">result_dict</span><span class="p">[</span><span class="s1">&#39;add_to_cart_count_90d&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="model-development-iteration">
<h3>Model Development &amp; Iteration<a class="headerlink" href="#model-development-iteration" title="Permalink to this heading">¶</a></h3>
<p>This is where raw data potential is transformed into a predictive model. The core philosophy is <strong>iterative and evidence-based</strong>: start simple, measure rigorously, and justify every increase in complexity with a tangible improvement against clear, predefined metrics.</p>
<p>This framework is organized into four pillars:</p>
<ol class="arabic simple">
<li><p><strong>Foundations for Success:</strong> The strategic setup required before experimentation begins.</p></li>
<li><p><strong>The Core Iterative Loop:</strong> The primary cycle of building, debugging, and improving the model.</p></li>
<li><p><strong>Advanced Optimization:</strong> Techniques to apply when initial iterations plateau.</p></li>
<li><p><strong>Validation and Governance:</strong> Ensuring the model is not just accurate, but also robust, fair, and ready for production.</p></li>
</ol>
<section id="i-foundations-for-success">
<h4><strong>I. Foundations for Success</strong><a class="headerlink" href="#i-foundations-for-success" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Define Success Metrics:</strong></p>
<ul>
<li><p><strong>Optimizing Metric:</strong> The single technical metric the model will be tuned to improve (e.g., RMSE, F1-Score).</p></li>
<li><p><strong>Satisficing Metrics:</strong> A set of operational or business constraints the model <em>must</em> meet to be considered viable (e.g., inference latency &lt;100ms, fairness across key segments).</p></li>
<li><p><strong>Business KPI:</strong> The high-level business metric the model is intended to influence (e.g., customer retention rate, marketing ROI).</p></li>
</ul>
</li>
<li><p><strong>Establish Data Strategy:</strong></p>
<ul>
<li><p><strong>Data Splitting:</strong> For time-series problems like CLV, a strict <strong>temporal split</strong> (e.g., train on months 1-9, validate on months 10-12) is non-negotiable to prevent data leakage.</p></li>
<li><p><strong>Data Quality:</strong> Ensure the dev/test sets reflect the expected production data distribution. Use a schema to detect anomalies.</p></li>
</ul>
</li>
<li><p><strong>Establish Baselines:</strong></p>
<ul>
<li><p><strong>Non-ML Baseline:</strong> A simple heuristic (e.g., <code class="docutils literal notranslate"><span class="pre">Avg.</span> <span class="pre">Spend</span> <span class="pre">x</span> <span class="pre">Avg.</span> <span class="pre">Lifespan</span></code>) to quantify the value of using ML.</p></li>
<li><p><strong>Simple ML Baseline:</strong> A simple, interpretable model (e.g., Linear Regression) to validate the end-to-end pipeline and set an initial performance floor.</p></li>
<li><p><strong>Human-Level Performance (HLP):</strong> If applicable, estimate the performance of a human expert to understand the “avoidable bias.”</p></li>
</ul>
</li>
</ul>
</section>
<section id="ii-the-core-iterative-loop">
<h4><strong>II. The Core Iterative Loop</strong><a class="headerlink" href="#ii-the-core-iterative-loop" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Experiment &amp; Model Selection:</strong></p>
<ul>
<li><p>Start with the simplest model that can do the job (e.g., Gradient Boosting for tabular data).</p></li>
<li><p>Compare model families (Probabilistic vs. Ensemble vs. Deep Learning), weighing trade-offs between accuracy, interpretability, and operational cost.</p></li>
<li><p>Formulate clear, testable hypotheses for each experiment (e.g., “Adding behavioral features will reduce RMSE by 5%”).</p></li>
</ul>
</li>
<li><p><strong>Track Everything:</strong></p>
<ul>
<li><p>Use an experiment tracking tool (like <strong>MLflow</strong>) to log every run’s:</p>
<ul>
<li><p>Code Version (Git Hash)</p></li>
<li><p>Data Version (DVC Hash)</p></li>
<li><p>Hyperparameters</p></li>
<li><p>Evaluation Metrics</p></li>
<li><p>Model Artifacts</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Debug &amp; Diagnose Systematically:</strong></p>
<ul>
<li><p><strong>Bias vs. Variance:</strong> Use learning curves to determine if the model is underfitting (high bias) or overfitting (high variance). This guides the next steps (e.g., “get more data” vs. “use a bigger model”).</p></li>
<li><p><strong>Error Analysis:</strong> Manually inspect the examples where the model fails most significantly. This often reveals data quality issues or opportunities for new features.</p></li>
<li><p><strong>Feature Importance:</strong> Use techniques like SHAP to understand which features are driving predictions. This aids debugging and builds business trust.</p></li>
</ul>
</li>
</ul>
</section>
<section id="iii-advanced-optimization">
<h4><strong>III. Advanced Optimization</strong><a class="headerlink" href="#iii-advanced-optimization" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Iterative Feature Engineering:</strong></p>
<ul>
<li><p>Continuously add, remove, or transform features based on error analysis and feature importance results. Use a Feature Store to manage this process scalably.</p></li>
</ul>
</li>
<li><p><strong>Automated Hyperparameter Optimization (HPO):</strong></p>
<ul>
<li><p>Use model-based methods like Bayesian Optimization (available in SageMaker, Vertex AI, or via libraries like Optuna) to efficiently search for the best hyperparameters.</p></li>
</ul>
</li>
<li><p><strong>Ensemble Methods:</strong></p>
<ul>
<li><p>If performance plateaus, consider simple ensembles (e.g., averaging predictions from an XGBoost and a linear model) to improve robustness and accuracy.</p></li>
</ul>
</li>
</ul>
</section>
<section id="iv-validation-and-governance">
<h4><strong>IV. Validation and Governance</strong><a class="headerlink" href="#iv-validation-and-governance" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Slice-Based Evaluation:</strong> Do not trust a single, global performance metric. Evaluate model performance across critical business segments (e.g., by country, acquisition channel) to uncover hidden biases or performance gaps.</p></li>
<li><p><strong>Model Calibration:</strong> Check if the model’s predicted outputs align with real-world averages. A model that predicts an average CLV of $500 for a segment should be checked against the actual average CLV of that segment.</p></li>
<li><p><strong>Model Registry &amp; Versioning:</strong></p>
<ul>
<li><p>Promote the final, validated model artifact to a <strong>Model Registry</strong> (like MLflow’s).</p></li>
<li><p>Tag the model with its version, performance metrics, and a link back to the training experiment, creating an auditable and governable asset ready for deployment.</p></li>
</ul>
</li>
</ul>
</section>
<section id="applying-the-framework-to-the-clv-project">
<h4><strong>Applying the Framework to the CLV Project</strong><a class="headerlink" href="#applying-the-framework-to-the-clv-project" title="Permalink to this heading">¶</a></h4>
<p>Here is how we applied this framework to our e-commerce Customer Lifetime Value prediction project:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Factor to Consider</p></th>
<th class="head text-left"><p>Decision / Choice Made</p></th>
<th class="head text-left"><p>Rationale &amp; Trade-offs</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>1. Success Metrics</strong></p></td>
<td class="text-left"><p><strong>Optimizing:</strong> Root Mean Squared Error (RMSE). <br> <strong>Satisficing:</strong> Gini Coefficient &gt; 0.3, Batch Inference Time &lt; 2 hours. <br> <strong>Business KPI:</strong> Increase in 12-month revenue from targeted retention campaigns.</p></td>
<td class="text-left"><p>RMSE was chosen to penalize large prediction errors heavily. The Gini coefficient ensures the model can effectively rank customers, which is vital for targeting campaigns. The time constraint ensures the pipeline fits within our nightly batch window.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>2. Data Splitting</strong></p></td>
<td class="text-left"><p>Strict temporal split. We trained the model on data up to a fixed cutoff date and evaluated it on the subsequent 3-month period.</p></td>
<td class="text-left"><p>This is the only correct way to validate a time-series forecasting model. A random split would leak future information into the training set, leading to misleadingly optimistic performance metrics.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>3. Baseline Models</strong></p></td>
<td class="text-left"><p>1. <strong>Heuristic:</strong> Simple average spend per customer. <br> 2. <strong>ML Baseline:</strong> A Linear Regression model using only RFM features.</p></td>
<td class="text-left"><p>The heuristic model established the absolute minimum performance bar. The linear model validated our end-to-end pipeline and proved that even basic ML could outperform simple averages.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>4. Primary Model Choice</strong></p></td>
<td class="text-left"><p><strong>XGBoost (Gradient Boosting Machine)</strong></p></td>
<td class="text-left"><p>We chose XGBoost over simpler models for its high performance and over deep learning for its lower data requirements and better training efficiency on tabular data. It represents the industry standard for this type of problem.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>5. Experiment Tracking</strong></p></td>
<td class="text-left"><p><strong>MLflow</strong></p></td>
<td class="text-left"><p>Aligned with our tech stack, MLflow provides a robust open-source solution for tracking experiments, versioning data/code, and managing the model lifecycle through its Model Registry.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>6. Debugging &amp; Diagnostics</strong></p></td>
<td class="text-left"><p>Used <strong>SHAP (SHapley Additive exPlanations)</strong> for feature importance and to explain individual predictions. Analyzed learning curves to balance bias and variance.</p></td>
<td class="text-left"><p>SHAP was critical for gaining business trust by explaining <em>why</em> a customer was predicted to be high-value. Learning curves guided our decision to invest more in feature engineering rather than just a bigger model.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>7. Hyperparameter Optimization</strong></p></td>
<td class="text-left"><p><strong>Amazon SageMaker’s Automatic Model Tuning</strong> (using Bayesian Optimization).</p></td>
<td class="text-left"><p>We leveraged a managed cloud service to automate this computationally intensive task. This freed up engineering time and ran parallel trials more efficiently than a manual or grid search approach.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>8. Validation &amp; Governance</strong></p></td>
<td class="text-left"><p>Evaluated model RMSE on slices based on <strong>Acquisition Channel</strong> and <strong>Country</strong>. Promoted the final model to the <strong>MLflow Model Registry</strong> with a “production-ready” tag.</p></td>
<td class="text-left"><p>Slice-based evaluation ensured our model was not just accurate overall, but also fair and effective for key business segments. The Model Registry provides the formal, auditable hand-off from development to production deployment.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="a-step-by-step-experimental-journey">
<h4><strong>A Step-by-Step Experimental Journey</strong><a class="headerlink" href="#a-step-by-step-experimental-journey" title="Permalink to this heading">¶</a></h4>
<p>Our approach to model development was methodical and iterative. We started with the simplest possible baselines to establish a performance floor and justify every increase in complexity with measurable improvements in our key metrics: <strong>Root Mean Squared Error (RMSE)</strong> for predictive accuracy and the <strong>Gini Coefficient</strong> for ranking ability.</p>
<p>Here is a summary of the experiments conducted:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Experiment No.</strong></p></th>
<th class="head text-left"><p><strong>Model/Technique Applied</strong></p></th>
<th class="head text-left"><p><strong>Features Used</strong></p></th>
<th class="head text-left"><p><strong>Result &amp; Key Learning</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>1. Heuristic Baseline</strong></p></td>
<td class="text-left"><p>Calculated CLV as <code class="docutils literal notranslate"><span class="pre">(Avg.</span> <span class="pre">Monthly</span> <span class="pre">Spend</span> <span class="pre">per</span> <span class="pre">Customer)</span> <span class="pre">x</span> <span class="pre">(Avg.</span> <span class="pre">Customer</span> <span class="pre">Lifespan</span> <span class="pre">in</span> <span class="pre">Months)</span></code>.</p></td>
<td class="text-left"><p>Basic historical transaction data.</p></td>
<td class="text-left"><p><strong>Result:</strong> Provided a single, company-wide CLV number. <br> <strong>Learning:</strong> This approach was too generic. It couldn’t differentiate between new and old customers or identify high-value segments, making it unusable for personalized marketing. It served as our “minimum-bar” baseline to beat.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>2. Simple ML Baseline</strong></p></td>
<td class="text-left"><p><strong>Linear Regression</strong></p></td>
<td class="text-left"><p>Foundational RFM features (Recency, Frequency, Monetary).</p></td>
<td class="text-left"><p><strong>Result:</strong> <strong>35% reduction in RMSE</strong> compared to the error of the heuristic baseline’s single prediction. <br> <strong>Learning:</strong> This validated that even the simplest ML model, by accounting for individual customer behavior, provided a significant accuracy boost. It also proved our end-to-end data pipeline was working correctly.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>3. Probabilistic Model</strong></p></td>
<td class="text-left"><p><strong>BG/NBD + Gamma-Gamma Model</strong></p></td>
<td class="text-left"><p>Foundational RFM features.</p></td>
<td class="text-left"><p><strong>Result:</strong> Performed similarly to Linear Regression on RMSE but provided a high degree of interpretability. <br> <strong>Learning:</strong> This model was excellent for understanding churn probability and purchase frequency drivers. We decided to keep it as a secondary, explainable model for the business, but its inability to use other features limited its predictive power.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>4. Gradient Boosting Model</strong></p></td>
<td class="text-left"><p><strong>XGBoost</strong></p></td>
<td class="text-left"><p>Foundational RFM features.</p></td>
<td class="text-left"><p><strong>Result:</strong> <strong>20% further reduction in RMSE</strong> over the Linear Regression baseline. <br> <strong>Learning:</strong> XGBoost’s ability to capture non-linear relationships in the RFM features provided a substantial performance lift. This became our new champion model.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>5. Adding Temporal Features</strong></p></td>
<td class="text-left"><p>XGBoost</p></td>
<td class="text-left"><p>RFM + <strong>Time-Windowed Features</strong> (e.g., spend and frequency over the last 30, 90, 365 days).</p></td>
<td class="text-left"><p><strong>Result:</strong> <strong>15% reduction in RMSE</strong> and a significant <strong>10% increase in the Gini Coefficient</strong>. <br> <strong>Learning:</strong> Capturing <em>trends</em> in customer behavior was highly predictive. A customer whose spending is recent and increasing is far more valuable than one with the same total spend spread out over years.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>6. Adding Behavioral Features</strong></p></td>
<td class="text-left"><p>XGBoost</p></td>
<td class="text-left"><p>All previous features + <strong>Behavioral Data</strong> (e.g., session counts, add-to-cart events).</p></td>
<td class="text-left"><p><strong>Result:</strong> <strong>10% reduction in RMSE</strong>. The improvement was most pronounced for newer customers with limited transaction history. <br> <strong>Learning:</strong> Clickstream data provides powerful early signals of customer intent and engagement, helping the model make better predictions before a purchase history is established.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>7. Hyperparameter Optimization</strong></p></td>
<td class="text-left"><p><strong>XGBoost with Amazon SageMaker Automatic Model Tuning</strong> (Bayesian Optimization).</p></td>
<td class="text-left"><p>All available features.</p></td>
<td class="text-left"><p><strong>Result:</strong> <strong>5% final reduction in RMSE</strong> and a <strong>5% increase in the Gini Coefficient</strong>. <br> <strong>Learning:</strong> Automated HPO squeezed out the final percentage points of performance by fine-tuning the model’s complexity and regularization, leading to a more robust and generalized final model.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Final Outcome:</strong> Through this structured, iterative process, we developed a final XGBoost model that was over <strong>60% more accurate (in terms of RMSE)</strong> than our initial simple baseline and demonstrated a strong ability to accurately rank our most valuable customers. Each step provided valuable insights and justified the subsequent increase in complexity.</p>
</section>
</section>
<section id="ml-training-pipelines">
<h3><strong>ML Training pipelines</strong><a class="headerlink" href="#ml-training-pipelines" title="Permalink to this heading">¶</a></h3>
<section id="plan">
<h4><strong>Plan</strong><a class="headerlink" href="#plan" title="Permalink to this heading">¶</a></h4>
<p>With SageMaker Pipelines as the core execution engine, orchestrated by Airflow.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Component</p></th>
<th class="head text-left"><p>Plan &amp; Implementation Details</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Python Scripts (<code class="docutils literal notranslate"><span class="pre">src/</span></code>)</strong></p></td>
<td class="text-left"><p>We will create modular Python scripts for each step of the SageMaker Pipeline:<br> - <code class="docutils literal notranslate"><span class="pre">preprocess.py</span></code>: Loads data from the Feature Store, performs final transformations (e.g., scaling), and splits data. Saves the fitted scaler object.<br> - <code class="docutils literal notranslate"><span class="pre">train.py</span></code>: Takes preprocessed data, trains the XGBoost model, and saves the model artifact.<br> - <code class="docutils literal notranslate"><span class="pre">evaluate.py</span></code>: Takes the trained model and test data, calculates metrics (RMSE, Gini), and generates an evaluation report.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Unit Tests (<code class="docutils literal notranslate"><span class="pre">tests/</span></code>)</strong></p></td>
<td class="text-left"><p>We will write <code class="docutils literal notranslate"><span class="pre">pytest</span></code> unit tests for the business logic within <code class="docutils literal notranslate"><span class="pre">preprocess.py</span></code>, <code class="docutils literal notranslate"><span class="pre">train.py</span></code>, and <code class="docutils literal notranslate"><span class="pre">evaluate.py</span></code> to ensure their correctness in isolation.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Pipeline Code</strong></p></td>
<td class="text-left"><p>1. <strong>SageMaker Pipeline (<code class="docutils literal notranslate"><span class="pre">pipelines/build_pipeline.py</span></code>):</strong> A Python script using the SageMaker SDK to define the DAG of ML steps (Preprocess -&gt; Tune -&gt; Train -&gt; Evaluate -&gt; Register).<br> 2. <strong>Airflow DAG (<code class="docutils literal notranslate"><span class="pre">pipelines/dag_trigger_training.py</span></code>):</strong> A simple DAG that triggers the execution of the SageMaker Pipeline on a weekly schedule.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Infrastructure as Code (<code class="docutils literal notranslate"><span class="pre">terraform/</span></code>)</strong></p></td>
<td class="text-left"><p>We will add Terraform code to provision the necessary IAM roles for SageMaker Pipelines to execute and access other AWS services (S3, Feature Store, etc.).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Integration Test (<code class="docutils literal notranslate"><span class="pre">tests/</span></code>)</strong></p></td>
<td class="text-left"><p>A <code class="docutils literal notranslate"><span class="pre">pytest</span></code> integration test that will:<br> 1. Programmatically trigger the Airflow DAG.<br> 2. Poll for the completion status of the SageMaker Pipeline execution.<br> 3. Check the MLflow Model Registry to assert that a new model version was (or was not) created based on the test outcome.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Architecture Diagram (Mermaid)</strong></p></td>
<td class="text-left"><p>A single, clear diagram illustrating how Airflow triggers the SageMaker Pipeline and how the pipeline steps interact with the Feature Store, S3, and Model Registry.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Why Amazon SageMaker Pipelines for the core ML steps.</strong></p>
<p>Instead of having Airflow directly manage each individual ML step (processing, training, evaluation), a more modern and robust pattern is to use <strong>Amazon SageMaker Pipelines</strong>.</p>
<ul class="simple">
<li><p><strong>How it works:</strong> We will define the ML workflow (preprocess, train, evaluate, register) as a single, powerful SageMaker Pipeline. The Airflow DAG’s role then becomes much simpler: its only job is to <strong>trigger</strong> this SageMaker Pipeline on a schedule.</p></li>
</ul>
<p><strong>Why is this a better approach?</strong></p>
<ol class="arabic simple">
<li><p><strong>Tightly Integrated:</strong> SageMaker Pipelines are deeply integrated with the entire SageMaker ecosystem (Feature Store, Training Jobs, Model Registry). This reduces boilerplate code and simplifies passing data between steps.</p></li>
<li><p><strong>ML-Specific Features:</strong> It provides features that Airflow doesn’t have out-of-the-box, such as experiment tracking integration, caching of pipeline steps (to avoid re-running steps with unchanged inputs), and more granular ML-focused monitoring.</p></li>
<li><p><strong>Decoupling:</strong> It decouples your general-purpose orchestrator (Airflow) from your ML-specific logic. Your Airflow DAGs remain clean and simple, while the complexity of the ML workflow is encapsulated within SageMaker. This makes the system easier to maintain.</p></li>
</ol>
<p>This leverages the best of both worlds: Airflow for enterprise-wide scheduling and dependency management, and SageMaker Pipelines for its powerful, purpose-built features for orchestrating ML workflows.</p>
</section>
<section id="id1">
<h4>Implementation<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h4>
<img src="../_static/past_experiences/ecom_cltv/ml_training_pipeline.svg" style="background-color: #FCF1EF;"/>
<p><strong>Python Component Scripts</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#src/preprocess.py</span>
<span class="k">def</span> <span class="nf">clean_and_split_data</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">target_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cleans the input dataframe and splits it into training and testing sets.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): The input data.</span>
<span class="sd">        target_col (str): The name of the target variable column.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing X_train, X_test, y_train, y_test.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">target_col</span><span class="p">])</span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_cleaned</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">,</span> <span class="n">target_col</span><span class="p">,</span> <span class="s1">&#39;EventTime&#39;</span><span class="p">]]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">target_col</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">scale_features</span><span class="p">(</span><span class="n">X_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">X_test</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits a StandardScaler on the training data and transforms both training and testing data.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        X_train (pd.DataFrame): Training feature set.</span>
<span class="sd">        X_test (pd.DataFrame): Testing feature set.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing the scaled training data, scaled testing data, and the fitted scaler object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">scaler</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/train.py</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">x_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">hyperparameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains an XGBoost regressor model.</span>

<span class="sd">    Args:</span>
<span class="sd">        x_train (pd.DataFrame): Training feature data.</span>
<span class="sd">        y_train (pd.DataFrame): Training target data.</span>
<span class="sd">        hyperparameters (dict): Dictionary of hyperparameters for the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        xgb.XGBRegressor: The trained model object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
        <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;reg:squarederror&#39;</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="o">**</span><span class="n">hyperparameters</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/evaluate.py</span>
<span class="k">def</span> <span class="nf">gini_coefficient</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates the Gini coefficient to measure model ranking ability.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mf">0.0</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;pred&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cumulative_true&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>
    <span class="n">total_true</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">total_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mf">0.0</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cumulative_true_percent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cumulative_true&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_true</span>
    
    <span class="n">area_under_curve</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cumulative_true_percent&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">area_under_curve</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.5</span>

<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_test</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates the model and returns a dictionary of metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The trained model object.</span>
<span class="sd">        x_test (pd.DataFrame): Testing feature data.</span>
<span class="sd">        y_test (pd.DataFrame): Testing target data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing evaluation metrics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))</span>
    <span class="n">gini</span> <span class="o">=</span> <span class="n">gini_coefficient</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">predictions</span><span class="p">)</span>
    
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;regression_metrics&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;rmse&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="n">rmse</span><span class="p">},</span>
            <span class="s2">&quot;gini&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="n">gini</span><span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">metrics</span>
</pre></div>
</div>
<p><strong>Infrastructure as Code</strong></p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/aws_sagemaker_roles.tf</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_pipeline_execution_role&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker-pipeline-execution-role&quot;</span>

<span class="w">  </span><span class="na">assume_role_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">jsonencode</span><span class="p">({</span>
<span class="w">    </span><span class="na">Version</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2012-10-17&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">Statement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nb">Principal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="na">Service</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker.amazonaws.com&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="na">Action</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sts:AssumeRole&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>

<span class="c1"># Granting broad SageMaker permissions for simplicity in this example.</span>
<span class="c1"># In a real production environment, you would scope this down significantly.</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role_policy_attachment&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_full_access&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">role</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.sagemaker_pipeline_execution_role.name</span>
<span class="w">  </span><span class="na">policy_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;arn:aws:iam::aws:policy/AmazonSageMakerFullAccess&quot;</span>
<span class="p">}</span>

<span class="c1"># Policy allowing access to the S3 bucket for artifacts and the Feature Store</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_policy&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_pipeline_custom_policy&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker-pipeline-s3-featurestore-policy&quot;</span>
<span class="w">  </span><span class="na">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allows SageMaker pipelines to access project resources&quot;</span>

<span class="w">  </span><span class="na">policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">jsonencode</span><span class="p">({</span>
<span class="w">    </span><span class="na">Version</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2012-10-17&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">Statement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="na">Action</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">          </span><span class="s2">&quot;s3:GetObject&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;s3:PutObject&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;s3:ListBucket&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="na">Resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">          </span><span class="s2">&quot;arn:aws:s3:::clv-artifacts-bucket&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;arn:aws:s3:::clv-artifacts-bucket/*&quot;</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="na">Action</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">          </span><span class="s2">&quot;sagemaker:DescribeFeatureGroup&quot;</span><span class="p">,</span>
<span class="c1">          # Permissions for Athena query to get data from offline store</span>
<span class="w">          </span><span class="s2">&quot;athena:StartQueryExecution&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;athena:GetQueryExecution&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;athena:GetQueryResults&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s2">&quot;glue:GetTable&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="na">Resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="c1"> # Scope down in production</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role_policy_attachment&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_pipeline_custom_policy_attach&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">role</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.sagemaker_pipeline_execution_role.name</span>
<span class="w">  </span><span class="na">policy_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_policy.sagemaker_pipeline_custom_policy.arn</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>SageMaker Pipeline Definition</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/build_pipeline.py</span>
<span class="kn">import</span> <span class="nn">sagemaker</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.steps</span> <span class="kn">import</span> <span class="n">ProcessingStep</span><span class="p">,</span> <span class="n">TrainingStep</span>
<span class="kn">from</span> <span class="nn">sagemaker.processing</span> <span class="kn">import</span> <span class="n">ScriptProcessor</span><span class="p">,</span> <span class="n">ProcessingInput</span><span class="p">,</span> <span class="n">ProcessingOutput</span>
<span class="kn">from</span> <span class="nn">sagemaker.sklearn.estimator</span> <span class="kn">import</span> <span class="n">SKLearn</span>
<span class="kn">from</span> <span class="nn">sagemaker.xgboost.estimator</span> <span class="kn">import</span> <span class="n">XGBoost</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.conditions</span> <span class="kn">import</span> <span class="n">ConditionLessThanOrEqualTo</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.condition_step</span> <span class="kn">import</span> <span class="n">ConditionStep</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.functions</span> <span class="kn">import</span> <span class="n">JsonGet</span>
<span class="kn">from</span> <span class="nn">sagemaker.model_metrics</span> <span class="kn">import</span> <span class="n">ModelMetrics</span><span class="p">,</span> <span class="n">MetricsSource</span>
<span class="kn">from</span> <span class="nn">sagemaker.workflow.model_step</span> <span class="kn">import</span> <span class="n">ModelStep</span>
<span class="kn">import</span> <span class="nn">boto3</span>

<span class="k">def</span> <span class="nf">get_sagemaker_pipeline</span><span class="p">(</span><span class="n">role</span><span class="p">,</span> <span class="n">s3_bucket</span><span class="p">):</span>
    <span class="c1"># Define Processors</span>
    <span class="n">sklearn_processor</span> <span class="o">=</span> <span class="n">ScriptProcessor</span><span class="p">(</span>
        <span class="n">image_uri</span><span class="o">=</span><span class="s1">&#39;your-account-id.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-scikit-learn:1.0-1&#39;</span><span class="p">,</span> <span class="c1"># Replace with your ECR image URI for sklearn</span>
        <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;python3&#39;</span><span class="p">],</span>
        <span class="n">instance_type</span><span class="o">=</span><span class="s1">&#39;ml.m5.large&#39;</span><span class="p">,</span>
        <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">base_job_name</span><span class="o">=</span><span class="s1">&#39;clv-preprocess&#39;</span><span class="p">,</span>
        <span class="n">role</span><span class="o">=</span><span class="n">role</span>
    <span class="p">)</span>

    <span class="c1"># 1. Preprocessing Step</span>
    <span class="n">step_preprocess</span> <span class="o">=</span> <span class="n">ProcessingStep</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;PreprocessData&quot;</span><span class="p">,</span>
        <span class="n">processor</span><span class="o">=</span><span class="n">sklearn_processor</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">ProcessingInput</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;s3://</span><span class="si">{</span><span class="n">s3_bucket</span><span class="si">}</span><span class="s2">/feature-data/features.csv&quot;</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/input&quot;</span><span class="p">)],</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span>
            <span class="n">ProcessingOutput</span><span class="p">(</span><span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/output/train&quot;</span><span class="p">),</span>
            <span class="n">ProcessingOutput</span><span class="p">(</span><span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/output/test&quot;</span><span class="p">),</span>
            <span class="n">ProcessingOutput</span><span class="p">(</span><span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/output/scaler&quot;</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">code</span><span class="o">=</span><span class="s2">&quot;src/preprocess.py&quot;</span>
    <span class="p">)</span>

    <span class="c1"># 2. Training Step</span>
    <span class="n">xgb_estimator</span> <span class="o">=</span> <span class="n">XGBoost</span><span class="p">(</span>
        <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;src/train.py&quot;</span><span class="p">,</span>
        <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
        <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">instance_type</span><span class="o">=</span><span class="s1">&#39;ml.m5.xlarge&#39;</span><span class="p">,</span>
        <span class="n">framework_version</span><span class="o">=</span><span class="s1">&#39;1.5-1&#39;</span><span class="p">,</span>
        <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">150</span><span class="p">}</span>
    <span class="p">)</span>
    
    <span class="n">step_train</span> <span class="o">=</span> <span class="n">TrainingStep</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;TrainModel&quot;</span><span class="p">,</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_estimator</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">TrainingInput</span><span class="p">(</span>
                <span class="n">s3_data</span><span class="o">=</span><span class="n">step_preprocess</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">ProcessingOutputConfig</span><span class="o">.</span><span class="n">Outputs</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">S3Output</span><span class="o">.</span><span class="n">S3Uri</span>
            <span class="p">)</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># 3. Evaluation Step</span>
    <span class="n">step_evaluate</span> <span class="o">=</span> <span class="n">ProcessingStep</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;EvaluateModel&quot;</span><span class="p">,</span>
        <span class="n">processor</span><span class="o">=</span><span class="n">sklearn_processor</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span>
            <span class="n">ProcessingInput</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">step_train</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">ModelArtifacts</span><span class="o">.</span><span class="n">S3ModelArtifacts</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/model&quot;</span><span class="p">),</span>
            <span class="n">ProcessingInput</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">step_preprocess</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">ProcessingOutputConfig</span><span class="o">.</span><span class="n">Outputs</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">S3Output</span><span class="o">.</span><span class="n">S3Uri</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/test&quot;</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">ProcessingOutput</span><span class="p">(</span><span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;evaluation&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;/opt/ml/processing/evaluation&quot;</span><span class="p">)],</span>
        <span class="n">code</span><span class="o">=</span><span class="s2">&quot;src/evaluate.py&quot;</span>
    <span class="p">)</span>

    <span class="c1"># 4. Conditional Model Registration Step</span>
    <span class="n">model_metrics</span> <span class="o">=</span> <span class="n">ModelMetrics</span><span class="p">(</span>
        <span class="n">model_statistics</span><span class="o">=</span><span class="n">MetricsSource</span><span class="p">(</span>
            <span class="n">s3_uri</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">step_evaluate</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">ProcessingOutputConfig</span><span class="o">.</span><span class="n">Outputs</span><span class="p">[</span><span class="s1">&#39;evaluation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">S3Output</span><span class="o">.</span><span class="n">S3Uri</span><span class="si">}</span><span class="s2">/evaluation.json&quot;</span><span class="p">,</span>
            <span class="n">content_type</span><span class="o">=</span><span class="s2">&quot;application/json&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Define a condition to check if RMSE is below a threshold</span>
    <span class="n">cond_lte</span> <span class="o">=</span> <span class="n">ConditionLessThanOrEqualTo</span><span class="p">(</span>
        <span class="n">left</span><span class="o">=</span><span class="n">JsonGet</span><span class="p">(</span>
            <span class="n">step_name</span><span class="o">=</span><span class="n">step_evaluate</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">property_file</span><span class="o">=</span><span class="s2">&quot;evaluation.json&quot;</span><span class="p">,</span>
            <span class="n">json_path</span><span class="o">=</span><span class="s2">&quot;regression_metrics.rmse.value&quot;</span>
        <span class="p">),</span>
        <span class="n">right</span><span class="o">=</span><span class="mf">250.0</span>  <span class="c1"># Your RMSE threshold</span>
    <span class="p">)</span>
    
    <span class="c1"># Define the registration step</span>
    <span class="c1"># First, create a model package</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
        <span class="n">image_uri</span><span class="o">=</span><span class="n">xgb_estimator</span><span class="o">.</span><span class="n">image_uri</span><span class="p">,</span>
        <span class="n">model_data</span><span class="o">=</span><span class="n">step_train</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">ModelArtifacts</span><span class="o">.</span><span class="n">S3ModelArtifacts</span><span class="p">,</span>
        <span class="n">sagemaker_session</span><span class="o">=</span><span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">(),</span>
        <span class="n">role</span><span class="o">=</span><span class="n">role</span>
    <span class="p">)</span>
    
    <span class="n">step_create_model</span> <span class="o">=</span> <span class="n">ModelStep</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;CreateModelPackage&quot;</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">model_package_group_name</span><span class="o">=</span><span class="s2">&quot;CLVModelPackageGroup&quot;</span> <span class="c1"># Must be created beforehand</span>
    <span class="p">)</span>

    <span class="n">step_conditional_register</span> <span class="o">=</span> <span class="n">ConditionStep</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;CheckEvaluationAndRegister&quot;</span><span class="p">,</span>
        <span class="n">conditions</span><span class="o">=</span><span class="p">[</span><span class="n">cond_lte</span><span class="p">],</span>
        <span class="n">if_steps</span><span class="o">=</span><span class="p">[</span><span class="n">step_create_model</span><span class="p">],</span>
        <span class="n">else_steps</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">)</span>

    <span class="c1"># Create and return the pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;CLV-Training-Pipeline&quot;</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">steps</span><span class="o">=</span><span class="p">[</span><span class="n">step_preprocess</span><span class="p">,</span> <span class="n">step_train</span><span class="p">,</span> <span class="n">step_evaluate</span><span class="p">,</span> <span class="n">step_conditional_register</span><span class="p">],</span>
        <span class="n">sagemaker_session</span><span class="o">=</span><span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">pipeline</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># This part is for creating/updating the pipeline definition in SageMaker</span>
    <span class="n">sagemaker_role_arn</span> <span class="o">=</span> <span class="s2">&quot;arn:aws:iam::ACCOUNT_ID:role/sagemaker-pipeline-execution-role&quot;</span> <span class="c1"># Replace</span>
    <span class="n">s3_artifact_bucket</span> <span class="o">=</span> <span class="s2">&quot;clv-artifacts-bucket&quot;</span> <span class="c1"># Replace</span>
    
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">get_sagemaker_pipeline</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="n">sagemaker_role_arn</span><span class="p">,</span> <span class="n">s3_bucket</span><span class="o">=</span><span class="n">s3_artifact_bucket</span><span class="p">)</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">upsert</span><span class="p">(</span><span class="n">role_arn</span><span class="o">=</span><span class="n">sagemaker_role_arn</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Airflow DAG</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_trigger_training.py</span>
<span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerPipelineOperator</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_trigger_sagemaker_training&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;@weekly&quot;</span><span class="p">,</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;training&#39;</span><span class="p">,</span> <span class="s1">&#39;sagemaker&#39;</span><span class="p">],</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    <span class="n">trigger_sagemaker_pipeline</span> <span class="o">=</span> <span class="n">SageMakerPipelineOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;trigger_training_pipeline&quot;</span><span class="p">,</span>
        <span class="n">pipeline_name</span><span class="o">=</span><span class="s2">&quot;CLV-Training-Pipeline&quot;</span><span class="p">,</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p><strong>Integration Test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/integration/test_training_pipeline_integration.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">airflow.models.dagbag</span> <span class="kn">import</span> <span class="n">DagBag</span>
<span class="kn">from</span> <span class="nn">airflow.models.dagrun</span> <span class="kn">import</span> <span class="n">DagRun</span>
<span class="kn">from</span> <span class="nn">airflow.utils.state</span> <span class="kn">import</span> <span class="n">State</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span> <span class="nf">test_training_pipeline_dag_runs_successfully</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tests the end-to-end execution by triggering the Airflow DAG</span>
<span class="sd">    and monitoring the SageMaker Pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load the Airflow DAG</span>
    <span class="n">dagbag</span> <span class="o">=</span> <span class="n">DagBag</span><span class="p">(</span><span class="n">dag_folder</span><span class="o">=</span><span class="s1">&#39;pipelines/&#39;</span><span class="p">,</span> <span class="n">include_examples</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dag</span> <span class="o">=</span> <span class="n">dagbag</span><span class="o">.</span><span class="n">get_dag</span><span class="p">(</span><span class="s1">&#39;clv_trigger_sagemaker_training&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">dag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;DAG not found&quot;</span>

    <span class="c1"># Manually trigger the DAG</span>
    <span class="n">dag</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">dag_run</span> <span class="o">=</span> <span class="n">dag</span><span class="o">.</span><span class="n">create_dagrun</span><span class="p">(</span>
        <span class="n">state</span><span class="o">=</span><span class="n">State</span><span class="o">.</span><span class="n">RUNNING</span><span class="p">,</span>
        <span class="n">run_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test_run_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">conf</span><span class="o">=</span><span class="p">{},</span>
    <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Triggered DAG run: </span><span class="si">{</span><span class="n">dag_run</span><span class="o">.</span><span class="n">run_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Monitor the DAG run and the underlying SageMaker Pipeline</span>
    <span class="c1"># This is a simplified check. A real-world test would need more robust polling.</span>
    <span class="n">sagemaker_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sagemaker&quot;</span><span class="p">)</span>
    
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span> <span class="c1"># Give Airflow time to start the SageMaker Pipeline</span>

    <span class="c1"># Find the latest pipeline execution</span>
    <span class="n">executions</span> <span class="o">=</span> <span class="n">sagemaker_client</span><span class="o">.</span><span class="n">list_pipeline_executions</span><span class="p">(</span>
        <span class="n">PipelineName</span><span class="o">=</span><span class="s2">&quot;CLV-Training-Pipeline&quot;</span><span class="p">,</span>
        <span class="n">SortBy</span><span class="o">=</span><span class="s2">&quot;CreationTime&quot;</span><span class="p">,</span>
        <span class="n">SortOrder</span><span class="o">=</span><span class="s2">&quot;Descending&quot;</span>
    <span class="p">)[</span><span class="s1">&#39;PipelineExecutionSummaries&#39;</span><span class="p">]</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">executions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;No SageMaker pipeline execution found&quot;</span>
    
    <span class="n">latest_execution_arn</span> <span class="o">=</span> <span class="n">executions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;PipelineExecutionArn&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Monitoring SageMaker Pipeline execution: </span><span class="si">{</span><span class="n">latest_execution_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Poll until the pipeline execution is complete</span>
    <span class="n">timeout</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">+</span> <span class="mi">60</span><span class="o">*</span><span class="mi">30</span> <span class="c1"># 30 minutes timeout</span>
    <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">sagemaker_client</span><span class="o">.</span><span class="n">describe_pipeline_execution</span><span class="p">(</span>
            <span class="n">PipelineExecutionArn</span><span class="o">=</span><span class="n">latest_execution_arn</span>
        <span class="p">)</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;PipelineExecutionStatus&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">status</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Succeeded&#39;</span><span class="p">,</span> <span class="s1">&#39;Failed&#39;</span><span class="p">,</span> <span class="s1">&#39;Stopped&#39;</span><span class="p">]:</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pipeline status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">. Waiting...&quot;</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">status</span> <span class="o">==</span> <span class="s1">&#39;Succeeded&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;SageMaker pipeline did not succeed. Final status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># ASSERTION: Check if a new model was registered in the MLflow Model Registry</span>
    <span class="c1"># (This would require MLflow client setup and querying logic)</span>
    <span class="c1"># mlflow_client = mlflow.tracking.MlflowClient()</span>
    <span class="c1"># versions = mlflow_client.get_latest_versions(&quot;clv-model&quot;)</span>
    <span class="c1"># assert len(versions) &gt; 0, &quot;No model was registered in MLflow&quot;</span>
</pre></div>
</div>
</section>
<section id="ml-training-pipeline-ci-workflow">
<h4><strong>ML Training Pipeline CI Workflow</strong><a class="headerlink" href="#ml-training-pipeline-ci-workflow" title="Permalink to this heading">¶</a></h4>
<p>Here is the plan and the corresponding GitHub Actions workflow file.</p>
<ol class="arabic simple">
<li><p><strong>Trigger:</strong> The workflow will be automatically triggered on every <code class="docutils literal notranslate"><span class="pre">pull_request</span></code> to the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch. This ensures that no code can be merged without passing all quality checks.</p></li>
<li><p><strong>Environment Setup:</strong> It will check out the code and set up a clean Python environment with all necessary dependencies. It will also securely configure AWS credentials to allow for interaction with AWS services during testing.</p></li>
<li><p><strong>Static Analysis:</strong> It will run fast, static checks first, including code linting (<code class="docutils literal notranslate"><span class="pre">flake8</span></code>) and formatting checks (<code class="docutils literal notranslate"><span class="pre">black</span></code>), to catch basic errors without needing to execute any code.</p></li>
<li><p><strong>Unit Testing:</strong> It will execute the <code class="docutils literal notranslate"><span class="pre">pytest</span></code> suite located in the <code class="docutils literal notranslate"><span class="pre">tests/unit/</span></code> directory. This validates that the core logic within our Python scripts (<code class="docutils literal notranslate"><span class="pre">preprocess.py</span></code>, <code class="docutils literal notranslate"><span class="pre">train.py</span></code>, <code class="docutils literal notranslate"><span class="pre">evaluate.py</span></code>) works as expected in isolation.</p></li>
<li><p><strong>Pipeline Integrity &amp; Integration Testing:</strong> This is the most crucial part. It validates that all the pieces of our training pipeline work together.</p>
<ul class="simple">
<li><p><strong>Terraform Validation:</strong> It will run <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">validate</span></code> and <code class="docutils literal notranslate"><span class="pre">tflint</span></code> on our infrastructure code to catch syntax errors or non-best-practice configurations.</p></li>
<li><p><strong>SageMaker Pipeline Definition Test:</strong> It will execute our <code class="docutils literal notranslate"><span class="pre">pipelines/build_pipeline.py</span></code> script. The script will be designed to build the SageMaker Pipeline object in memory without actually deploying it. This acts as a powerful integration test, confirming that all the SDK calls and parameter integrations are correct and that the pipeline definition can be successfully compiled.</p></li>
</ul>
</li>
</ol>
<p>If all these steps pass, the pull request will show a green checkmark, giving the repository maintainer confidence that the proposed changes are safe to merge.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># .github/workflows/ci_training_pipeline.yml</span>

<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;CI</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">ML</span><span class="nv"> </span><span class="s">Training</span><span class="nv"> </span><span class="s">Pipeline&quot;</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
<span class="w">    </span><span class="nt">paths</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;src/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;tests/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;terraform/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;.github/workflows/ci_training_pipeline.yml&#39;</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">validate-training-pipeline</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span>
<span class="w">    </span><span class="nt">permissions</span><span class="p">:</span>
<span class="w">      </span><span class="nt">id-token</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">write</span><span class="w">  </span><span class="c1"># Required for OIDC AWS authentication</span>
<span class="w">      </span><span class="nt">contents</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">read</span>
<span class="w">      </span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout Repository</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v4</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python 3.9</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.9</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install Python Dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">python -m pip install --upgrade pip</span>
<span class="w">          </span><span class="no">pip install -r requirements.txt # Assuming a requirements.txt in the root</span>
<span class="w">          </span><span class="no">pip install -r tests/requirements.txt # For test-specific libraries like pytest, moto</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Configure AWS Credentials</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aws-actions/configure-aws-credentials@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">role-to-assume</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-ci-role</span><span class="w"> </span><span class="c1"># Replace with your IAM role for GitHub Actions</span>
<span class="w">          </span><span class="nt">aws-region</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eu-west-1</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run Linting and Formatting Checks</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install flake8 black</span>
<span class="w">          </span><span class="no">flake8 src/ pipelines/ tests/</span>
<span class="w">          </span><span class="no">black --check src/ pipelines/ tests/</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run Unit Tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pytest tests/unit/</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Setup Terraform</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hashicorp/setup-terraform@v2</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Validate Infrastructure as Code (Terraform)</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">cd terraform</span>
<span class="w">          </span><span class="no">terraform init -backend=false</span>
<span class="w">          </span><span class="no">terraform validate</span>
<span class="w">          </span><span class="no">tflint --recursive</span>
<span class="w">        </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Validate SageMaker Pipeline Definition</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no"># This step runs the pipeline build script.</span>
<span class="w">          </span><span class="no"># The script should be designed to build the pipeline object</span>
<span class="w">          </span><span class="no"># and perform validations without deploying.</span>
<span class="w">          </span><span class="no"># We can add a --dry-run flag to our script for this purpose.</span>
<span class="w">          </span><span class="no">python pipelines/build_pipeline.py --role-arn ${{ secrets.SAGEMAKER_EXECUTION_ROLE_ARN }} --bucket-name ${{ secrets.ARTIFACT_BUCKET }} --dry-run</span>
</pre></div>
</div>
</section>
<section id="ml-training-pipeline-cd-workflow-plan">
<h4><strong>ML Training Pipeline CD Workflow Plan</strong><a class="headerlink" href="#ml-training-pipeline-cd-workflow-plan" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>Trigger:</strong> The workflow is triggered on every <code class="docutils literal notranslate"><span class="pre">push</span></code> to the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch.</p></li>
<li><p><strong>Deploy Pipeline to Staging:</strong> It runs the <code class="docutils literal notranslate"><span class="pre">pipelines/build_pipeline.py</span></code> script without the <code class="docutils literal notranslate"><span class="pre">--dry-run</span></code> flag, pointing to the staging AWS environment. This <code class="docutils literal notranslate"><span class="pre">upsert</span></code> action creates or updates the SageMaker Pipeline definition.</p></li>
<li><p><strong>Run Pipeline in Staging:</strong> It then makes an AWS API call to start an execution of this newly deployed SageMaker Pipeline.</p></li>
<li><p><strong>Monitor Run:</strong> The final step is to wait for the pipeline execution to complete and check its status. If the pipeline run fails in Staging, the entire CD workflow fails.</p></li>
</ol>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># .github/workflows/cd_training_pipeline.yml</span>

<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;CD</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">ML</span><span class="nv"> </span><span class="s">Training</span><span class="nv"> </span><span class="s">Pipeline&quot;</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
<span class="w">    </span><span class="nt">paths</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;src/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/**&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;terraform/**&#39;</span>
<span class="w">      </span>
<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">deploy-and-run-in-staging</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">staging</span><span class="w"> </span><span class="c1"># This links to GitHub Environments for managing secrets</span>
<span class="w">    </span>
<span class="w">    </span><span class="nt">permissions</span><span class="p">:</span>
<span class="w">      </span><span class="nt">id-token</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">write</span>
<span class="w">      </span><span class="nt">contents</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">read</span>
<span class="w">      </span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout Repository</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v4</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python 3.9</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.9</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install Python Dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install -r requirements.txt</span>
<span class="w">          </span><span class="no">pip install boto3</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Configure Staging AWS Credentials</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aws-actions/configure-aws-credentials@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">role-to-assume</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ secrets.STAGING_AWS_ROLE_ARN }}</span><span class="w"> </span><span class="c1"># Secret stored in GitHub Environment</span>
<span class="w">          </span><span class="nt">aws-region</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eu-west-1</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deploy SageMaker Pipeline to Staging</span>
<span class="w">        </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">deploy_pipeline</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">echo &quot;Deploying SageMaker Pipeline definition to Staging...&quot;</span>
<span class="w">          </span><span class="no">python pipelines/build_pipeline.py \</span>
<span class="w">            </span><span class="no">--role-arn ${{ secrets.STAGING_SAGEMAKER_ROLE_ARN }} \</span>
<span class="w">            </span><span class="no">--bucket-name ${{ secrets.STAGING_ARTIFACT_BUCKET }}</span>
<span class="w">      </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Start SageMaker Pipeline Execution in Staging</span>
<span class="w">        </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">start_execution</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">echo &quot;Starting pipeline execution...&quot;</span>
<span class="w">          </span><span class="no">EXECUTION_ARN=$(aws sagemaker start-pipeline-execution \</span>
<span class="w">            </span><span class="no">--pipeline-name CLV-Training-Pipeline \</span>
<span class="w">            </span><span class="no">--query &#39;PipelineExecutionArn&#39; \</span>
<span class="w">            </span><span class="no">--output text)</span>
<span class="w">          </span><span class="no">echo &quot;Pipeline execution started: $EXECUTION_ARN&quot;</span>
<span class="w">          </span><span class="no">echo &quot;execution_arn=$EXECUTION_ARN&quot; &gt;&gt; $GITHUB_OUTPUT</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Wait for Pipeline Execution to Complete</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">echo &quot;Waiting for pipeline execution to complete...&quot;</span>
<span class="w">          </span><span class="no">aws sagemaker wait pipeline-execution-complete --pipeline-execution-arn ${{ steps.start_execution.outputs.execution_arn }}</span>
<span class="w">          </span>
<span class="w">          </span><span class="no">echo &quot;Checking final status...&quot;</span>
<span class="w">          </span><span class="no">STATUS=$(aws sagemaker describe-pipeline-execution --pipeline-execution-arn ${{ steps.start_execution.outputs.execution_arn }} --query &#39;PipelineExecutionStatus&#39; --output text)</span>
<span class="w">          </span>
<span class="w">          </span><span class="no">if [ &quot;$STATUS&quot; != &quot;Succeeded&quot; ]; then</span>
<span class="w">            </span><span class="no">echo &quot;Pipeline execution failed with status: $STATUS&quot;</span>
<span class="w">            </span><span class="no">exit 1</span>
<span class="w">          </span><span class="no">fi</span>
<span class="w">          </span><span class="no">echo &quot;Pipeline execution succeeded!&quot;</span>
</pre></div>
</div>
</section>
</section>
<section id="inference-pipeline">
<h3><strong>Inference Pipeline</strong><a class="headerlink" href="#inference-pipeline" title="Permalink to this heading">¶</a></h3>
<section id="high-level-strategy-choosing-the-deployment-pattern">
<h4><strong>1. High-Level Strategy: Choosing the Deployment Pattern</strong><a class="headerlink" href="#high-level-strategy-choosing-the-deployment-pattern" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Business Need:</strong> The primary goal is to provide updated CLV scores for the marketing and CRM teams to design weekly or monthly campaigns.</p></li>
<li><p><strong>Latency Requirement:</strong> Predictions are not needed in real-time. A delay of several hours is perfectly acceptable.</p></li>
<li><p><strong>Data Freshness:</strong> Features are updated daily, so predictions based on daily-refreshed data are sufficient.</p></li>
</ul>
<p><strong>Decision:</strong> Based on these requirements, we will implement a <strong>Batch Prediction (Asynchronous Inference)</strong> strategy. This pattern is ideal for our use case because it is “simpler to implement, cost-effective for large volumes, and allows for high throughput.”</p>
</section>
<section id="architectural-plan-components-and-tooling">
<h4><strong>2. Architectural Plan: Components and Tooling</strong><a class="headerlink" href="#architectural-plan-components-and-tooling" title="Permalink to this heading">¶</a></h4>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Component / Consideration</p></th>
<th class="head text-left"><p>Decision / Implementation Choice</p></th>
<th class="head text-left"><p>Rationale (Applying the Guide)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Workflow Orchestrator</strong></p></td>
<td class="text-left"><p><strong>Apache Airflow (on AWS MWAA)</strong></p></td>
<td class="text-left"><p>Aligns with our existing tech stack for the training pipeline. Airflow is the industry standard for scheduling and managing complex, multi-step batch jobs, as highlighted in the guide.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Batch Prediction Job/Processor</strong></p></td>
<td class="text-left"><p><strong>Amazon SageMaker Batch Transform</strong></p></td>
<td class="text-left"><p>This is a fully managed AWS service purpose-built for this task. It eliminates the need to manage our own compute cluster for inference, which is more cost-effective and operationally simpler than using a persistent EMR cluster for this job. It directly aligns with the “Cloud Services” tooling mentioned in the guide.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Model Source</strong></p></td>
<td class="text-left"><p><strong>MLflow Model Registry</strong></p></td>
<td class="text-left"><p>The pipeline will be configured to automatically fetch the model version currently tagged as <strong>“Production”</strong> from our MLflow Model Registry. This ensures a governed, auditable link between a production run and a specific, approved model artifact</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Feature Source</strong></p></td>
<td class="text-left"><p><strong>Amazon SageMaker Feature Store</strong></p></td>
<td class="text-left"><p>To prevent training-serving skew, the Batch Transform job will not re-calculate features. Instead, it will retrieve the latest pre-calculated features for each customer directly from the SageMaker Feature Store. This guarantees consistency between the features used for training and inference.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Input Data Source</strong></p></td>
<td class="text-left"><p><strong>S3 Bucket</strong></p></td>
<td class="text-left"><p>A simple text file containing the list of all active <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code>s to be scored will be the input for the Batch Transform job.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Prediction Store</strong></p></td>
<td class="text-left"><p><strong>1. S3 Bucket (Primary Output)</strong> <br> <strong>2. Data Warehouse (e.g., Redshift)</strong></p></td>
<td class="text-left"><p>The Batch Transform job will write its output (a CSV/Parquet file of <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code>, <code class="docutils literal notranslate"><span class="pre">CLV_Prediction</span></code>, <code class="docutils literal notranslate"><span class="pre">ModelVersion</span></code>, <code class="docutils literal notranslate"><span class="pre">PredictionTimestamp</span></code>) to a designated S3 bucket. A final step in the Airflow DAG will then load this data into the main data warehouse, making it accessible to BI tools and marketing platforms.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="core-pipeline-artifacts-to-be-implemented">
<h4><strong>3. Core Pipeline Artifacts to Be Implemented</strong><a class="headerlink" href="#core-pipeline-artifacts-to-be-implemented" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>Inference Script (<code class="docutils literal notranslate"><span class="pre">src/batch_inference.py</span></code>):</strong> A Python script containing the core transformation logic. This script will define how SageMaker Batch Transform should handle incoming data, load the model, fetch features, and generate a prediction.</p></li>
<li><p><strong>Airflow DAG (<code class="docutils literal notranslate"><span class="pre">pipelines/dag_batch_inference.py</span></code>):</strong> The orchestration logic that defines the end-to-end pipeline:</p>
<ul class="simple">
<li><p><strong>Trigger:</strong> Runs on a weekly schedule.</p></li>
<li><p><strong>Steps:</strong></p>
<ol class="arabic simple">
<li><p>Fetch the S3 URI of the “Production” model from the MLflow Model Registry.</p></li>
<li><p>Initiate the SageMaker Batch Transform job, passing the model URI and the location of the active customer list.</p></li>
<li><p>Monitor the job until completion.</p></li>
<li><p>Upon success, trigger a subsequent task to load the predictions from the output S3 bucket into the data warehouse.</p></li>
</ol>
</li>
</ul>
</li>
<li><p><strong>Infrastructure as Code (<code class="docutils literal notranslate"><span class="pre">terraform/aws_sagemaker_inference.tf</span></code>):</strong> Terraform code to provision the necessary IAM roles and permissions for the SageMaker Batch Transform job to access S3, the Feature Store, and the Model Registry.</p></li>
<li><p><strong>Architecture Diagram (Mermaid Code):</strong> A clear diagram illustrating the entire batch inference flow.</p></li>
</ol>
</section>
<section id="testing-the-inference-pipeline-in-a-staging-environment">
<h4><strong>4. Testing the Inference Pipeline in a Staging Environment</strong><a class="headerlink" href="#testing-the-inference-pipeline-in-a-staging-environment" title="Permalink to this heading">¶</a></h4>
<p>Following the principles in the guide, we must test the inference pipeline’s code and infrastructure, not just the model.</p>
<ul class="simple">
<li><p><strong>Objective:</strong> To validate that the entire pipeline mechanism works correctly before deploying it to production. This includes testing the Airflow DAG logic, the inference script, and all IAM permissions.</p></li>
<li><p><strong>Process:</strong></p>
<ol class="arabic simple">
<li><p>A <strong>staging version of the Airflow DAG</strong> will be deployed to our staging Airflow instance.</p></li>
<li><p>This DAG will be configured to use a <strong>“Staging” tagged model</strong> from the MLflow registry.</p></li>
<li><p>The pipeline will be run against a <strong>small, representative sample</strong> of staging customer data.</p></li>
</ol>
</li>
<li><p><strong>Success Criteria:</strong></p>
<ul>
<li><p>The DAG completes successfully without any operational errors.</p></li>
<li><p>The SageMaker Batch Transform job runs without permission or code errors.</p></li>
<li><p>The output predictions are written to the staging S3 bucket in the correct format and schema.</p></li>
</ul>
</li>
</ul>
</section>
<section id="ci-cd-for-the-inference-pipeline">
<h4><strong>5. CI/CD for the Inference Pipeline</strong><a class="headerlink" href="#ci-cd-for-the-inference-pipeline" title="Permalink to this heading">¶</a></h4>
<p>As discussed, this pipeline requires its own CI/CD workflow, separate from the training pipeline.</p>
<ul class="simple">
<li><p><strong>Continuous Integration (CI):</strong> Triggered on a pull request with changes to the inference pipeline code.</p>
<ul>
<li><p>Runs static analysis and unit tests on <code class="docutils literal notranslate"><span class="pre">src/batch_inference.py</span></code>.</p></li>
<li><p>Validates the Airflow DAG syntax.</p></li>
<li><p>Validates the Terraform configuration for inference resources.</p></li>
</ul>
</li>
<li><p><strong>Continuous Delivery (CD):</strong> Triggered on a merge to the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch.</p>
<ul>
<li><p>Deploys the updated Airflow DAG to the <strong>Staging Airflow environment</strong>.</p></li>
<li><p>Automatically runs the <strong>Staging Test</strong> described in the section above to verify the full pipeline execution.</p></li>
<li><p>Requires manual approval to deploy the DAG to the <strong>Production Airflow environment</strong>.</p></li>
</ul>
</li>
</ul>
<p>This plan provides a robust, secure, and cost-effective solution for our batch inference needs, directly applying the best practices for Model Serving</p>
</section>
<section id="id2">
<h4>Implementation<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h4>
<p><strong>Batch Inference Pipeline Architecture Diagram</strong>
<img src="../_static/past_experiences/ecom_cltv/inference_pipeline.svg" style="background-color: #FCF1EF;"/></p>
<p><strong>Infrastructure as Code</strong></p>
<p>This Terraform code provisions the IAM Role that the SageMaker jobs (both the Transform job and the model object itself) will use.</p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/aws_sagemaker_inference.tf</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_inference_role&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker-inference-execution-role&quot;</span>

<span class="w">  </span><span class="na">assume_role_policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">jsonencode</span><span class="p">({</span>
<span class="w">    </span><span class="na">Version</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2012-10-17&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">Statement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nb">Principal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="na">Service</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker.amazonaws.com&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="na">Action</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sts:AssumeRole&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>

<span class="c1"># This policy grants the necessary permissions for the batch transform job</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_policy&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_inference_policy&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;sagemaker-inference-policy&quot;</span>
<span class="w">  </span><span class="na">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allows SageMaker to run batch inference jobs for the CLV project&quot;</span>

<span class="w">  </span><span class="na">policy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">jsonencode</span><span class="p">({</span>
<span class="w">    </span><span class="na">Version</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2012-10-17&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">Statement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="na">Action</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;s3:GetObject&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s2">&quot;s3:PutObject&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s2">&quot;s3:ListBucket&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="na">Resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;arn:aws:s3:::clv-artifacts-bucket/*&quot;</span><span class="p">,</span><span class="c1"> # Access to model artifacts</span>
<span class="w">            </span><span class="s2">&quot;arn:aws:s3:::clv-inference-data-bucket/*&quot;</span><span class="c1"> # Access to input/output data</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="na">Action</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;sagemaker:GetRecord&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="na">Resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;arn:aws:sagemaker:eu-west-1:${data.aws_caller_identity.current.account_id}:feature-group/*&quot;</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="na">Effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="na">Action</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;logs:CreateLogStream&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s2">&quot;logs:PutLogEvents&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s2">&quot;logs:CreateLogGroup&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s2">&quot;logs:DescribeLogStreams&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="na">Resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;arn:aws:logs:*:*:*&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">})</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_iam_role_policy_attachment&quot;</span><span class="w"> </span><span class="nv">&quot;sagemaker_inference_policy_attach&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">role</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_role.sagemaker_inference_role.name</span>
<span class="w">  </span><span class="na">policy_arn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">aws_iam_policy.sagemaker_inference_policy.arn</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Inference Script</strong></p>
<p>This is the core logic that runs inside the SageMaker Batch Transform job. It handles loading the model, fetching features from the Feature Store, and making predictions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/batch_inference.py</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">model_dir</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the model and the scaler from the model directory.</span>
<span class="sd">    SageMaker will place the contents of the model.tar.gz here.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading model and scaler...&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s2">&quot;model.joblib&quot;</span><span class="p">))</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s2">&quot;scaler.joblib&quot;</span><span class="p">))</span> <span class="c1"># Assumes scaler is packaged with the model</span>
    
    <span class="c1"># Initialize boto3 client in the global scope for reuse</span>
    <span class="c1"># The region should be dynamically available in the SageMaker environment</span>
    <span class="n">region</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;AWS_REGION&quot;</span><span class="p">)</span>
    <span class="n">sagemaker_fs_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">&#39;sagemaker-featurestore-runtime&#39;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="n">region</span><span class="p">)</span>
    
    <span class="c1"># Define feature group name from environment variable or hardcode</span>
    <span class="n">feature_group_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;FEATURE_GROUP_NAME&quot;</span><span class="p">,</span> <span class="s2">&quot;clv-feature-group-v1&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="s2">&quot;scaler&quot;</span><span class="p">:</span> <span class="n">scaler</span><span class="p">,</span>
        <span class="s2">&quot;fs_client&quot;</span><span class="p">:</span> <span class="n">sagemaker_fs_client</span><span class="p">,</span>
        <span class="s2">&quot;feature_group_name&quot;</span><span class="p">:</span> <span class="n">feature_group_name</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">input_fn</span><span class="p">(</span><span class="n">request_body</span><span class="p">,</span> <span class="n">request_content_type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parses the input data. The input is expected to be a file where each line is a JSON object</span>
<span class="sd">    containing a &#39;CustomerID&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">request_content_type</span> <span class="o">==</span> <span class="s1">&#39;application/json&#39;</span><span class="p">:</span>
        <span class="n">customer_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">request_body</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">customer_ids</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported content type: </span><span class="si">{</span><span class="n">request_content_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict_fn</span><span class="p">(</span><span class="n">customer_ids</span><span class="p">,</span> <span class="n">model_artifacts</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each customer, fetches features from the Feature Store, scales them,</span>
<span class="sd">    and then makes a prediction.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_artifacts</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">model_artifacts</span><span class="p">[</span><span class="s2">&quot;scaler&quot;</span><span class="p">]</span>
    <span class="n">fs_client</span> <span class="o">=</span> <span class="n">model_artifacts</span><span class="p">[</span><span class="s2">&quot;fs_client&quot;</span><span class="p">]</span>
    <span class="n">feature_group_name</span> <span class="o">=</span> <span class="n">model_artifacts</span><span class="p">[</span><span class="s2">&quot;feature_group_name&quot;</span><span class="p">]</span>
    
    <span class="c1"># Get the feature names from the scaler object</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">feature_names_in_</span>

    <span class="n">all_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">processed_customer_ids</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">customer_id</span> <span class="ow">in</span> <span class="n">customer_ids</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">fs_client</span><span class="o">.</span><span class="n">get_record</span><span class="p">(</span>
                <span class="n">FeatureGroupName</span><span class="o">=</span><span class="n">feature_group_name</span><span class="p">,</span>
                <span class="n">RecordIdentifierValueAsString</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">customer_id</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;Record&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No record found for customer </span><span class="si">{</span><span class="n">customer_id</span><span class="si">}</span><span class="s2">. Skipping.&quot;</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Convert feature store record to a dictionary</span>
            <span class="n">record</span> <span class="o">=</span> <span class="p">{</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">]:</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;ValueAsString&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;Record&#39;</span><span class="p">]}</span>
            
            <span class="c1"># Ensure all required features are present</span>
            <span class="n">features_for_model</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">]</span>
            <span class="n">all_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features_for_model</span><span class="p">)</span>
            <span class="n">processed_customer_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">customer_id</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error fetching features for customer </span><span class="si">{</span><span class="n">customer_id</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Skipping.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">all_features</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="c1"># Create a DataFrame and scale the features</span>
    <span class="n">features_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_features</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
    <span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_df</span><span class="p">)</span>
    
    <span class="c1"># Make predictions</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>
    
    <span class="c1"># Combine customer IDs with their predictions</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="n">cid</span><span class="p">,</span> <span class="s2">&quot;CLV_Prediction&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred</span><span class="p">)}</span>
        <span class="k">for</span> <span class="n">cid</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">processed_customer_ids</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="p">]</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">output</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">output_fn</span><span class="p">(</span><span class="n">prediction_output</span><span class="p">,</span> <span class="n">accept</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Formats the predictions into a JSON Lines format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">accept</span> <span class="o">==</span> <span class="s2">&quot;application/json&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">rec</span><span class="p">)</span> <span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">prediction_output</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">]),</span> <span class="n">accept</span>
    
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported accept type: </span><span class="si">{</span><span class="n">accept</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Unit Tests</strong>
This test validates the batch_inference.py script using mocks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/unit/test_batch_inference.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">MagicMock</span><span class="p">,</span> <span class="n">patch</span>
<span class="kn">from</span> <span class="nn">src.batch_inference</span> <span class="kn">import</span> <span class="n">predict_fn</span><span class="p">,</span> <span class="n">input_fn</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_model_artifacts</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mocks the model artifacts dictionary.&quot;&quot;&quot;</span>
    <span class="c1"># Mock scaler</span>
    <span class="n">mock_scaler</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">mock_scaler</span><span class="o">.</span><span class="n">feature_names_in_</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature2&#39;</span><span class="p">]</span>
    <span class="n">mock_scaler</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]]</span> <span class="c1"># Dummy scaled data</span>
    
    <span class="c1"># Mock model</span>
    <span class="n">mock_model</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">mock_model</span><span class="o">.</span><span class="n">predict</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">500.50</span><span class="p">,</span> <span class="mf">150.25</span><span class="p">]</span>
    
    <span class="c1"># Mock feature store client</span>
    <span class="n">mock_fs_client</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
    <span class="c1"># Simulate response for two customers</span>
    <span class="n">mock_fs_client</span><span class="o">.</span><span class="n">get_record</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;Record&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">:</span> <span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="s1">&#39;ValueAsString&#39;</span><span class="p">:</span> <span class="s1">&#39;10&#39;</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">:</span> <span class="s1">&#39;feature2&#39;</span><span class="p">,</span> <span class="s1">&#39;ValueAsString&#39;</span><span class="p">:</span> <span class="s1">&#39;20&#39;</span><span class="p">}]},</span>
        <span class="p">{</span><span class="s1">&#39;Record&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">:</span> <span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="s1">&#39;ValueAsString&#39;</span><span class="p">:</span> <span class="s1">&#39;1&#39;</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;FeatureName&#39;</span><span class="p">:</span> <span class="s1">&#39;feature2&#39;</span><span class="p">,</span> <span class="s1">&#39;ValueAsString&#39;</span><span class="p">:</span> <span class="s1">&#39;2&#39;</span><span class="p">}]}</span>
    <span class="p">]</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">mock_model</span><span class="p">,</span>
        <span class="s2">&quot;scaler&quot;</span><span class="p">:</span> <span class="n">mock_scaler</span><span class="p">,</span>
        <span class="s2">&quot;fs_client&quot;</span><span class="p">:</span> <span class="n">mock_fs_client</span><span class="p">,</span>
        <span class="s2">&quot;feature_group_name&quot;</span><span class="p">:</span> <span class="s2">&quot;test-fg&quot;</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">test_input_fn</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests if the input parsing works correctly.&quot;&quot;&quot;</span>
    <span class="n">request_body</span> <span class="o">=</span> <span class="s1">&#39;{&quot;CustomerID&quot;: 101}</span><span class="se">\n</span><span class="s1">{&quot;CustomerID&quot;: 102}&#39;</span>
    <span class="n">customer_ids</span> <span class="o">=</span> <span class="n">input_fn</span><span class="p">(</span><span class="n">request_body</span><span class="p">,</span> <span class="s1">&#39;application/json&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">customer_ids</span> <span class="o">==</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">102</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">test_predict_fn</span><span class="p">(</span><span class="n">mock_model_artifacts</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tests the core prediction logic.&quot;&quot;&quot;</span>
    <span class="n">customer_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">102</span><span class="p">]</span>
    <span class="n">predictions_output</span> <span class="o">=</span> <span class="n">predict_fn</span><span class="p">(</span><span class="n">customer_ids</span><span class="p">,</span> <span class="n">mock_model_artifacts</span><span class="p">)</span>
    
    <span class="c1"># Assert feature store was called twice</span>
    <span class="k">assert</span> <span class="n">mock_model_artifacts</span><span class="p">[</span><span class="s2">&quot;fs_client&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_record</span><span class="o">.</span><span class="n">call_count</span> <span class="o">==</span> <span class="mi">2</span>
    
    <span class="c1"># Assert model predict was called once with the scaled data</span>
    <span class="n">mock_model_artifacts</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="o">.</span><span class="n">assert_called_once</span><span class="p">()</span>
    
    <span class="c1"># Assert the output is correctly formatted</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="mi">101</span><span class="p">,</span> <span class="s2">&quot;CLV_Prediction&quot;</span><span class="p">:</span> <span class="mf">500.50</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;CustomerID&quot;</span><span class="p">:</span> <span class="mi">102</span><span class="p">,</span> <span class="s2">&quot;CLV_Prediction&quot;</span><span class="p">:</span> <span class="mf">150.25</span><span class="p">}</span>
        <span class="p">]</span>
    <span class="p">}</span>
    <span class="k">assert</span> <span class="n">predictions_output</span> <span class="o">==</span> <span class="n">expected_output</span>
</pre></div>
</div>
<blockquote>
<div><p>unittest MagicMock return value vs side effect</p>
<p>Use return_value when your mock needs to provide a single, consistent return value.</p>
<p>Use side_effect for more complex and dynamic behaviors, including:</p>
<ul class="simple">
<li><p>Providing a sequence of return values.</p></li>
<li><p>Raising exceptions to test error handling.</p></li>
<li><p>Executing custom logic to determine the return value or perform other actions.</p></li>
</ul>
<p>Choosing between return_value and side_effect depends on the specific scenario you are trying to test and how much control you need over the mocked object’s behavior.</p>
</div></blockquote>
<p><strong>Airflow DAG</strong></p>
<p>This DAG orchestrates the entire weekly batch prediction job.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_batch_inference.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerTransformOperator</span>
<span class="kn">from</span> <span class="nn">airflow.models.param</span> <span class="kn">import</span> <span class="n">Param</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="c1"># --- Constants ---</span>
<span class="n">MLFLOW_TRACKING_URI</span> <span class="o">=</span> <span class="s2">&quot;http://your-mlflow-server:5000&quot;</span> <span class="c1"># Should be an Airflow Variable/Connection</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-prediction-model&quot;</span>
<span class="n">SAGEMAKER_ROLE</span> <span class="o">=</span> <span class="s2">&quot;arn:aws:iam::ACCOUNT_ID:role/sagemaker-inference-execution-role&quot;</span>
<span class="n">INPUT_S3_URI</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-inference-data-bucket/input/active_customers.jsonl&quot;</span>
<span class="n">OUTPUT_S3_URI</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-inference-data-bucket/output/&quot;</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_batch_inference_pipeline&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;@weekly&quot;</span><span class="p">,</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;DAG to run weekly batch inference for CLV prediction.&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;clv&quot;</span><span class="p">,</span> <span class="s2">&quot;inference&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">batch_inference_dag</span><span class="p">():</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">get_production_model_uri</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fetches the S3 URI of the latest model in the &#39;Production&#39; stage.&quot;&quot;&quot;</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="n">MLFLOW_TRACKING_URI</span><span class="p">)</span>
        <span class="n">latest_versions</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_latest_versions</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Production&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">latest_versions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No model in Production stage found for &#39;</span><span class="si">{</span><span class="n">MODEL_NAME</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        
        <span class="n">prod_model</span> <span class="o">=</span> <span class="n">latest_versions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found production model: Version </span><span class="si">{</span><span class="n">prod_model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">, URI: </span><span class="si">{</span><span class="n">prod_model</span><span class="o">.</span><span class="n">source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prod_model</span><span class="o">.</span><span class="n">source</span>

    <span class="n">model_uri</span> <span class="o">=</span> <span class="n">get_production_model_uri</span><span class="p">()</span>
    
    <span class="c1"># In a real pipeline, the model object in SageMaker should be created separately.</span>
    <span class="c1"># For this operator, we assume a SageMaker model object exists.</span>
    <span class="c1"># The operator just creates the transform job.</span>
    <span class="n">run_batch_transform</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;run_sagemaker_batch_transform&quot;</span><span class="p">,</span>
        <span class="n">config</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;TransformJobName&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;clv-batch-inference-</span><span class="se">{{{{</span><span class="s2"> ds_nodash </span><span class="se">}}}}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ModelName&quot;</span><span class="p">:</span> <span class="s2">&quot;clv-sagemaker-model-name&quot;</span><span class="p">,</span> <span class="c1"># Name of the model in SageMaker</span>
            <span class="s2">&quot;TransformInput&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;DataSource&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;S3DataSource&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;S3DataType&quot;</span><span class="p">:</span> <span class="s2">&quot;S3Prefix&quot;</span><span class="p">,</span> <span class="s2">&quot;S3Uri&quot;</span><span class="p">:</span> <span class="n">INPUT_S3_URI</span><span class="p">}},</span>
                <span class="s2">&quot;ContentType&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">,</span>
                <span class="s2">&quot;SplitType&quot;</span><span class="p">:</span> <span class="s2">&quot;Line&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;TransformOutput&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;S3OutputPath&quot;</span><span class="p">:</span> <span class="n">OUTPUT_S3_URI</span><span class="p">,</span>
                <span class="s2">&quot;Accept&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">,</span>
                <span class="s2">&quot;AssembleWith&quot;</span><span class="p">:</span> <span class="s2">&quot;Line&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;TransformResources&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="s2">&quot;ml.m5.large&quot;</span><span class="p">,</span> <span class="s2">&quot;InstanceCount&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># This task would load the S3 output into the data warehouse</span>
    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">load_predictions_to_dwh</span><span class="p">(</span><span class="n">s3_output_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Simulating load of data from </span><span class="si">{</span><span class="n">s3_output_path</span><span class="si">}</span><span class="s2"> into Data Warehouse.&quot;</span><span class="p">)</span>
        <span class="c1"># Add pandas/boto3 logic here to read from S3 and write to Redshift/Snowflake</span>
        <span class="k">return</span> <span class="s2">&quot;Load complete.&quot;</span>

    <span class="n">model_uri</span> <span class="o">&gt;&gt;</span> <span class="n">run_batch_transform</span> <span class="o">&gt;&gt;</span> <span class="n">load_predictions_to_dwh</span><span class="p">(</span><span class="n">OUTPUT_S3_URI</span><span class="p">)</span>

<span class="n">batch_inference_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Integration Test</strong></p>
<p>This test triggers the DAG and validates the output in a live staging environment.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/integration/test_inference_pipeline_integration.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">airflow.api.client.local_client</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">DAG_ID</span> <span class="o">=</span> <span class="s2">&quot;clv_batch_inference_pipeline&quot;</span>
<span class="n">OUTPUT_BUCKET</span> <span class="o">=</span> <span class="s2">&quot;clv-inference-data-bucket-staging&quot;</span> <span class="c1"># Use a staging bucket</span>
<span class="n">OUTPUT_PREFIX</span> <span class="o">=</span> <span class="s2">&quot;output/&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span> <span class="nf">test_inference_dag_end_to_end</span><span class="p">():</span>
    <span class="c1"># Setup: Ensure the output location is clean</span>
    <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s1">&#39;s3&#39;</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="n">OUTPUT_BUCKET</span><span class="p">)</span>
    <span class="n">bucket</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">Prefix</span><span class="o">=</span><span class="n">OUTPUT_PREFIX</span><span class="p">)</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>
    
    <span class="c1"># Act: Trigger the DAG</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;integration_test_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">c</span><span class="o">.</span><span class="n">trigger_dag</span><span class="p">(</span><span class="n">dag_id</span><span class="o">=</span><span class="n">DAG_ID</span><span class="p">,</span> <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">)</span>

    <span class="c1"># Poll for completion</span>
    <span class="n">timeout</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">+</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">15</span> <span class="c1"># 15 minute timeout</span>
    <span class="n">final_state</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout</span><span class="p">:</span>
        <span class="n">dag_run</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">get_dag_run</span><span class="p">(</span><span class="n">dag_id</span><span class="o">=</span><span class="n">DAG_ID</span><span class="p">,</span> <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dag_run</span><span class="o">.</span><span class="n">state</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;success&#39;</span><span class="p">,</span> <span class="s1">&#39;failed&#39;</span><span class="p">]:</span>
            <span class="n">final_state</span> <span class="o">=</span> <span class="n">dag_run</span><span class="o">.</span><span class="n">state</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DAG state is </span><span class="si">{</span><span class="n">dag_run</span><span class="o">.</span><span class="n">state</span><span class="si">}</span><span class="s2">. Waiting...&quot;</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
        
    <span class="c1"># Assert DAG success</span>
    <span class="k">assert</span> <span class="n">final_state</span> <span class="o">==</span> <span class="s1">&#39;success&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;DAG run failed with state: </span><span class="si">{</span><span class="n">final_state</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># Assert: Check if the output file was created in S3</span>
    <span class="n">objects</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bucket</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">Prefix</span><span class="o">=</span><span class="n">OUTPUT_PREFIX</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">objects</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;No output file was found in the S3 bucket.&quot;</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integration test passed. Output file found: </span><span class="si">{</span><span class="n">objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>GitHub Actions CI/CD Workflow</strong>
This workflow validates and deploys the inference pipeline code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># .github/workflows/cicd_inference_pipeline.yml

name: &quot;CI/CD for Batch Inference Pipeline&quot;

on:
  push:
    branches:
      - main
    paths:
      - &#39;src/batch_inference.py&#39;
      - &#39;pipelines/dag_batch_inference.py&#39;
      - &#39;terraform/**&#39; # Now triggers on infrastructure changes as well
      - &#39;tests/**&#39;
      - &#39;.github/workflows/cicd_inference_pipeline.yml&#39;
  pull_request:
    branches:
      - main

jobs:
  ci-checks:
    name: &quot;Continuous Integration&quot;
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install -r tests/requirements.txt
      
      - name: Run Linting and Formatting Checks
        run: |
          pip install flake8 black
          flake8 src/ pipelines/ tests/
          black --check src/ pipelines/ tests/

      - name: Run Unit Tests
        run: pytest tests/unit/
  
  cd-staging:
    name: &quot;Continuous Delivery to Staging&quot;
    needs: ci-checks
    if: github.event_name == &#39;push&#39; &amp;&amp; github.ref == &#39;refs/heads/main&#39;
    runs-on: ubuntu-latest
    environment: staging # Links to GitHub secrets for the staging environment

    permissions:
      id-token: write
      contents: read
      
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        
      - name: Configure Staging AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.STAGING_AWS_ROLE_ARN }}
          aws-region: eu-west-1

      - name: Terraform Init (Staging)
        id: init
        run: |
          cd terraform
          # The -backend-config flag points to a file specifying the S3 bucket/key for staging&#39;s state
          terraform init -backend-config=staging.backend.hcl

      - name: Terraform Apply (Staging)
        id: apply
        run: |
          cd terraform
          # The -var-file flag points to variables specific to the staging env (e.g., bucket names)
          terraform apply -auto-approve -var-file=staging.tfvars

      - name: Install Python Test Dependencies
        run: |
          pip install -r requirements.txt
          pip install -r tests/integration/requirements.txt
          
      - name: Deploy DAG to Staging Airflow
        run: |
          # This script would sync your DAGs folder with Airflow&#39;s DAGs folder in S3
          echo &quot;Syncing pipelines/dag_batch_inference.py to Staging Airflow...&quot;
          # Example: aws s3 sync pipelines/ s3://your-staging-airflow-dags-bucket/ --exclude &quot;*&quot; --include &quot;dag_batch_inference.py&quot;
          
      - name: Run Integration Test in Staging
        run: pytest tests/integration/test_inference_pipeline_integration.py
</pre></div>
</div>
</section>
</section>
<section id="monitoring-observability">
<h3><strong>Monitoring &amp; Observability</strong><a class="headerlink" href="#monitoring-observability" title="Permalink to this heading">¶</a></h3>
<section id="guiding-philosophy-and-approach">
<h4><strong>1. Guiding Philosophy and Approach</strong><a class="headerlink" href="#guiding-philosophy-and-approach" title="Permalink to this heading">¶</a></h4>
<p>Our approach will be twofold:</p>
<ol class="arabic simple">
<li><p><strong>Monitoring (Answering “What”):</strong> We will implement automated systems to track a predefined set of metrics covering data quality, system health, and model performance proxies. This is our early warning system, designed to be the first to know when a known problem occurs.</p></li>
<li><p><strong>Observability (Answering “Why”):</strong> We will collect the necessary data (logs, feature values, SHAP values) to enable deep-dive analysis when an alert is triggered. This allows us to move beyond knowing <em>that</em> something is wrong to understanding <em>why</em> it’s wrong, which is crucial for effective debugging and resolution.</p></li>
</ol>
<p>Our goal is to create a system that minimizes <strong>Time to Detection (TTD)</strong> and <strong>Time to Resolution (TTR)</strong> for any issues that arise in our production ML system.</p>
</section>
<section id="tech-stack-for-monitoring-observability">
<h4><strong>2. Tech Stack for Monitoring &amp; Observability</strong><a class="headerlink" href="#tech-stack-for-monitoring-observability" title="Permalink to this heading">¶</a></h4>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Component</p></th>
<th class="head text-left"><p>Chosen Tool/Framework</p></th>
<th class="head text-left"><p>Rationale (Based on the Guide &amp; Our Stack)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Data Quality Validation</strong></p></td>
<td class="text-left"><p><strong>Great Expectations</strong></p></td>
<td class="text-left"><p>Integrated directly into our Airflow data pipelines. Allows us to define “unit tests for data” and stop bad data from ever reaching the feature store</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Drift &amp; Performance Monitoring</strong></p></td>
<td class="text-left"><p><strong>Amazon SageMaker Model Monitor</strong></p></td>
<td class="text-left"><p>The most tightly integrated solution for our SageMaker-based pipelines. It can automatically compare production data against a baseline (our training data) to detect both data and prediction drift.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Infrastructure &amp; System Health</strong></p></td>
<td class="text-left"><p><strong>Amazon CloudWatch</strong></p></td>
<td class="text-left"><p>The native AWS solution for tracking operational metrics like job duration (latency), error rates, and resource utilization for our SageMaker jobs and Airflow DAGs.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Dashboards &amp; Visualization</strong></p></td>
<td class="text-left"><p>1. <strong>Amazon CloudWatch Dashboards</strong> <br> 2. <strong>BI Tool (Tableau, QuickSight)</strong></p></td>
<td class="text-left"><p>CloudWatch will be used for real-time operational health dashboards (for the MLOps team). A BI tool will be used for higher-level model performance and business KPI dashboards (for data scientists and product managers).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Alerting &amp; Notifications</strong></p></td>
<td class="text-left"><p><strong>Amazon CloudWatch Alarms</strong></p></td>
<td class="text-left"><p>Integrated with CloudWatch metrics, these will trigger notifications based on predefined thresholds.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Notification Channels</strong></p></td>
<td class="text-left"><p><strong>Slack &amp; PagerDuty</strong></p></td>
<td class="text-left"><p>Slack for medium-priority notifications (e.g., moderate drift) and PagerDuty for high-priority, critical alerts that require immediate attention (e.g., pipeline failure).</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Explainability &amp; Debugging</strong></p></td>
<td class="text-left"><p><strong>SHAP &amp; S3/Data Warehouse</strong></p></td>
<td class="text-left"><p>We will generate SHAP values during model evaluation and log them alongside predictions. This allows us to query and analyze the drivers of specific predictions, enabling deep observability.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="detailed-monitoring-plan">
<h4><strong>3. Detailed Monitoring Plan</strong><a class="headerlink" href="#detailed-monitoring-plan" title="Permalink to this heading">¶</a></h4>
<section id="a-data-quality-monitoring-the-foundation">
<h5><strong>a) Data Quality Monitoring (The Foundation)</strong><a class="headerlink" href="#a-data-quality-monitoring-the-foundation" title="Permalink to this heading">¶</a></h5>
<ul class="simple">
<li><p><strong>Where:</strong> Integrated into our Airflow <strong>Data Ingestion</strong> and <strong>Feature Engineering</strong> DAGs.</p></li>
<li><p><strong>Tool:</strong> Great Expectations.</p></li>
<li><p><strong>Checks to Implement:</strong></p>
<ul>
<li><p><strong>Schema Validation:</strong> The number of columns, column names, and column types must match the expected schema.</p></li>
<li><p><strong>Null Rates:</strong> The percentage of missing values for critical features (e.g., <code class="docutils literal notranslate"><span class="pre">total_spend</span></code>, <code class="docutils literal notranslate"><span class="pre">recency</span></code>) must not exceed a threshold (e.g., 5%).</p></li>
<li><p><strong>Range Checks:</strong> Numerical features must fall within valid ranges (e.g., <code class="docutils literal notranslate"><span class="pre">SalePrice</span></code> must be &gt; 0).</p></li>
<li><p><strong>Type Matching:</strong> Ensure features expected to be numerical are not strings.</p></li>
<li><p><strong>Cardinality Checks:</strong> Alert if the number of unique categories for features like <code class="docutils literal notranslate"><span class="pre">country</span></code> or <code class="docutils literal notranslate"><span class="pre">acquisition_channel</span></code> changes unexpectedly.</p></li>
</ul>
</li>
</ul>
</section>
<section id="b-data-prediction-drift-monitoring-proxy-for-performance">
<h5><strong>b) Data &amp; Prediction Drift Monitoring (Proxy for Performance)</strong><a class="headerlink" href="#b-data-prediction-drift-monitoring-proxy-for-performance" title="Permalink to this heading">¶</a></h5>
<ul class="simple">
<li><p><strong>Challenge:</strong> Our ground truth (actual 12-month spend) is severely delayed. Therefore, monitoring input and output distributions is our most critical leading indicator of performance degradation.</p></li>
<li><p><strong>Tool:</strong> Amazon SageMaker Model Monitor.</p></li>
<li><p><strong>Baseline:</strong> The training dataset used to build the current production model.</p></li>
</ul>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Drift Type</p></th>
<th class="head text-left"><p>What We’ll Track</p></th>
<th class="head text-left"><p>Metric</p></th>
<th class="head text-left"><p>Why It’s Important</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Input Drift (Covariate Shift)</strong></p></td>
<td class="text-left"><p>Distribution of key input features (<code class="docutils literal notranslate"><span class="pre">recency</span></code>, <code class="docutils literal notranslate"><span class="pre">frequency</span></code>, <code class="docutils literal notranslate"><span class="pre">monetary</span></code>, <code class="docutils literal notranslate"><span class="pre">total_spend_90d</span></code>).</p></td>
<td class="text-left"><p><strong>Population Stability Index (PSI)</strong></p></td>
<td class="text-left"><p>Alerts us if the fundamental characteristics of our customer base are changing. This is a direct application of the techniques in Section V-C of the guide.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Prediction Drift</strong></p></td>
<td class="text-left"><p>Distribution of the model’s output CLV scores (<code class="docutils literal notranslate"><span class="pre">P(model_output)</span></code>).</p></td>
<td class="text-left"><p><strong>Population Stability Index (PSI)</strong></p></td>
<td class="text-left"><p>A powerful signal that the model’s behavior is changing, which could be due to input drift or concept drift. If the model starts predicting much higher or lower on average, we need to investigate.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="c-model-performance-monitoring">
<h5><strong>c) Model Performance Monitoring</strong><a class="headerlink" href="#c-model-performance-monitoring" title="Permalink to this heading">¶</a></h5>
<ul class="simple">
<li><p><strong>Challenge:</strong> True performance (RMSE against 12-month spend) is a lagging indicator. We must use proxy metrics.</p></li>
<li><p><strong>Metrics to Track:</strong></p>
<ul>
<li><p><strong>Primary Proxy Metric:</strong> Correlation between <strong>predicted 12-month CLV</strong> and <strong>actual 30-day customer spend</strong>. We’ll calculate this monthly. While not perfect, a drop in this correlation is a strong signal that the model’s predictive power is weakening.</p></li>
<li><p><strong>Business KPI Slices:</strong> Track key business metrics for cohorts defined by the model’s predictions. For example:</p>
<ul>
<li><p>Average Order Value (AOV) for customers in the “Top 10% Predicted CLV” vs. “Bottom 50%”.</p></li>
<li><p>30-day churn rate for the “Top 10% Predicted CLV” cohort.</p></li>
</ul>
</li>
<li><p><strong>Long-Term Ground Truth:</strong> On a quarterly basis, calculate the true RMSE and Gini Coefficient for the cohort of customers whose 12-month window has just completed. This validates our model’s long-term accuracy.</p></li>
</ul>
</li>
</ul>
</section>
<section id="d-system-health-monitoring-operational">
<h5><strong>d) System Health Monitoring (Operational)</strong><a class="headerlink" href="#d-system-health-monitoring-operational" title="Permalink to this heading">¶</a></h5>
<ul class="simple">
<li><p><strong>Tool:</strong> Amazon CloudWatch.</p></li>
<li><p><strong>Metrics to Track:</strong></p>
<ul>
<li><p><strong>Airflow DAGs:</strong> Success/failure status of all pipeline runs.</p></li>
<li><p><strong>SageMaker Jobs (Training &amp; Inference):</strong> Job duration (latency), error rates, CPU/Memory utilization.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="observability-debugging-plan">
<h4><strong>4. Observability &amp; Debugging Plan</strong><a class="headerlink" href="#observability-debugging-plan" title="Permalink to this heading">¶</a></h4>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Scenario</p></th>
<th class="head text-left"><p>Observability Workflow</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>A “High Prediction Drift” alert is triggered.</strong></p></td>
<td class="text-left"><p>1. <strong>Check Input Drift Dashboards:</strong> Is the prediction drift caused by a significant shift in one or more input features? (e.g., a marketing campaign brought in a new demographic, causing <code class="docutils literal notranslate"><span class="pre">recency</span></code> to drop). <br> 2. <strong>Analyze Slice Performance:</strong> Did the drift disproportionately affect a specific segment (e.g., customers from a new country)?</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>The business team asks “Why was this specific customer predicted to have a high CLV?”</strong></p></td>
<td class="text-left"><p>1. <strong>Query Prediction Logs:</strong> Retrieve the saved prediction and associated SHAP values for that <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code>. <br> 2. <strong>Provide Local Explanation:</strong> Use the SHAP values to explain which features (e.g., high frequency, large recent purchases) contributed most to that individual’s score. This builds trust and provides actionable insights.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>The “Top 10% Predicted CLV” cohort has a high churn rate.</strong></p></td>
<td class="text-left"><p>1. <strong>Root Cause with SHAP:</strong> Analyze the aggregated SHAP values for this cohort. Is the model over-reliant on a feature that isn’t a true indicator of loyalty for this segment? <br> 2. <strong>Identify Data Quality Issues:</strong> Check if this cohort has data quality problems that are misleading the model.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="alerting-strategy">
<h4><strong>5. Alerting Strategy</strong><a class="headerlink" href="#alerting-strategy" title="Permalink to this heading">¶</a></h4>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Priority</p></th>
<th class="head text-left"><p>Channel</p></th>
<th class="head text-left"><p>Alert Condition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>High</strong></p></td>
<td class="text-left"><p>PagerDuty</p></td>
<td class="text-left"><p>- Any ML pipeline (training or inference) fails completely. <br> - Critical data quality validation fails (e.g., schema mismatch).</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Medium</strong></p></td>
<td class="text-left"><p>Slack</p></td>
<td class="text-left"><p>- PSI for Prediction Drift &gt; 0.25. <br> - PSI for a key input feature &gt; 0.25. <br> - 30-day proxy metric (correlation) drops by &gt; 20%.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Low</strong></p></td>
<td class="text-left"><p>Email / Dashboard</p></td>
<td class="text-left"><p>- PSI for any drift metric is between 0.1 and 0.25. <br> - A non-critical data quality check fails (e.g., slight increase in nulls).</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="dashboard-design">
<h4><strong>6. Dashboard Design</strong><a class="headerlink" href="#dashboard-design" title="Permalink to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p><strong>MLOps Team Dashboard (on CloudWatch):</strong></p>
<ul class="simple">
<li><p><strong>Focus:</strong> Real-time system and data health.</p></li>
<li><p><strong>Widgets:</strong></p>
<ul>
<li><p>Pipeline Status (Green/Red indicators for Airflow DAGs).</p></li>
<li><p>SageMaker Job Durations (Line graphs).</p></li>
<li><p>Input Feature Drift Scores (PSI over time).</p></li>
<li><p>Prediction Drift Score (PSI over time).</p></li>
<li><p>Data Quality Alerts (List of recent validation failures).</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Data Science &amp; Product Dashboard (on Tableau/QuickSight):</strong></p>
<ul class="simple">
<li><p><strong>Focus:</strong> Model performance and business impact.</p></li>
<li><p><strong>Widgets:</strong></p>
<ul>
<li><p>Distribution of CLV predictions over time (histogram/density plot).</p></li>
<li><p>Proxy Metric: Correlation of Predicted CLV vs. Actual 30-Day Spend (Line graph).</p></li>
<li><p>Business KPIs by Prediction Cohort (Bar charts for AOV, Churn Rate).</p></li>
<li><p>Deep Dive: Slicing performance by country, acquisition channel, etc.</p></li>
<li><p>Global Feature Importance (Aggregated SHAP values).</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Drift Monitoring (Custom Batch Solution)</strong></p>
<p>This script will be run by a SageMaker Processing Job. It calculates drift metrics and produces a JSON report.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># src/run_drift_check.py</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ks_2samp</span>

<span class="k">def</span> <span class="nf">calculate_psi</span><span class="p">(</span><span class="n">baseline</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">current</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates the Population Stability Index (PSI) for a numerical series.&quot;&quot;&quot;</span>
    <span class="c1"># Define bins based on the baseline distribution</span>
    <span class="n">baseline_bins</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">retbins</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">baseline_dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">baseline_bins</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">current_dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">baseline_bins</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Align distributions and fill missing bins with a small value to avoid division by zero</span>
    <span class="n">psi_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;baseline&#39;</span><span class="p">:</span> <span class="n">baseline_dist</span><span class="p">,</span> <span class="s1">&#39;current&#39;</span><span class="p">:</span> <span class="n">current_dist</span><span class="p">})</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;psi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;current&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;baseline&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;current&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;baseline&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">psi_df</span><span class="p">[</span><span class="s1">&#39;psi&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--baseline-path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--current-path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--output-path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># Load data</span>
    <span class="n">baseline_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">baseline_path</span><span class="p">,</span> <span class="s2">&quot;training_data.csv&quot;</span><span class="p">))</span>
    <span class="n">current_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">current_path</span><span class="p">,</span> <span class="s2">&quot;inference_input.csv&quot;</span><span class="p">))</span> <span class="c1"># Assuming inference inputs are logged</span>

    <span class="n">drift_report</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;input_drift&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;prediction_drift&quot;</span><span class="p">:</span> <span class="p">{}</span>
    <span class="p">}</span>
    
    <span class="n">features_to_check</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;recency&#39;</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">,</span> <span class="s1">&#39;monetary&#39;</span><span class="p">,</span> <span class="s1">&#39;total_spend_90d&#39;</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Calculating Input Drift ---&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features_to_check</span><span class="p">:</span>
        <span class="n">psi</span> <span class="o">=</span> <span class="n">calculate_psi</span><span class="p">(</span><span class="n">baseline_df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">current_df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
        <span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_pvalue</span> <span class="o">=</span> <span class="n">ks_2samp</span><span class="p">(</span><span class="n">baseline_df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">current_df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
        <span class="n">drift_report</span><span class="p">[</span><span class="s2">&quot;input_drift&quot;</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;psi&quot;</span><span class="p">:</span> <span class="n">psi</span><span class="p">,</span>
            <span class="s2">&quot;ks_statistic&quot;</span><span class="p">:</span> <span class="n">ks_stat</span><span class="p">,</span>
            <span class="s2">&quot;ks_pvalue&quot;</span><span class="p">:</span> <span class="n">ks_pvalue</span>
        <span class="p">}</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature &#39;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">&#39;: PSI = </span><span class="si">{</span><span class="n">psi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, KS p-value = </span><span class="si">{</span><span class="n">ks_pvalue</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Calculating Prediction Drift ---&quot;</span><span class="p">)</span>
    <span class="c1"># Assuming predictions are part of the &#39;current_df&#39; and a baseline prediction set exists</span>
    <span class="k">if</span> <span class="s1">&#39;prediction&#39;</span> <span class="ow">in</span> <span class="n">current_df</span><span class="o">.</span><span class="n">columns</span> <span class="ow">and</span> <span class="s1">&#39;prediction&#39;</span> <span class="ow">in</span> <span class="n">baseline_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">psi</span> <span class="o">=</span> <span class="n">calculate_psi</span><span class="p">(</span><span class="n">baseline_df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">current_df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>
        <span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_pvalue</span> <span class="o">=</span> <span class="n">ks_2samp</span><span class="p">(</span><span class="n">baseline_df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">current_df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>
        <span class="n">drift_report</span><span class="p">[</span><span class="s2">&quot;prediction_drift&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;psi&quot;</span><span class="p">:</span> <span class="n">psi</span><span class="p">,</span>
            <span class="s2">&quot;ks_statistic&quot;</span><span class="p">:</span> <span class="n">ks_stat</span><span class="p">,</span>
            <span class="s2">&quot;ks_pvalue&quot;</span><span class="p">:</span> <span class="n">ks_pvalue</span>
        <span class="p">}</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction Drift: PSI = </span><span class="si">{</span><span class="n">psi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, KS p-value = </span><span class="si">{</span><span class="n">ks_pvalue</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Save the report</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;drift_report.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">drift_report</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Drift check complete.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Infrastructure for Alerting</strong></p>
<p>This Terraform code sets up the notification and alerting infrastructure.</p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/monitoring.tf</span>

<span class="c1"># --- SNS Topics for Notifications ---</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_sns_topic&quot;</span><span class="w"> </span><span class="nv">&quot;critical_alerts_topic&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-critical-alerts&quot;</span>
<span class="w">  </span><span class="nb">tags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="na">Environment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.environment</span><span class="w"> </span><span class="p">}</span>
<span class="p">}</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_sns_topic&quot;</span><span class="w"> </span><span class="nv">&quot;medium_alerts_topic&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-medium-alerts&quot;</span>
<span class="w">  </span><span class="nb">tags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="na">Environment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.environment</span><span class="w"> </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Assume subscriptions (e.g., to a PagerDuty endpoint or email) are configured separately</span>

<span class="c1"># --- CloudWatch Alarms for System Health ---</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_cloudwatch_metric_alarm&quot;</span><span class="w"> </span><span class="nv">&quot;training_pipeline_failures&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">alarm_name</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-${var.environment}-training-pipeline-failures&quot;</span>
<span class="w">  </span><span class="na">comparison_operator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;GreaterThanOrEqualToThreshold&quot;</span>
<span class="w">  </span><span class="na">evaluation_periods</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;1&quot;</span>
<span class="w">  </span><span class="na">metric_name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;FailedJobs&quot;</span>
<span class="w">  </span><span class="na">namespace</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;AWS/SageMaker&quot;</span>
<span class="w">  </span><span class="na">period</span><span class="w">              </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;3600&quot;</span><span class="c1"> # Check hourly</span>
<span class="w">  </span><span class="na">statistic</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Sum&quot;</span>
<span class="w">  </span><span class="na">threshold</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;1&quot;</span>
<span class="w">  </span><span class="na">alarm_description</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Alerts when a SageMaker training job fails.&quot;</span>
<span class="w">  </span><span class="na">alarm_actions</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="nv">aws_sns_topic.critical_alerts_topic.arn</span><span class="p">]</span>

<span class="w">  </span><span class="nb">dimensions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">TrainingJobName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-training-pipeline-*&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Dashboard Definition</strong>
This JSON represents the structure for a CloudWatch dashboard that our MLOps team would use.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="c1">// dashboards/mlops_health_dashboard.json</span>
<span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;widgets&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;metric&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="p">[</span><span class="s2">&quot;AWS/SageMaker&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;CPUUtilization&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Host&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;algo-1&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;stat&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Average&quot;</span><span class="w"> </span><span class="p">}]</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Training Job CPU Utilization (Avg)&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;metric&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="p">[</span><span class="s2">&quot;CLV/Drift&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;PredictionDriftPSI&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;stat&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Average&quot;</span><span class="w"> </span><span class="p">}]</span>
<span class="w">                </span><span class="p">],</span>
<span class="w">                </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Production Prediction Drift (PSI)&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;log&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SOURCE &#39;/aws/sagemaker/ProcessingJobs&#39; | fields @timestamp, @message | sort @timestamp desc | limit 20&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Latest Processing Job Logs&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;alarm&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Pipeline Alarms&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;alarms&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                    </span><span class="s2">&quot;arn:aws:cloudwatch:eu-west-1:ACCOUNT_ID:alarm:clv-production-training-pipeline-failures&quot;</span>
<span class="w">                </span><span class="p">]</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="continual-learning-production-testing-plan">
<h3><strong>Continual Learning &amp; Production Testing Plan</strong><a class="headerlink" href="#continual-learning-production-testing-plan" title="Permalink to this heading">¶</a></h3>
<section id="guiding-philosophy-from-static-predictions-to-a-dynamic-learning-system">
<h4><strong>1. Guiding Philosophy: From Static Predictions to a Dynamic, Learning System</strong><a class="headerlink" href="#guiding-philosophy-from-static-predictions-to-a-dynamic-learning-system" title="Permalink to this heading">¶</a></h4>
<p>Our core philosophy, is that deploying our CLV model is the beginning, not the end. To maintain its value, the model must evolve. The e-commerce landscape is not static; customer preferences change, marketing strategies shift, and new products are introduced. This guarantees that our model will suffer from <strong>data and concept drift</strong> over time, degrading its accuracy and business utility.</p>
<p>Therefore, we will implement a robust <strong>Continual Learning</strong> strategy. Our goal is to create an automated, closed-loop system where production performance insights directly fuel model improvements, which are then safely validated and redeployed. This transforms our CLV model from a static artifact into an adaptive, self-improving system, ensuring it consistently drives business value.</p>
</section>
<section id="continual-learning-model-retraining-strategy">
<h4><strong>2. Continual Learning &amp; Model Retraining Strategy</strong><a class="headerlink" href="#continual-learning-model-retraining-strategy" title="Permalink to this heading">¶</a></h4>
<p>This section defines <em>how</em> and <em>when</em> we will update our CLV model.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Strategy Component</p></th>
<th class="head text-left"><p>Decision / Implementation Choice</p></th>
<th class="head text-left"><p>Rationale (Based on the Provided Guides)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Retraining Approach</strong></p></td>
<td class="text-left"><p><strong>Stateless Retraining (from scratch) for now.</strong></p></td>
<td class="text-left"><p>For our XGBoost model, stateless retraining is simpler to implement robustly and avoids the risk of catastrophic forgetting. This is a common and practical starting point (Stage 2 of adoption). We can plan to evolve to Stateful (fine-tuning) in the future to reduce compute costs, but we must first establish a solid, reliable baseline.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Data Curation for Retraining</strong></p></td>
<td class="text-left"><p><strong>Sliding Window Approach: Train on the last 3 months of data.</strong></p></td>
<td class="text-left"><p>This strategy balances freshness with stability. It ensures the model is trained on recent customer behavior while retaining enough data to be robust. The data selection logic will be a parameterized step in our training pipeline.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Triggers for Retraining</strong></p></td>
<td class="text-left"><p>We will implement a multi-trigger system, moving towards an <strong>event-driven</strong> approach.</p></td>
<td class="text-left"><p>A simple schedule is a good start, but a mature system reacts to performance signals.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>- Trigger 1 (Schedule)</strong></p></td>
<td class="text-left"><p><strong>Weekly automated retraining job.</strong></p></td>
<td class="text-left"><p>A weekly cadence aligns perfectly with the marketing team’s weekly campaign planning cycle. This is our primary, proactive trigger.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>- Trigger 2 (Performance)</strong></p></td>
<td class="text-left"><p><strong>Automated trigger if the 30-day proxy metric degrades.</strong></p></td>
<td class="text-left"><p>The ground truth (12-month spend) is severely delayed. Therefore, we will monitor the correlation between <code class="docutils literal notranslate"><span class="pre">predicted</span> <span class="pre">CLV</span></code> and <code class="docutils literal notranslate"><span class="pre">actual</span> <span class="pre">30-day</span> <span class="pre">spend</span></code> as a proxy. If this correlation drops by &gt;20% month-over-month, an automated retraining run will be triggered. This is a practical application of using proxy metrics when ground truth is latent.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>- Trigger 3 (Drift)</strong></p></td>
<td class="text-left"><p><strong>Automated trigger if Prediction Drift PSI &gt; 0.25.</strong></p></td>
<td class="text-left"><p>This is our most sensitive leading indicator. A significant change in the distribution of model outputs, as detected by our monitoring system, is a strong signal that the model’s behavior is changing, warranting a proactive retraining run.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="production-testing-rollout-strategy-a-phased-approach">
<h4><strong>3. Production Testing &amp; Rollout Strategy: A Phased Approach</strong><a class="headerlink" href="#production-testing-rollout-strategy-a-phased-approach" title="Permalink to this heading">¶</a></h4>
<p>We will adopt a multi-stage, progressive delivery strategy to de-risk the deployment of any new challenger model produced by our retraining pipeline.</p>
<p><strong>Stage 1: Shadow Deployment</strong></p>
<ul class="simple">
<li><p><strong>Purpose:</strong> To validate the new model’s operational health and prediction sanity in a live environment with zero user impact.</p></li>
<li><p><strong>Execution:</strong> The existing “Production” batch inference pipeline will run as usual. A parallel, “Shadow” version of the inference pipeline will be triggered, using the new challenger model. It will run on the same input list of active customers.</p></li>
<li><p><strong>Success Criteria / Metrics:</strong></p>
<ul>
<li><p><strong>Operational Health:</strong> The shadow pipeline must complete successfully with latency and resource consumption within 10% of the champion pipeline.</p></li>
<li><p><strong>Prediction Sanity:</strong> The distribution of the challenger’s predictions will be compared to the champion’s. We will check that the mean prediction has not shifted by an unexpected amount (e.g., &gt; 15%) and there are no catastrophic errors (e.g., all predictions are zero).</p></li>
</ul>
</li>
<li><p><strong>Outcome:</strong> If the shadow deployment passes, the model is automatically promoted to the Canary stage. If it fails, an alert is sent to the MLOps team for investigation.</p></li>
</ul>
<p><strong>Stage 2: Canary Release (Segment-based)</strong></p>
<ul class="simple">
<li><p><strong>Purpose:</strong> To measure the real-world business impact of the new model’s scores on a small, controlled segment of our marketing efforts before a full rollout.</p></li>
<li><p><strong>Execution:</strong></p>
<ol class="arabic simple">
<li><p>Both the champion and challenger models will score the <em>entire</em> active customer base.</p></li>
<li><p>For our next marketing campaign (e.g., a promotional email), the target audience will be split.</p></li>
<li><p><strong>95% of the audience (Control)</strong> will be selected based on the scores from the <strong>champion model</strong>.</p></li>
<li><p><strong>5% of the audience (Canary)</strong> will be selected based on the scores from the <strong>challenger model</strong>.</p></li>
<li><p>The campaign will be executed, and the results from the two segments will be tracked independently.</p></li>
</ol>
</li>
<li><p><strong>Success Criteria / Metrics:</strong></p>
<ul>
<li><p><strong>Primary Metric:</strong> The conversion rate of the Canary segment must be statistically equal to or greater than the Control segment.</p></li>
<li><p><strong>Guardrail Metric:</strong> The unsubscribe rate for the Canary segment must not be statistically higher than the Control.</p></li>
</ul>
</li>
<li><p><strong>Outcome:</strong> If the canary test is successful after a one-week run, the model can be approved for full production promotion.</p></li>
</ul>
<p><strong>Stage 3: Full Production Rollout</strong></p>
<ul class="simple">
<li><p><strong>Execution:</strong> After passing the Canary stage and receiving manual sign-off, the challenger model is promoted to the “Production” tag in the MLflow Model Registry. The next scheduled batch inference pipeline will automatically pick up and use this new model for all customers.</p></li>
</ul>
</section>
<section id="a-b-testing-framework-for-major-model-changes">
<h4><strong>4. A/B Testing Framework for Major Model Changes</strong><a class="headerlink" href="#a-b-testing-framework-for-major-model-changes" title="Permalink to this heading">¶</a></h4>
<p>For more significant changes (e.g., introducing a new model architecture or fundamentally new features), a simple canary release may be insufficient. We will use a formal A/B testing framework.</p>
<ul class="simple">
<li><p><strong>Hypothesis:</strong> A new CLV model (Challenger) that incorporates behavioral clickstream features will identify high-intent, high-value customers more accurately than the current RFM-based model (Champion), leading to a higher return on investment (ROI) for targeted marketing campaigns.</p></li>
<li><p><strong>Randomization Unit:</strong> <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code>.</p></li>
<li><p><strong>Traffic Split:</strong> 50% Control (Champion Model), 50% Treatment (Challenger Model).</p></li>
<li><p><strong>Metrics:</strong></p>
<ul>
<li><p><strong>Primary Metric:</strong> <strong>Incremental Revenue Per User</strong> from the targeted campaign. We will compare the average revenue generated from users in the Treatment group vs. the Control group.</p></li>
<li><p><strong>Secondary Metrics:</strong> Campaign Conversion Rate, Average Order Value (AOV).</p></li>
<li><p><strong>Guardrail Metrics:</strong> Marketing email unsubscribe rate, inference pipeline compute cost (the new model should not be prohibitively expensive).</p></li>
</ul>
</li>
<li><p><strong>Duration:</strong> The test will run for 4 weeks to capture multiple campaign cycles and mitigate short-term novelty effects.</p></li>
<li><p><strong>Decision:</strong> The Challenger will be adopted if it shows a statistically significant lift in the primary metric with a p-value &lt; 0.05, without any significant negative impact on guardrail metrics.</p></li>
</ul>
</section>
<section id="automating-the-continual-learning-testing-cycle">
<h4><strong>5. Automating the Continual Learning &amp; Testing Cycle</strong><a class="headerlink" href="#automating-the-continual-learning-testing-cycle" title="Permalink to this heading">¶</a></h4>
<p>We will use Airflow to orchestrate this entire end-to-end workflow.</p>
<ol class="arabic simple">
<li><p><strong>Monitoring Service (e.g., a custom Python script, SageMaker Model Monitor output analysis)</strong> runs daily/weekly.</p></li>
<li><p>If a <strong>retraining trigger</strong> (performance drop or drift alert) is detected, it makes an API call to Airflow to trigger the <code class="docutils literal notranslate"><span class="pre">clv_retraining_dag</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">clv_retraining_dag</span></code> runs, producing a new challenger model and registering it in MLflow with a “staging” tag.</p></li>
<li><p>Upon successful completion, the retraining DAG triggers the <code class="docutils literal notranslate"><span class="pre">clv_shadow_test_dag</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">clv_shadow_test_dag</span></code> runs. If it succeeds, it promotes the model to “ready-for-canary” in MLflow and sends a Slack notification for awareness.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">clv_canary_test_dag</span></code> is triggered manually by the marketing team for the next relevant campaign. It fetches the “ready-for-canary” model and runs the test.</p></li>
<li><p>After the canary test period, a final report is generated. A <strong>manual approval gate</strong> (e.g., using an Airflow <code class="docutils literal notranslate"><span class="pre">EmailOperator</span></code> or a custom UI) requires a Product Manager or MLOps Lead to sign off.</p></li>
<li><p>Upon approval, the model is promoted to the <strong>“Production”</strong> stage in MLflow, completing the cycle. The next run of the main <code class="docutils literal notranslate"><span class="pre">clv_batch_inference_pipeline</span></code> will automatically use this new champion.</p></li>
</ol>
<img src="../_static/past_experiences/ecom_cltv/continual_learning_retraining.svg" style="background-color: #FCF1EF;"/>
<p><strong>Automated Retraining Pipeline</strong></p>
<p>This Airflow DAG is triggered when our monitoring system detects a problem. It runs the training pipeline and, on success, promotes the new model to “Staging” and triggers the shadow test.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_automated_retraining.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.operators.trigger_dagrun</span> <span class="kn">import</span> <span class="n">TriggerDagRunOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerPipelineOperator</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="n">MLFLOW_TRACKING_URI</span> <span class="o">=</span> <span class="s2">&quot;http://your-mlflow-server:5000&quot;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-prediction-model&quot;</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_automated_retraining&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># This DAG is externally triggered</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Triggered by monitoring alerts (drift, performance degradation).</span>
<span class="s2">    Runs the SageMaker training pipeline and registers a new challenger model.</span>
<span class="s2">    On success, triggers the shadow deployment validation pipeline.</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;retraining&#39;</span><span class="p">,</span> <span class="s1">&#39;lifecycle&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">automated_retraining_dag</span><span class="p">():</span>

    <span class="c1"># This operator starts the SageMaker Pipeline we defined in the previous section.</span>
    <span class="n">trigger_sagemaker_training</span> <span class="o">=</span> <span class="n">SageMakerPipelineOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;trigger_sagemaker_training_pipeline&quot;</span><span class="p">,</span>
        <span class="n">pipeline_name</span><span class="o">=</span><span class="s2">&quot;CLV-Training-Pipeline&quot;</span><span class="p">,</span>
        <span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">,</span>
        <span class="n">wait_for_completion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># Ensure we wait until it&#39;s done</span>
    <span class="p">)</span>
    
    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">get_latest_model_version_and_promote_to_staging</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        After training, the SageMaker pipeline registers a model. This task finds</span>
<span class="sd">        the latest version, assumes it&#39;s the one we just trained, and promotes</span>
<span class="sd">        it to the &#39;Staging&#39; stage in MLflow.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="n">MLFLOW_TRACKING_URI</span><span class="p">)</span>
        <span class="c1"># Find the most recently registered version of our model</span>
        <span class="n">latest_version</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_latest_versions</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;None&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found new model version: </span><span class="si">{</span><span class="n">latest_version</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">. Transitioning to &#39;Staging&#39;.&quot;</span><span class="p">)</span>
        
        <span class="n">client</span><span class="o">.</span><span class="n">transition_model_version_stage</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span>
            <span class="n">version</span><span class="o">=</span><span class="n">latest_version</span><span class="o">.</span><span class="n">version</span><span class="p">,</span>
            <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;Staging&quot;</span><span class="p">,</span>
            <span class="n">archive_existing_versions</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># Demotes any existing model in &#39;Staging&#39;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">latest_version</span><span class="o">.</span><span class="n">version</span>

    <span class="c1"># Trigger the shadow test pipeline, passing the new model version for validation.</span>
    <span class="n">trigger_shadow_test</span> <span class="o">=</span> <span class="n">TriggerDagRunOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;trigger_shadow_deployment&quot;</span><span class="p">,</span>
        <span class="n">trigger_dag_id</span><span class="o">=</span><span class="s2">&quot;clv_shadow_deployment&quot;</span><span class="p">,</span>
        <span class="n">conf</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model_version&quot;</span><span class="p">:</span> <span class="s2">&quot;{{ task_instance.xcom_pull(task_ids=&#39;get_latest_model_version_and_promote_to_staging&#39;) }}&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">new_model_version</span> <span class="o">=</span> <span class="n">get_latest_model_version_and_promote_to_staging</span><span class="p">()</span>
    
    <span class="n">trigger_sagemaker_training</span> <span class="o">&gt;&gt;</span> <span class="n">new_model_version</span> <span class="o">&gt;&gt;</span> <span class="n">trigger_shadow_test</span>

<span class="n">automated_retraining_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Shadow Deployment Pipeline</strong></p>
<p>This DAG compares the new “Staging” model against the “Production” champion on live data without affecting users.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_shadow_deployment.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerTransformOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.hooks.s3</span> <span class="kn">import</span> <span class="n">S3Hook</span>
<span class="kn">from</span> <span class="nn">airflow.models.param</span> <span class="kn">import</span> <span class="n">Param</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">MLFLOW_TRACKING_URI</span> <span class="o">=</span> <span class="s2">&quot;http://your-mlflow-server:5000&quot;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-prediction-model&quot;</span>
<span class="n">SAGEMAKER_ROLE</span> <span class="o">=</span> <span class="s2">&quot;arn:aws:iam::ACCOUNT_ID:role/sagemaker-inference-execution-role&quot;</span>
<span class="n">INPUT_S3_URI</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-inference-data-bucket/input/active_customers.jsonl&quot;</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_shadow_deployment&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Triggered by the retraining DAG</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model_version&quot;</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;null&quot;</span><span class="p">,</span> <span class="s2">&quot;string&quot;</span><span class="p">])},</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;Compares a &#39;Staging&#39; challenger model against the &#39;Production&#39; champion.&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="s1">&#39;lifecycle&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">shadow_deployment_dag</span><span class="p">():</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">get_model_uris</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fetches S3 URIs for both the Production and new Staging models.&quot;&quot;&quot;</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="n">MLFLOW_TRACKING_URI</span><span class="p">)</span>
        
        <span class="c1"># Get Production model</span>
        <span class="n">prod_model</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_latest_versions</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Production&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Get Challenger (Staging) model version from the trigger payload</span>
        <span class="n">challenger_version</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="s2">&quot;model_version&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">challenger_version</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No model_version passed in the trigger config.&quot;</span><span class="p">)</span>
            
        <span class="n">challenger_model</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_model_version</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">challenger_version</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Champion Model: v</span><span class="si">{</span><span class="n">prod_model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Challenger Model: v</span><span class="si">{</span><span class="n">challenger_model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;champion_uri&quot;</span><span class="p">:</span> <span class="n">prod_model</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
            <span class="s2">&quot;challenger_uri&quot;</span><span class="p">:</span> <span class="n">challenger_model</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
            <span class="s2">&quot;challenger_version&quot;</span><span class="p">:</span> <span class="n">challenger_model</span><span class="o">.</span><span class="n">version</span>
        <span class="p">}</span>
    
    <span class="n">model_uris</span> <span class="o">=</span> <span class="n">get_model_uris</span><span class="p">()</span>

    <span class="c1"># Assume SageMaker model objects are created/updated based on these URIs</span>
    <span class="c1"># These tasks run the inference jobs</span>
    <span class="n">run_champion_inference</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;run_champion_inference&quot;</span><span class="p">,</span>
        <span class="c1"># Config would point to the champion model object</span>
    <span class="p">)</span>
    
    <span class="n">run_challenger_inference</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;run_challenger_inference&quot;</span><span class="p">,</span>
        <span class="c1"># Config would point to the challenger model object</span>
    <span class="p">)</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">compare_shadow_results</span><span class="p">(</span><span class="n">champion_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">challenger_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">challenger_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compares prediction distributions from both models.&quot;&quot;&quot;</span>
        <span class="n">s3_hook</span> <span class="o">=</span> <span class="n">S3Hook</span><span class="p">(</span><span class="n">aws_conn_id</span><span class="o">=</span><span class="s2">&quot;aws_default&quot;</span><span class="p">)</span>
        
        <span class="c1"># This is simplified. In reality, you&#39;d download the files from S3.</span>
        <span class="n">champion_preds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">champion_output</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">challenger_preds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">challenger_output</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">champion_mean</span> <span class="o">=</span> <span class="n">champion_preds</span><span class="p">[</span><span class="s1">&#39;CLV_Prediction&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">challenger_mean</span> <span class="o">=</span> <span class="n">challenger_preds</span><span class="p">[</span><span class="s1">&#39;CLV_Prediction&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        
        <span class="n">percent_diff</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">challenger_mean</span> <span class="o">-</span> <span class="n">champion_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">champion_mean</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Champion Mean Prediction: </span><span class="si">{</span><span class="n">champion_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Challenger Mean Prediction: </span><span class="si">{</span><span class="n">challenger_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Percentage Difference: </span><span class="si">{</span><span class="n">percent_diff</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Validation Gate: Pass if the mean prediction is within 15%</span>
        <span class="k">if</span> <span class="n">percent_diff</span> <span class="o">&lt;</span> <span class="mf">0.15</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shadow test PASSED. Promoting model to &#39;Ready-for-Canary&#39;.&quot;</span><span class="p">)</span>
            <span class="n">client</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="n">MLFLOW_TRACKING_URI</span><span class="p">)</span>
            <span class="n">client</span><span class="o">.</span><span class="n">transition_model_version_stage</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="n">challenger_version</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;Ready-for-Canary&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shadow test FAILED. Mean prediction shifted too much.&quot;</span><span class="p">)</span>
            <span class="c1"># Trigger failure alert here (e.g., via SnsPublishOperator)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shadow test failed.&quot;</span><span class="p">)</span>

    <span class="c1"># Define dependencies</span>
    <span class="p">[</span><span class="n">run_champion_inference</span><span class="p">,</span> <span class="n">run_challenger_inference</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">compare_shadow_results</span><span class="p">(</span>
        <span class="n">champion_output</span><span class="o">=</span><span class="n">run_champion_inference</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span>
        <span class="n">challenger_output</span><span class="o">=</span><span class="n">run_challenger_inference</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span>
        <span class="n">challenger_version</span><span class="o">=</span><span class="n">model_uris</span><span class="p">[</span><span class="s2">&quot;challenger_version&quot;</span><span class="p">],</span>
    <span class="p">)</span>

<span class="n">shadow_deployment_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Canary Release Pipeline</strong></p>
<p>This DAG prepares data segments for the marketing team to run a live canary test.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_canary_release.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerTransformOperator</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_canary_release_prep&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Manually triggered for a campaign</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;Prepares customer segments for a live canary test.&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="s1">&#39;lifecycle&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">canary_release_prep_dag</span><span class="p">():</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">get_canary_and_champion_models</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="c1"># Fetches URIs for &#39;Production&#39; and &#39;Ready-for-Canary&#39; models from MLflow</span>
        <span class="c1"># (Similar logic to the shadow DAG)</span>
        <span class="k">pass</span>

    <span class="n">model_uris</span> <span class="o">=</span> <span class="n">get_canary_and_champion_models</span><span class="p">()</span>
    
    <span class="c1"># Run two batch transform jobs to score all customers with both models</span>
    <span class="n">score_with_champion</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">score_with_challenger</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">generate_campaign_segments</span><span class="p">(</span><span class="n">champion_scores_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">challenger_scores_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Splits customers into control and canary groups for the campaign.&quot;&quot;&quot;</span>
        <span class="c1"># This task would:</span>
        <span class="c1"># 1. Load both sets of scores from S3.</span>
        <span class="c1"># 2. Sort customers by predicted CLV for each model.</span>
        <span class="c1"># 3. Select the top N customers based on champion scores for the control group.</span>
        <span class="c1"># 4. Select the top N*0.05 customers based on challenger scores for the canary group.</span>
        <span class="c1"># 5. Save two separate CSV files (control_group.csv, canary_group.csv) to an S3 bucket</span>
        <span class="c1">#    for the marketing team to use.</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated control and canary group files.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;Campaign segments are ready in S3.&quot;</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">notify_marketing_team</span><span class="p">(</span><span class="n">status</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># This task would send an email or Slack message.</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Notifying marketing team: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Define dependencies</span>
    <span class="p">[</span><span class="n">score_with_champion</span><span class="p">,</span> <span class="n">score_with_challenger</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">generate_campaign_segments</span><span class="p">(</span>
        <span class="c1">#... pass paths ...</span>
    <span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">notify_marketing_team</span><span class="p">()</span>

<span class="n">canary_release_prep_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Manual Model Promotion Pipeline</strong></p>
<p>This is the final, human-driven step to make a new model the official champion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_promote_to_production.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.models.param</span> <span class="kn">import</span> <span class="n">Param</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_promote_model_to_production&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Manually triggered only</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model_version_to_promote&quot;</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;The model version to promote to Production&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">)},</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;Manual gate to promote a validated model version to &#39;Production&#39;.&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;promotion&#39;</span><span class="p">,</span> <span class="s1">&#39;lifecycle&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">promote_to_production_dag</span><span class="p">():</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">promote_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">version</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="s2">&quot;model_version_to_promote&quot;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Promoting model version </span><span class="si">{</span><span class="n">version</span><span class="si">}</span><span class="s2"> to &#39;Production&#39;...&quot;</span><span class="p">)</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">tracking</span><span class="o">.</span><span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="s2">&quot;http://your-mlflow-server:5000&quot;</span><span class="p">)</span>
        <span class="n">client</span><span class="o">.</span><span class="n">transition_model_version_stage</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;clv-prediction-model&quot;</span><span class="p">,</span>
            <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">,</span>
            <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;Production&quot;</span><span class="p">,</span>
            <span class="n">archive_existing_versions</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promotion successful.&quot;</span><span class="p">)</span>

    <span class="n">promote_model</span><span class="p">()</span>

<span class="n">promote_to_production_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>CI/CD Workflow for All Pipelines</strong></p>
<p>This workflow validates all the new lifecycle DAGs.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># .github/workflows/cicd_lifecycle_pipelines.yml</span>

<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;CI/CD</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">Model</span><span class="nv"> </span><span class="s">Lifecycle</span><span class="nv"> </span><span class="s">DAGs&quot;</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
<span class="w">    </span><span class="nt">paths</span><span class="p">:</span>
<span class="w">      </span><span class="c1"># Add paths to all the new DAGs and any new src files</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_automated_retraining.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_shadow_deployment.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_canary_release.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_promote_to_production.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;.github/workflows/cicd_lifecycle_pipelines.yml&#39;</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">validate-dags</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Validate</span><span class="nv"> </span><span class="s">Lifecycle</span><span class="nv"> </span><span class="s">DAGs&quot;</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout Repository</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v4</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.9</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install Dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install -r requirements.txt</span>
<span class="w">          </span><span class="no">pip install -r tests/requirements.txt</span>
<span class="w">      </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run Linting Checks</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install flake8</span>
<span class="w">          </span><span class="no"># Run flake8 on the new DAG files</span>
<span class="w">          </span><span class="no">flake8 pipelines/dag_automated_retraining.py pipelines/dag_shadow_deployment.py ...</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Validate Airflow DAG Integrity</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no"># Use the airflow standalone command to check for syntax errors</span>
<span class="w">          </span><span class="no">airflow dags list --subset pipelines/dag_automated_retraining.py</span>
<span class="w">          </span><span class="no">airflow dags list --subset pipelines/dag_shadow_deployment.py</span>
<span class="w">          </span><span class="no"># ... and so on for the other new DAGs</span>
</pre></div>
</div>
</section>
</section>
<section id="a-b-testing">
<h3>A/B Testing<a class="headerlink" href="#a-b-testing" title="Permalink to this heading">¶</a></h3>
<p><strong>Architecture Diagram</strong></p>
<p>This diagram shows the two main phases: the Setup Phase (orchestrated by Airflow) and the Analysis Phase (performed by a data scientist after the experiment period).</p>
<img src="../_static/past_experiences/ecom_cltv/ab_testing.svg" style="background-color: #FCF1EF;"/>
<p><strong>Infrastructure as Code</strong></p>
<p>We need a dedicated SNS topic to notify stakeholders when the A/B test segments are ready.</p>
<div class="highlight-hcl notranslate"><div class="highlight"><pre><span></span><span class="c1"># terraform/ab_testing.tf</span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">&quot;aws_sns_topic&quot;</span><span class="w"> </span><span class="nv">&quot;ab_test_notifications_topic&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;clv-ab-test-notifications&quot;</span>
<span class="w">  </span><span class="na">display_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Notifications for CLV A/B Test Readiness&quot;</span>
<span class="w">  </span>
<span class="w">  </span><span class="nb">tags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="na">Environment</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.environment</span>
<span class="w">    </span><span class="na">Purpose</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;AB-Testing&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># We will reuse the sagemaker_inference_role created previously.</span>
<span class="c1"># No new roles are needed if permissions are broad enough.</span>
</pre></div>
</div>
<p><strong>A/B Test Setup Airflow DAG</strong></p>
<p>This DAG prepares all the necessary data for the marketing and analytics teams to run the A/B test.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipelines/dag_ab_test_setup.py</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">dag</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.operators.sagemaker</span> <span class="kn">import</span> <span class="n">SageMakerTransformOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.sns.operators.sns</span> <span class="kn">import</span> <span class="n">SnsPublishOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.amazon.aws.hooks.s3</span> <span class="kn">import</span> <span class="n">S3Hook</span>
<span class="kn">from</span> <span class="nn">airflow.models.param</span> <span class="kn">import</span> <span class="n">Param</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># --- Constants ---</span>
<span class="n">MLFLOW_TRACKING_URI</span> <span class="o">=</span> <span class="s2">&quot;http://your-mlflow-server:5000&quot;</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;clv-prediction-model&quot;</span>
<span class="n">BASE_S3_PATH</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-inference-data-bucket/ab-tests&quot;</span>
<span class="n">CUSTOMER_LIST_PATH</span> <span class="o">=</span> <span class="s2">&quot;s3://clv-inference-data-bucket/input/active_customers.jsonl&quot;</span>
<span class="n">SNS_TOPIC_ARN</span> <span class="o">=</span> <span class="s2">&quot;arn:aws:sns:eu-west-1:ACCOUNT_ID:clv-ab-test-notifications&quot;</span>

<span class="nd">@dag</span><span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;clv_ab_test_setup&quot;</span><span class="p">,</span>
    <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">schedule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Manually triggered for major tests</span>
    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;challenger_version&quot;</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The challenger model version from MLflow to test.&quot;</span><span class="p">)},</span>
    <span class="n">doc_md</span><span class="o">=</span><span class="s2">&quot;Sets up a formal A/B test by scoring all users with Champion and Challenger models and assigning them to groups.&quot;</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;clv&#39;</span><span class="p">,</span> <span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="s1">&#39;ab-test&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">ab_test_setup_dag</span><span class="p">():</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">get_model_uris</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fetches S3 URIs for the Production (Champion) and specified Challenger models.&quot;&quot;&quot;</span>
        <span class="c1"># Logic to fetch champion and challenger URIs from MLflow</span>
        <span class="c1"># ... (similar to shadow DAG) ...</span>
        <span class="k">pass</span>

    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">assign_users_to_groups</span><span class="p">(</span><span class="n">run_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Randomly assigns all active customers to a &#39;control&#39; or &#39;treatment&#39; group.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Assigning users to A/B test groups...&quot;</span><span class="p">)</span>
        <span class="n">s3_hook</span> <span class="o">=</span> <span class="n">S3Hook</span><span class="p">()</span>
        <span class="n">customer_file</span> <span class="o">=</span> <span class="n">s3_hook</span><span class="o">.</span><span class="n">download_file</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">CUSTOMER_LIST_PATH</span><span class="p">)</span>
        <span class="n">customers_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">customer_file</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Assign each user to a group</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> <span class="c1"># for reproducibility</span>
        <span class="n">customers_df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">&#39;control&#39;</span><span class="p">,</span> <span class="s1">&#39;treatment&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">customers_df</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
        
        <span class="n">output_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;ab-tests/</span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span><span class="s2">/assignments/user_assignments.csv&quot;</span>
        <span class="n">s3_hook</span><span class="o">.</span><span class="n">load_string</span><span class="p">(</span>
            <span class="n">string_data</span><span class="o">=</span><span class="n">customers_df</span><span class="p">[[</span><span class="s1">&#39;CustomerID&#39;</span><span class="p">,</span> <span class="s1">&#39;group&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">key</span><span class="o">=</span><span class="n">output_path</span><span class="p">,</span>
            <span class="n">bucket_name</span><span class="o">=</span><span class="s2">&quot;clv-inference-data-bucket&quot;</span><span class="p">,</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;User assignments saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_path</span>

    <span class="n">model_uris</span> <span class="o">=</span> <span class="n">get_model_uris</span><span class="p">()</span>
    <span class="n">user_assignments_path</span> <span class="o">=</span> <span class="n">assign_users_to_groups</span><span class="p">(</span><span class="n">run_id</span><span class="o">=</span><span class="s2">&quot;{{ run_id }}&quot;</span><span class="p">)</span>
    
    <span class="c1"># Run two parallel batch transform jobs</span>
    <span class="n">run_champion_job</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">run_challenger_job</span> <span class="o">=</span> <span class="n">SageMakerTransformOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="nd">@task</span>
    <span class="k">def</span> <span class="nf">notify_stakeholders</span><span class="p">(</span><span class="n">run_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sends a notification that the A/B test setup is complete.&quot;&quot;&quot;</span>
        <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        A/B Test Setup Complete for run_id: </span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span>

<span class="s2">        The following artifacts are ready for the Marketing and Analytics teams:</span>
<span class="s2">        - User Group Assignments: s3://clv-inference-data-bucket/ab-tests/</span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span><span class="s2">/assignments/</span>
<span class="s2">        - Champion Model Scores: </span><span class="si">{</span><span class="n">run_champion_job</span><span class="o">.</span><span class="n">output_path</span><span class="si">}</span>
<span class="s2">        - Challenger Model Scores: </span><span class="si">{</span><span class="n">run_challenger_job</span><span class="o">.</span><span class="n">output_path</span><span class="si">}</span>
<span class="s2">        </span>
<span class="s2">        The experiment can now begin.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">message</span>

    <span class="n">notification</span> <span class="o">=</span> <span class="n">notify_stakeholders</span><span class="p">(</span><span class="n">run_id</span><span class="o">=</span><span class="s2">&quot;{{ run_id }}&quot;</span><span class="p">)</span>

    <span class="n">publish_notification</span> <span class="o">=</span> <span class="n">SnsPublishOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;publish_setup_complete_notification&quot;</span><span class="p">,</span>
        <span class="n">target_arn</span><span class="o">=</span><span class="n">SNS_TOPIC_ARN</span><span class="p">,</span>
        <span class="n">message</span><span class="o">=</span><span class="n">notification</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Dependencies</span>
    <span class="p">[</span><span class="n">run_champion_job</span><span class="p">,</span> <span class="n">run_challenger_job</span><span class="p">]</span>
    <span class="n">user_assignments_path</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">run_champion_job</span><span class="p">,</span> <span class="n">run_challenger_job</span><span class="p">]</span>
    <span class="n">model_uris</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">run_champion_job</span><span class="p">,</span> <span class="n">run_challenger_job</span><span class="p">]</span>
    <span class="p">[</span><span class="n">run_champion_job</span><span class="p">,</span> <span class="n">run_challenger_job</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">notification</span> <span class="o">&gt;&gt;</span> <span class="n">publish_notification</span>

<span class="n">ab_test_setup_dag</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Analysis Notebook</strong>
After the experiment period (e.g., 4 weeks), a data scientist would use this notebook to analyze the results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># analysis/analyze_ab_test_results.ipynb</span>

<span class="c1"># --- 1. Setup and Load Data ---</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># In a real scenario, you would load the results from your data warehouse.</span>
<span class="c1"># Here, we simulate the final dataset.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simulating experimental results...&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">num_users</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="c1"># Load the user assignments from the DAG run</span>
<span class="c1"># user_assignments = pd.read_csv(&quot;s3://clv-inference-data-bucket/ab-tests/RUN_ID/assignments/user_assignments.csv&quot;)</span>
<span class="n">user_assignments</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;CustomerID&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_users</span><span class="p">),</span>
    <span class="s1">&#39;group&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">&#39;control&#39;</span><span class="p">,</span> <span class="s1">&#39;treatment&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">num_users</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="p">})</span>

<span class="c1"># Simulate revenue generated during the 4-week test period</span>
<span class="c1"># Let&#39;s assume the treatment group had a small positive effect</span>
<span class="n">control_revenue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">user_assignments</span><span class="p">[</span><span class="n">user_assignments</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;control&#39;</span><span class="p">]))</span>
<span class="n">treatment_revenue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mf">1.6</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">user_assignments</span><span class="p">[</span><span class="n">user_assignments</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;treatment&#39;</span><span class="p">]))</span>

<span class="n">user_assignments</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">user_assignments</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;control&#39;</span><span class="p">,</span> <span class="s1">&#39;revenue&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">control_revenue</span>
<span class="n">user_assignments</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">user_assignments</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;treatment&#39;</span><span class="p">,</span> <span class="s1">&#39;revenue&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">treatment_revenue</span>

<span class="n">results_df</span> <span class="o">=</span> <span class="n">user_assignments</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Data Loaded ---&quot;</span><span class="p">)</span>

<span class="c1"># --- 2. Analyze Primary Metric: Incremental Revenue Per User ---</span>
<span class="n">control_group</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;control&#39;</span><span class="p">][</span><span class="s1">&#39;revenue&#39;</span><span class="p">]</span>
<span class="n">treatment_group</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;treatment&#39;</span><span class="p">][</span><span class="s1">&#39;revenue&#39;</span><span class="p">]</span>

<span class="n">avg_control_revenue</span> <span class="o">=</span> <span class="n">control_group</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">avg_treatment_revenue</span> <span class="o">=</span> <span class="n">treatment_group</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">lift</span> <span class="o">=</span> <span class="p">(</span><span class="n">avg_treatment_revenue</span> <span class="o">-</span> <span class="n">avg_control_revenue</span><span class="p">)</span> <span class="o">/</span> <span class="n">avg_control_revenue</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- A/B Test Results ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Control Group Mean Revenue: $</span><span class="si">{</span><span class="n">avg_control_revenue</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Treatment Group Mean Revenue: $</span><span class="si">{</span><span class="n">avg_treatment_revenue</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed Lift: </span><span class="si">{</span><span class="n">lift</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># --- 3. Statistical Significance Testing (t-test) ---</span>
<span class="c1"># Perform an independent t-test to check if the difference is statistically significant</span>
<span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">treatment_group</span><span class="p">,</span> <span class="n">control_group</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Welch&#39;s t-test</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">T-statistic: </span><span class="si">{</span><span class="n">t_stat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Result is STATISTICALLY SIGNIFICANT at alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">. We reject the null hypothesis.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Result is NOT statistically significant at alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">. We fail to reject the null hypothesis.&quot;</span><span class="p">)</span>

<span class="c1"># --- 4. Visualize the Results ---</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">control_group</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Control Group&quot;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">element</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">treatment_group</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Treatment Group&quot;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">element</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of Revenue per User&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># --- 5. Conclusion ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Conclusion ---&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The challenger model led to a statistically significant increase in revenue per user.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recommendation: Promote the challenger model to production.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The challenger model did not show a statistically significant improvement over the champion.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recommendation: Do not ship. Re-evaluate the model or iterate further.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>CI Workflow for A/B Test DAG</strong></p>
<p>This ensures the setup DAG is always valid before being merged.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># .github/workflows/ci_ab_test_dag.yml</span>

<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;CI</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">A/B</span><span class="nv"> </span><span class="s">Test</span><span class="nv"> </span><span class="s">Setup</span><span class="nv"> </span><span class="s">DAG&quot;</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
<span class="w">    </span><span class="nt">paths</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;pipelines/dag_ab_test_setup.py&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;.github/workflows/ci_ab_test_dag.yml&#39;</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">validate-ab-test-dag</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Validate</span><span class="nv"> </span><span class="s">A/B</span><span class="nv"> </span><span class="s">Test</span><span class="nv"> </span><span class="s">DAG&quot;</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout Repository</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v4</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.9</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install Dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install -r requirements.txt</span>
<span class="w">      </span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Validate Airflow DAG Integrity</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no"># Use the airflow standalone command to check for syntax errors</span>
<span class="w">          </span><span class="no">airflow dags list --subset pipelines/dag_ab_test_setup.py</span>
</pre></div>
</div>
</section>
<section id="governance-ethics-the-human-element">
<h3><strong>Governance, Ethics &amp; The Human Element</strong><a class="headerlink" href="#governance-ethics-the-human-element" title="Permalink to this heading">¶</a></h3>
<section id="guiding-philosophy-building-a-trustworthy-and-compliant-system">
<h4><strong>1. Guiding Philosophy: Building a Trustworthy and Compliant System</strong><a class="headerlink" href="#guiding-philosophy-building-a-trustworthy-and-compliant-system" title="Permalink to this heading">¶</a></h4>
<p>Our core philosophy is that effective <strong>Model Governance</strong> and <strong>Responsible AI (RAI)</strong> practices are not optional add-ons but are integral to the long-term success and viability of the CLV prediction system. Given that this system directly influences marketing decisions, customer segmentation, and potentially financial outcomes (promotions, offers), it falls into a category requiring a high degree of diligence. We will integrate governance and ethical checks throughout the MLOps lifecycle.</p>
</section>
<section id="comprehensive-model-governance-plan">
<h4><strong>2. Comprehensive Model Governance Plan</strong><a class="headerlink" href="#comprehensive-model-governance-plan" title="Permalink to this heading">¶</a></h4>
<p>We will implement a governance framework tailored to our MLOps lifecycle, focusing on reproducibility, validation, and control.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>ML Lifecycle Stage</p></th>
<th class="head text-left"><p>Governance Component</p></th>
<th class="head text-left"><p>Actions &amp; Artifacts for the CLV Project</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Development</strong></p></td>
<td class="text-left"><p><strong>Reproducibility &amp; Validation</strong></p></td>
<td class="text-left"><p><strong>1. Model Registry (MLflow):</strong> Every production and challenger model will have its metadata logged, including: Git commit hash of the training code, DVC hash of the training data, key hyperparameters, and final offline evaluation metrics (RMSE, Gini, Fairness metrics). <br> <strong>2. Model Card:</strong> We will generate and attach a <code class="docutils literal notranslate"><span class="pre">ModelCard.md</span></code> to every registered “Production” model version. This will document its intended use, limitations, training data overview, evaluation results on key slices, and fairness assessments. <br> <strong>3. Data Sheets:</strong> The schema and source of our core datasets (transactional, behavioral) will be documented using Great Expectations, serving as our “Data Sheets”.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Deployment &amp; Operations</strong></p></td>
<td class="text-left"><p><strong>Observation, Control &amp; Auditability</strong></p></td>
<td class="text-left"><p><strong>1. Versioned Deployments:</strong> All deployments of inference pipelines (our weekly batch job) will be tied to a specific version-controlled Airflow DAG and a versioned model from the registry. <br> <strong>2. Access Control (IAM):</strong> We will use specific, least-privilege IAM roles for each component (Airflow, SageMaker Training, SageMaker Inference) to control access to data and resources. <br> <strong>3. Logging &amp; Audit Trail:</strong> All pipeline runs (Airflow), model training jobs (SageMaker), and inference jobs (SageMaker Batch Transform) will generate detailed logs stored in CloudWatch. Prediction outputs will be logged to S3 with metadata linking them to the exact model version used. This creates a complete, auditable trail from prediction back to the source model, code, and data.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Cross-Cutting</strong></p></td>
<td class="text-left"><p><strong>Model Service Catalog</strong></p></td>
<td class="text-left"><p>The MLflow Model Registry will serve as our internal catalog, allowing stakeholders to discover available CLV models, view their performance, and understand their current deployment stage (Staging, Production, Archived).</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="responsible-ai-rai-practices">
<h4><strong>3. Responsible AI (RAI) Practices</strong><a class="headerlink" href="#responsible-ai-rai-practices" title="Permalink to this heading">¶</a></h4>
<p>We will proactively address the key pillars of Responsible AI to ensure our CLV model is fair, transparent, and secure.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>RAI Pillar</p></th>
<th class="head text-left"><p>Plan for the CLV Project</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Fairness</strong></p></td>
<td class="text-left"><p><strong>1. Identify Potential Biases:</strong> We recognize that our historical sales data may contain biases. For example, marketing efforts might have historically targeted specific demographics, leading to <em>representation bias</em>. <br> <strong>2. Fairness as a Guardrail Metric:</strong> During the offline evaluation step of our training pipeline, we will calculate the <strong>Disparate Impact Ratio</strong>. We will measure the average predicted CLV for different customer segments (e.g., based on <code class="docutils literal notranslate"><span class="pre">country</span></code> or <code class="docutils literal notranslate"><span class="pre">acquisition_channel</span></code>) and calculate the ratio between the lowest-scoring and highest-scoring groups. <br> <strong>3. Mitigation Strategy:</strong> If this ratio falls below a threshold (e.g., 0.8), the model will be flagged, and it will not be automatically promoted. This will trigger a manual review by the data science team, who may need to apply pre-processing techniques like re-weighting the training data for the under-predicted segment.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Explainability (XAI)</strong></p></td>
<td class="text-left"><p><strong>1. Global Explainability:</strong> For each production model, we will generate and store a global feature importance plot using aggregated SHAP values. This will be included in the Model Card to help business stakeholders understand the primary drivers of CLV across the entire customer base. <br> <strong>2. Local Explainability:</strong> Our batch inference pipeline will be configured to optionally generate and log SHAP values for each individual prediction. While not enabled by default to save costs, this capability can be turned on for debugging specific customer predictions or for providing explanations to customer service teams.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Transparency</strong></p></td>
<td class="text-left"><p><strong>1. Model Cards:</strong> The Model Card is our primary tool for transparency. It will be our “nutrition label” for the model. <br> <strong>2. Internal Communication:</strong> We will establish a clear process for communicating model updates and their expected impact (from A/B test results) to the marketing and business intelligence teams.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Privacy</strong></p></td>
<td class="text-left"><p><strong>1. PII Handling:</strong> Our data ingestion pipelines will include a explicit step to hash or anonymize any direct Personally Identifiable Information (PII) like names or full addresses before storing it in our analytical data lake. The <code class="docutils literal notranslate"><span class="pre">CustomerID</span></code> will be a pseudonymized key. <br> <strong>2. Data Minimization:</strong> We will only use the data necessary for the CLV task and will not ingest unrelated sensitive customer data.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Security</strong></p></td>
<td class="text-left"><p><strong>1. Endpoint Security:</strong> N/A as we are using a batch pipeline, not a real-time API. <br> <strong>2. Access Control:</strong> All access to data (S3), code (Git), and infrastructure (AWS) is managed via strict IAM roles and policies. <br> <strong>3. Secret Management:</strong> Database credentials and other secrets are stored securely in AWS Secrets Manager, not in code.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="holistic-system-testing-production-readiness">
<h4><strong>4. Holistic System Testing &amp; Production Readiness</strong><a class="headerlink" href="#holistic-system-testing-production-readiness" title="Permalink to this heading">¶</a></h4>
<p>We will use the <strong>ML Test Score</strong> framework as a guiding checklist to assess our production readiness.</p>
<ul class="simple">
<li><p><strong>Data Tests:</strong> We have already implemented several of these with Great Expectations (schema checks, feature expectations). We will add a manual review step to ensure no features inadvertently contain PII.</p></li>
<li><p><strong>Model Development Tests:</strong></p>
<ul>
<li><p>Our model specs are versioned in Git and peer-reviewed.</p></li>
<li><p>We have a plan to correlate offline metrics with online A/B test results.</p></li>
<li><p>Our training pipeline includes hyperparameter tuning.</p></li>
<li><p>We have a baseline model (Linear Regression) to compare against.</p></li>
<li><p>We have slice-based performance checks for fairness (<code class="docutils literal notranslate"><span class="pre">evaluate_on_slices</span></code>).</p></li>
</ul>
</li>
<li><p><strong>ML Infrastructure Tests:</strong></p>
<ul>
<li><p>Our training is reproducible via versioned code, data, and config.</p></li>
<li><p>Our pipeline is integration tested via the CD workflow (<code class="docutils literal notranslate"><span class="pre">cd_training_pipeline.yml</span></code>).</p></li>
<li><p>Model quality is validated before promotion (automated checks and manual gates).</p></li>
<li><p>We have a rollback mechanism (promoting the previous “Production” model from the MLflow archive).</p></li>
</ul>
</li>
<li><p><strong>Monitoring Tests:</strong></p>
<ul>
<li><p>We have monitoring for data invariants (Great Expectations), feature compute skew (by using a Feature Store), and prediction quality drift (PSI monitoring).</p></li>
</ul>
</li>
</ul>
<p>Our self-assessed ML Test Score for this plan would be high, indicating a strong degree of production readiness.</p>
</section>
<section id="human-element-team-structure-user-centric-design">
<h4><strong>5. Human Element: Team Structure &amp; User-Centric Design</strong><a class="headerlink" href="#human-element-team-structure-user-centric-design" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Team Structure:</strong> We will operate on a <strong>Platform-Enabled Model</strong>.</p>
<ul>
<li><p>The <strong>ML Platform Team</strong> (MLOps Engineers) is responsible for building and maintaining the automated MLOps infrastructure (the Airflow DAGs, CI/CD workflows, Terraform modules, monitoring stack).</p></li>
<li><p>The <strong>Data Science Team</strong> (ML Engineers/Data Scientists) is responsible for the “Task” of building the CLV model. They own the model development code (<code class="docutils literal notranslate"><span class="pre">src/</span></code>), the evaluation logic, and are the primary consumers of the platform. They are responsible for analyzing model performance and proposing improvements.</p></li>
</ul>
</li>
<li><p><strong>User-Centric Design:</strong> The “users” of our CLV model are the marketing and business intelligence teams.</p>
<ul>
<li><p><strong>Managing Expectations:</strong> We will communicate clearly that the CLV score is a <em>prediction</em>, not a guarantee. The Model Card will document the model’s RMSE to provide a clear indication of its average error range.</p></li>
<li><p><strong>Building Trust:</strong> By providing explanations for model behavior (via feature importance) and being transparent about its performance (via dashboards), we will build the marketing team’s trust in the scores, encouraging them to use the output effectively in their campaigns.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="system-architecture-cost-performance-optimisations">
<h3>System Architecture, Cost, Performance Optimisations<a class="headerlink" href="#system-architecture-cost-performance-optimisations" title="Permalink to this heading">¶</a></h3>
<section id="overall-system-architecture-diagram">
<h4>Overall System Architecture Diagram<a class="headerlink" href="#overall-system-architecture-diagram" title="Permalink to this heading">¶</a></h4>
<img src="../_static/past_experiences/ecom_cltv/overall_system_architecture_diagram.svg" style="background-color: #FCF1EF;"/>
</section>
<section id="sequence-diagram-batch-inference">
<h4>Sequence Diagram: Batch Inference<a class="headerlink" href="#sequence-diagram-batch-inference" title="Permalink to this heading">¶</a></h4>
<img src="../_static/past_experiences/ecom_cltv/sequence_diagram_inference.svg" style="background-color: #FCF1EF;"/>
</section>
<section id="latency-potential-bottlenecks-and-optimizations">
<h4>Latency, Potential Bottlenecks, and Optimizations<a class="headerlink" href="#latency-potential-bottlenecks-and-optimizations" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Total Pipeline Latency:</strong> The end-to-end latency is dominated by the SageMaker Batch Transform job runtime. A realistic estimate for scoring 1 million customers on moderately complex instances would be <strong>1 to 3 hours</strong>.</p></li>
<li><p><strong>Potential Bottlenecks &amp; Optimizations:</strong></p>
<ol class="arabic simple">
<li><p><strong>Bottleneck:</strong> <strong>Feature Retrieval.</strong> If our inference script naively calls <code class="docutils literal notranslate"><span class="pre">GetRecord</span></code> from the Online Feature Store for every single customer, this will be the biggest bottleneck. A single <code class="docutils literal notranslate"><span class="pre">GetRecord</span></code> call might take ~10-20ms. For 1 million customers, this would be <code class="docutils literal notranslate"><span class="pre">1,000,000</span> <span class="pre">*</span> <span class="pre">0.015s</span> <span class="pre">≈</span> <span class="pre">4.2</span> <span class="pre">hours</span></code> of just waiting for feature data, overwhelming any other part of the process.</p>
<ul>
<li><p><strong>✅ Performance Optimization:</strong> This is the most critical optimization. We must leverage the <strong>SageMaker Feature Store’s Offline Store</strong>. The inference script should be designed to execute a single, efficient Athena SQL query that joins the input customer list with the feature data in the offline store. This transforms the feature retrieval from millions of slow, individual lookups into a single, fast, parallelized data join operation, likely reducing feature retrieval time to just a few minutes.</p></li>
</ul>
</li>
<li><p><strong>Bottleneck:</strong> <strong>Compute Instance Sizing.</strong> The runtime of the Batch Transform job is directly proportional to the compute power allocated.</p>
<ul>
<li><p><strong>✅ Performance Optimization:</strong> We can horizontally scale by increasing the <code class="docutils literal notranslate"><span class="pre">InstanceCount</span></code> in the Batch Transform job configuration. SageMaker will automatically partition the input data across the instances, running them in parallel. We can also vertically scale by choosing a more powerful <code class="docutils literal notranslate"><span class="pre">InstanceType</span></code> (e.g., from <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> to <code class="docutils literal notranslate"><span class="pre">ml.m5.4xlarge</span></code>).</p></li>
</ul>
</li>
<li><p><strong>Bottleneck:</strong> <strong>Model Complexity.</strong> A very large XGBoost model (many trees, deep trees) will take longer to load and will have higher per-prediction latency.</p>
<ul>
<li><p><strong>✅ Performance Optimization:</strong> Use model quantization or compile the model using SageMaker Neo. This can reduce the model’s on-disk size and improve inference speed, though it requires an extra step in the training pipeline.</p></li>
</ul>
</li>
</ol>
</li>
</ul>
</section>
<section id="estimated-monthly-cost">
<h4>Estimated Monthly Cost<a class="headerlink" href="#estimated-monthly-cost" title="Permalink to this heading">¶</a></h4>
<p><strong>Assumptions:</strong></p>
<ul class="simple">
<li><p>Region: <code class="docutils literal notranslate"><span class="pre">eu-west-1</span></code> (Ireland)</p></li>
<li><p>Active Customers: 1 million</p></li>
<li><p>Daily Transactions: ~150,000 records (~1GB/month)</p></li>
<li><p>Daily Behavioral Events: ~250k sessions, generating ~5GB/day (~150GB/month)</p></li>
<li><p>Feature Engineering: Runs daily on 1 month of data (~150GB).</p></li>
<li><p>Model Training: Runs weekly.</p></li>
<li><p>Batch Inference: Runs weekly on 1 million customers.</p></li>
</ul>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Component</p></th>
<th class="head text-left"><p>Assumptions / Usage</p></th>
<th class="head text-left"><p>Instance / Pricing Unit</p></th>
<th class="head text-left"><p>Estimated Monthly Cost ($)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>S3 Storage</strong></p></td>
<td class="text-left"><p>Raw Data (~150GB) + Features (~50GB) + Models/Artifacts (~10GB) = ~210 GB</p></td>
<td class="text-left"><p>$0.023 per GB-month</p></td>
<td class="text-left"><p>~$5</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>AWS Glue</strong></p></td>
<td class="text-left"><p>Daily job, ~15 mins on 2 DPUs. (0.25h * 2 DPUs * 30 days * $0.44/DPU-hr)</p></td>
<td class="text-left"><p>DPU-Hours</p></td>
<td class="text-left"><p>~$7</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Kinesis Data Streams</strong></p></td>
<td class="text-left"><p>1 shard, continuously running. (1 shard * 24h * 30d * $0.015/hr)</p></td>
<td class="text-left"><p>Shard-Hours</p></td>
<td class="text-left"><p>~$11</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Kinesis Data Firehose</strong></p></td>
<td class="text-left"><p>Ingests 150 GB/month. ($0.029/GB)</p></td>
<td class="text-left"><p>GB Ingested</p></td>
<td class="text-left"><p>~$5</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>EMR (Feature Engineering)</strong></p></td>
<td class="text-left"><p>Daily transient cluster. 1 master + 4 core <code class="docutils literal notranslate"><span class="pre">m5.xlarge</span></code> instances for 1 hour. (5 instances * 1h * 30d * $0.192/hr)</p></td>
<td class="text-left"><p>Instance-Hours</p></td>
<td class="text-left"><p>~$29</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>SageMaker Feature Store</strong></p></td>
<td class="text-left"><p><em>Offline:</em> 50GB storage. <br> <em>Online:</em> Low write/read units for batch. (50 * $0.023) + (2 RCU * 730h * $0.057) + (2 WCU * 730h * $0.285)</p></td>
<td class="text-left"><p>Storage + RCU/WCU-Hours</p></td>
<td class="text-left"><p>~$500</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>SageMaker Training</strong></p></td>
<td class="text-left"><p>Weekly job on one <code class="docutils literal notranslate"><span class="pre">ml.m5.4xlarge</span></code> for 2 hours. (1 instance * 2h * 4 weeks * $0.922/hr)</p></td>
<td class="text-left"><p>Instance-Hours</p></td>
<td class="text-left"><p>~$8</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>SageMaker Batch Inference</strong></p></td>
<td class="text-left"><p>Weekly job on two <code class="docutils literal notranslate"><span class="pre">ml.m5.4xlarge</span></code> for 2 hours. (2 instances * 2h * 4 weeks * $0.922/hr)</p></td>
<td class="text-left"><p>Instance-Hours</p></td>
<td class="text-left"><p>~$15</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>MWAA (Airflow)</strong></p></td>
<td class="text-left"><p>Smallest environment (<code class="docutils literal notranslate"><span class="pre">mw1.small</span></code>), continuously running. ($0.49/hr * 24h * 30d)</p></td>
<td class="text-left"><p>Environment-Hours</p></td>
<td class="text-left"><p>~$353</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>CloudWatch</strong></p></td>
<td class="text-left"><p>Logs (~10 GB/month) + Custom Metrics + Alarms</p></td>
<td class="text-left"><p>GB Ingested &amp; Metrics</p></td>
<td class="text-left"><p>~$10</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Total Estimated Monthly Cost</strong></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p><strong>~$943</strong></p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Conclusion on Cost:</strong> The primary cost drivers are the continuously running managed services: <strong>SageMaker Feature Store (Online Store)</strong> and <strong>Airflow (MWAA)</strong>. The batch compute jobs (EMR, SageMaker) are significant but less than the persistent services. This cost structure is very reasonable for providing a production-grade ML capability for a mid-sized business.</p>
</section>
<section id="throughput-estimates-performance-optimizations">
<h4>Throughput Estimates &amp; Performance Optimizations<a class="headerlink" href="#throughput-estimates-performance-optimizations" title="Permalink to this heading">¶</a></h4>
</section>
<section id="a-throughput-estimates">
<h4><strong>a) Throughput Estimates</strong><a class="headerlink" href="#a-throughput-estimates" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Feature Engineering (EMR):</strong> With a 5-node <code class="docutils literal notranslate"><span class="pre">m5.xlarge</span></code> cluster, processing the full monthly dataset of ~150GB to generate features for ~1M customers would likely take <strong>~1-2 hours</strong>. This equates to a throughput of <strong>~500,000 to 1,000,000 customers per hour</strong>.</p></li>
<li><p><strong>Batch Inference (SageMaker):</strong> With two <code class="docutils literal notranslate"><span class="pre">ml.m5.4xlarge</span></code> instances, scoring 1M customers (with the optimized feature retrieval) would likely take <strong>~1 hour</strong>. This equates to a throughput of <strong>~1,000,000 customers per hour</strong>, or ~280 predictions per second.</p></li>
</ul>
</section>
<section id="further-performance-optimizations">
<h4>Further Performance Optimizations<a class="headerlink" href="#further-performance-optimizations" title="Permalink to this heading">¶</a></h4>
<p>While we’ve discussed key optimizations, here’s a consolidated list:</p>
<ol class="arabic simple">
<li><p><strong>Optimize Feature Engineering:</strong></p>
<ul class="simple">
<li><p><strong>Right-size the EMR Cluster:</strong> Profile the Spark jobs to find the optimal number and type of instances. Too small a cluster is slow; too large a cluster wastes money.</p></li>
<li><p><strong>Optimize Spark Code:</strong> Use techniques like data partitioning, caching intermediate DataFrames, and avoiding expensive operations like <code class="docutils literal notranslate"><span class="pre">collect()</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Optimize Batch Inference:</strong></p>
<ul class="simple">
<li><p><strong>Use the Offline Feature Store:</strong> As detailed above, this is the most critical optimization.</p></li>
<li><p><strong>Increase Parallelism:</strong> Increase the <code class="docutils literal notranslate"><span class="pre">MaxConcurrentTransforms</span></code> and <code class="docutils literal notranslate"><span class="pre">InstanceCount</span></code> in the Batch Transform job configuration to process the data faster.</p></li>
<li><p><strong>Batching Strategy:</strong> For the inference script, ensure that it processes records in mini-batches to take advantage of vectorized prediction in libraries like XGBoost, rather than predicting one record at a time.</p></li>
</ul>
</li>
<li><p><strong>General Optimizations:</strong></p>
<ul class="simple">
<li><p><strong>Use AWS Savings Plans or Reserved Instances:</strong> For the continuously running components like MWAA and the Feature Store, committing to a 1 or 3-year term can reduce costs by up to 40-60%.</p></li>
<li><p><strong>Automate Shutdowns:</strong> Ensure all development and staging environments (e.g., test Airflow instances) are automatically shut down when not in use.</p></li>
</ul>
</li>
</ol>
</section>
<section id="rationale-behind-design-choices">
<h4>Rationale behind Design Choices<a class="headerlink" href="#rationale-behind-design-choices" title="Permalink to this heading">¶</a></h4>
<p><strong>Why is the Airflow (MWAA) running continuously?</strong></p>
<ul class="simple">
<li><p><strong>Its Function is Continuous Orchestration:</strong> Think of Airflow as the “control tower” or the “central nervous system” for all of our data and ML pipelines. It’s a server, not a job. Its primary responsibilities are continuous and time-sensitive:</p>
<ol class="arabic simple">
<li><p><strong>Scheduling:</strong> It needs to be “awake” 24/7 to check its schedules. When a DAG is defined with <code class="docutils literal notranslate"><span class="pre">schedule_interval=&quot;&#64;daily&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;&#64;weekly&quot;</span></code>, Airflow’s internal scheduler component is constantly checking the clock to see if it’s time to trigger a new run.</p></li>
<li><p><strong>State Management:</strong> It maintains the status of all past and current pipeline runs. If a job fails, Airflow holds that state and knows not to run downstream tasks. This historical state is crucial for debugging and operational reliability.</p></li>
<li><p><strong>API and UI:</strong> It serves a user interface and an API, allowing developers to inspect logs, trigger manual runs, and see the status of all pipelines at any time.</p></li>
<li><p><strong>Listening for Triggers:</strong> As we designed in the Continual Learning section, our retraining pipeline can be triggered by an external API call from our monitoring system. Airflow must be running continuously to listen for and respond to these event-driven triggers.</p></li>
</ol>
</li>
<li><p><strong>Conclusion:</strong> Because its core function is to schedule, monitor, and respond in real-time, MWAA is a persistent service by design. It cannot be spun up on-demand just to run a single pipeline, as that would defeat its purpose as an orchestrator.</p></li>
</ul>
<p><strong>Why is the Feature Store (Online) running continuously?</strong></p>
<ul class="simple">
<li><p><strong>Its Function is Low-Latency Access:</strong> The <em>Online</em> Feature Store is specifically designed and optimized for real-time, low-millisecond data retrieval. It’s essentially a managed, high-performance key-value database. This low-latency guarantee is only possible because the service is persistent, with data indexed and ready in memory. If you had to “spin it up” each time you needed it, the lookup time would be minutes, not milliseconds, and it would just be a slow, expensive version of the Offline Store.</p></li>
<li><p><strong>Architectural Refinement for Our Use Case:</strong></p>
<ul>
<li><p><strong>Initial Design:</strong> The Online Store was included as a best practice for <strong>future-proofing</strong>. A common next step for a CLV project is to expose the scores via a real-time API for an application to use (e.g., showing a special offer to a high-value customer <em>while they are browsing</em>). That real-time API would absolutely require the Online Feature Store. By building it into the initial architecture, the system is ready for that evolution.</p></li>
<li><p><strong>A More Cost-Effective, Batch-Only Approach:</strong> If we are 100% certain that we will <em>not</em> have a real-time requirement in the near future, we could optimize for cost. We can configure the SageMaker Feature Group to have <strong>only the Offline Store enabled</strong>. This means data is still cataloged and organized, but it is written only to S3.</p></li>
<li><p><strong>Impact on the Pipeline:</strong> In this optimized scenario, our Batch Inference script would be modified to query the <strong>Offline Store</strong> (using an Athena query via the SDK) instead of the Online Store. The cost would drop dramatically (from ~$500/month to just a few dollars for S3 storage and Athena query costs), as we would no longer be paying for the continuously running read/write capacity units of the Online Store.</p></li>
</ul>
</li>
<li><p><strong>Conclusion:</strong> The initial estimate included the Online Store for strategic, forward-looking reasons. However, for the specific batch-only pipeline we’ve built, disabling it is a valid and significant cost optimization. The final decision is a classic MLOps trade-off: <strong>current cost savings vs. future agility.</strong></p></li>
</ul>
<p><strong>Why is feature engineering run daily instead of just before weekly training?</strong></p>
<p><strong>a) The Need for Fresh Features</strong></p>
<p>The predictive power of our CLV model relies heavily on features that change daily. If we only update them weekly, we lose a significant amount of signal.</p>
<ul class="simple">
<li><p><strong>Recency is Critical:</strong> The <code class="docutils literal notranslate"><span class="pre">recency</span></code> feature (days since last purchase) is one of the strongest predictors of churn and repeat purchases. This value changes <em>every single day</em> for every customer who doesn’t make a purchase. If we only calculate this weekly, a customer who bought yesterday and a customer who bought 6 days ago look identical to the model, but their short-term behavior is vastly different.</p></li>
<li><p><strong>Rolling Windows Capture Trends:</strong> Features like <code class="docutils literal notranslate"><span class="pre">total_spend_30d</span></code> or <code class="docutils literal notranslate"><span class="pre">purchase_count_90d</span></code> are designed to capture recent momentum. A daily update ensures this window accurately reflects the last 30/90 days. A weekly update means that for most of the week, the window is stale and includes data that should have already “aged out.”</p></li>
</ul>
<p>By calculating features daily, we ensure that when the weekly training job runs, it uses the most accurate, up-to-date representation of each customer’s behavior.</p>
<p><strong>b) Architectural Decoupling: The Feature Store as a Central Asset</strong></p>
<p>This is the key MLOps principle at play. Tightly coupling the feature engineering pipeline to the training pipeline (i.e., only running it when you need to train) creates a brittle, monolithic system. By decoupling them, we create a more robust and scalable architecture.</p>
<ul class="simple">
<li><p><strong>The Feature Store as a “Source of Truth”:</strong> The purpose of the daily feature engineering pipeline is to produce a clean, validated, and up-to-date table of customer features in the Feature Store. This table becomes a central data asset for the entire organization, not just for one model.</p></li>
<li><p><strong>Enabling Other Use Cases:</strong> Once this daily-refreshed feature set exists, it can be consumed by numerous other services without needing to re-run the complex engineering logic:</p>
<ul>
<li><p><strong>Other ML Models:</strong> A different team might want to build a real-time churn prediction model. They don’t need to build their own feature pipeline; they can simply consume the fresh features we are already producing.</p></li>
<li><p><strong>Business Intelligence (BI):</strong> The marketing team might want a daily dashboard showing the number of customers in different RFM segments. They can query the Feature Store directly instead of asking data engineering for a custom pipeline.</p></li>
<li><p><strong>Ad-Hoc Analysis:</strong> A data scientist wanting to explore customer behavior can immediately query the Feature Store for clean, ready-to-use data.</p></li>
</ul>
</li>
</ul>
<p>By running feature engineering daily, we are not just preparing data for <em>our</em> model; we are creating a reliable, daily-refreshed data product that serves the entire business. This is a core tenet of building a scalable and efficient data culture.</p>
<!--
### **Challenges Faced, Lessons Learned & The Path Forward**

Building and operationalizing our end-to-end Customer Lifetime Value (CLV) prediction system was a journey of immense learning. While we successfully delivered a system that drives significant business value, the path was punctuated by complex challenges that went far beyond simple model training. Here are three specific, high-impact challenges we faced and the invaluable lessons they taught us.


#### **Challenge 1: The Silent Data Pipeline Bug and the "Gift Card" Anomaly**

This was a classic, insidious data issue that morphed into a modeling challenge, highlighting the fragility of even well-designed pipelines and the critical need for deep, cross-functional observability.

*   **The Initial Symptom & Stakeholder Pressure:** About two months after a successful launch, the Marketing team raised a "red flag." They noticed that our model's CLV scores for a historically stable, high-value customer segment were inexplicably dropping week over week. With their crucial quarterly campaign planning approaching, their confidence in the model was eroding, putting significant pressure on the ML team to diagnose and fix the issue immediately.

*   **Chronological Investigation:**
    1.  **MLOps Initial Triage (Day 1-2):** Our first step was to check the monitoring dashboards. There were no smoking guns. Airflow DAGs were all green. The SageMaker Batch Transform jobs were completing successfully. Our prediction drift monitor showed a slightly elevated Population Stability Index (PSI) of 0.12, but it was below our medium-alert threshold of 0.15. The system, on the surface, looked healthy.
    2.  **Data Science Deep Dive (Day 3-5):** The data science team took over, performing a slice analysis on the affected customer segment. They confirmed Marketing's observation: the `monetary` and `frequency` features for these customers were indeed trending downwards. They pulled the raw transaction logs for a few specific `CustomerID`s and saw recent purchase activity. The data existed at the source, but it was vanishing somewhere before model training.
    3.  **The Cross-Functional Hunt (Week 2):** This triggered a deep-dive involving Data Engineering, MLOps, and Data Science. The data engineers began meticulously tracing data lineage from the source PostgreSQL database through the AWS Glue ETL job, to the raw S3 data lake, and finally to the Feature Engineering pipeline running on EMR.
    4.  **The "Aha!" Moment:** The root cause was discovered in the logs of the Glue job. A month prior, the e-commerce backend team had launched a new "Gift Card" product line. Crucially, the `product_id` for these gift card transactions was an alphanumeric string (e.g., `GC-WINTER-50`), whereas all previous `product_id`s were integers. Our feature engineering pipeline had a validation step that expected an integer type. Instead of failing loudly, the Spark job was silently casting the incompatible alphanumeric IDs to `NULL`. Subsequent steps in the pipeline were configured to drop records with null keys, effectively making these gift card purchases invisible to the CLV model.
    5.  **The Fix and the Second-Order Problem (Week 3):** The data engineering team quickly patched the feature engineering script to correctly handle alphanumeric `product_id`s and reprocessed the last month of data. The data quality issue was fixed. We retrained the model on this corrected, complete dataset. The overall offline RMSE improved, and we celebrated. However, the first batch inference run with the new model produced a new, even more alarming issue: customers who had *only* purchased a single, high-value gift card were now being assigned massive CLV scores, placing them in the top percentile. The model had incorrectly learned that a one-off, high-value purchase was a signal of an extremely valuable customer, failing to understand the non-recurring nature of many gift card purchases.
    6.  **The Final, Correct Solution (Week 4):** We realized this was now a modeling problem, not just a data problem. We went back to the feature engineering pipeline and created a new binary feature: `is_gift_card_purchase`. This allowed the XGBoost model to explicitly learn the difference between regular product purchases and gift card transactions. After retraining with this new feature, the model's predictions became far more robust, and the scores for the affected segment returned to sensible levels.

*   **Lessons Learned:**
    *   **Silent Failures are the Most Dangerous:** Loud pipeline failures are easy; silent data corruption is what erodes trust. Our initial data validation was too trusting and lacked strict type enforcement that would have failed the pipeline immediately.
    *   **Observability is More Than Dashboards:** True observability is the ability to trace data lineage from end to end. Without the collaborative effort to track data flow across services, we would have been flying blind.
    *   **A Data Bug is Often a Hidden Model Bug:** The data issue revealed a flaw in our model's conceptual understanding of the world. It didn't know how to handle a new type of transaction. The ultimate fix required improving the model's feature set, not just cleaning the data.


#### **Challenge 2: The Proxy Metric Paradox: Optimizing for the Wrong Thing**

This challenge was a humbling experience that went to the heart of our project's validity. It taught us that a statistically "good" model can be a functionally "bad" model if it's optimizing for a flawed proxy of business value.

*   **The Initial Setup and a Confusing A/B Test:** Our CLV model's ground truth—actual 12-month spend—is severely latent. To iterate quickly, we made a pragmatic decision: our primary offline evaluation metric and automated retraining trigger would be based on the model's ability to predict a shorter-term proxy: **90-day revenue**. For several months, this worked well. Our training pipeline dutifully retrained the model weekly, and the 90-day RMSE remained low and stable. We then launched a formal A/B test for a new challenger model (v1.3) that showed a 5% better 90-day RMSE offline. We were confident it would be a winner. The result was a shock: the challenger model produced a **statistically significant *decrease*** in actual revenue per user during the 30-day experiment. The business stakeholders were, justifiably, confused and concerned about the project's ROI.

*   **Chronological Investigation:**
    1.  **Validate the Experiment (Week 1):** The first assumption was that the A/B test itself was flawed. We rigorously checked the setup: Was there Sample Ratio Mismatch (SRM)? Was the user assignment truly random? Was the logging correct? The platform team confirmed the test was executed flawlessly. The negative result was real.
    2.  **Model Autopsy (Week 2):** We performed a deep dive into the challenger model's behavior. Using SHAP, we analyzed the feature contributions for customers where the challenger's prediction differed most from the champion's. A clear pattern emerged: the challenger model had learned to assign extremely high CLV scores to customers who made a single, large, "binge" purchase of discounted, end-of-season items. These customers looked fantastic in a 90-day revenue window but had virtually zero repeat purchases, making their true lifetime value very low.
    3.  **The "Aha!" Moment - The Proxy Was Drifting:** We realized the problem wasn't the model; it was our objective function. In our quest for short-term predictive accuracy, we had built a model that perfectly optimized for a flawed proxy. The relationship between "high 90-day spend" and "high 12-month value" had decayed. The model was doing exactly what we asked it to do, but we were asking the wrong question.
    4.  **Reframing the ML Problem (Week 3-4):** This led to a critical, cross-functional meeting with product, marketing, and data science. We decided to move beyond a simple regression problem. The business didn't just care about *how much* a customer would spend, but also *how likely they were to return*.
    5.  **The Solution - A Multi-Headed Model:** We re-architected our model into a "two-headed" system. The input features and core XGBoost body remained, but it now had two separate output layers (heads):
        *   **Head 1 (Regression):** Predicts the expected 12-month revenue.
        *   **Head 2 (Classification):** Predicts the probability of churn (no purchases in the next 6 months).
    6.  The final "CLV Score" was no longer just the revenue prediction but a combined score, heavily penalizing customers with a high churn probability. This required a significant refactoring of our training and evaluation pipelines.

*   **Lessons Learned:**
    *   **Proxy Metrics are a Necessary Evil, but a Dangerous One:** They must be continuously validated against the true north-star business KPI. Their correlation is not static.
    *   **Offline Metrics are Not Ground Truth:** The ultimate arbiter of a model's value is its impact in a live, online experiment. Never blindly trust offline results, no matter how good they look.
    *   **Be Prepared to Redefine Success:** The most valuable lesson was being humble enough to admit our entire problem framing was wrong and being agile enough to pivot. MLOps isn't just about iterating on models; it's about iterating on the *problem definition itself* based on production feedback.


#### **Challenge 3: The Self-Fulfilling Prophecy: When an "Improving" Model Hides a Stagnating Business**

This was the most subtle and complex challenge we faced. It was a classic case of a degenerate feedback loop, where the model's success was creating an echo chamber that masked a critical business problem.

*   **The "Success" Story:** For over six months, our CLV system was seen as a resounding success. The model was retrained weekly, and with each retraining, its offline accuracy (RMSE) and ranking ability (Gini coefficient) on newly held-out data were consistently improving. The prediction drift was low. From a technical standpoint, the model was performing beautifully.
*   **The Alarming Disconnect:** The business analytics team presented a report that sent a chill through the project team. While our model was reporting ever-improving performance, the company's overall 6-month customer retention rate had been completely flat. Even more concerning, the growth in revenue from our "high-value" segments was slowing down. Our model's "success" was completely disconnected from the business's reality.

*   **Chronological Investigation:**
    1.  **Initial Confusion (Week 1):** The data science team was stumped. Their offline metrics, calculated correctly on temporally held-out data, showed clear improvement. They re-ran evaluations and confirmed the numbers. The model *was* getting better at predicting the outcomes in the data it was seeing.
    2.  **The Feedback Loop Hypothesis (Week 2):** During a tense brainstorming session, the MLOps lead proposed the feedback loop theory. The marketing team had confirmed they were *exclusively* using our model's scores to target the top 20% of predicted high-CLV customers with their retention campaigns (e.g., special offers, early access).
    3.  **The Realization:** We had created a perfectly sealed loop. The model identified "good" customers. Marketing showered them with attention and offers. These customers, unsurprisingly, continued to purchase, generating the very data that, in the next training cycle, confirmed to the model that they were indeed "good" customers. The model never received new data about the 80% of customers it ignored. It was simply learning its own biases, and its "improving accuracy" was an illusion created by a data-generating process it was directly controlling.
    4.  **The Difficult Conversation and the "Exploration" Experiment (Week 3):** We had to convince the Marketing team to let us run an experiment that felt, to them, counter-intuitive and inefficient. We proposed a formal A/B test not on a new model, but on a new *targeting strategy*.
        *   **Control Group (90% of campaign budget):** Continue targeting the top 20% of customers as predicted by the current model.
        *   **Treatment / "Exploration" Group (10% of budget):** Target a *completely random sample* of customers from across the *entire* CLV spectrum, including those the model predicted were low-value.
    5.  **Running the Test (Month 2):** This required significant stakeholder management. The marketing team was concerned about "wasting" their budget on "bad" customers, which could hurt their quarterly KPIs. We had to make the case that this short-term "cost" was a crucial investment in the long-term health and learning capability of our entire personalization engine.
    6.  **The Breakthrough (Month 3):** The experiment concluded. As expected, the immediate ROI from the Exploration group was lower. But the data we collected was invaluable. We used the labeled data from this unbiased 10% sample to retrain the CLV model. The newly trained model was, on paper, slightly less accurate on the old, biased data. But it had "rediscovered" patterns of value in the segments it had previously ignored. The very next A/B test comparing this new model to the old one showed a significant lift in identifying and converting "at-risk, high-potential" customers.

*   **Lessons Learned:**
    *   **Actively Fight Feedback Loops:** If your model's outputs influence user treatment, you *must* assume a feedback loop exists. The only way to break it is with intentional, randomized exploration.
    *   **Business Process is Part of the ML System:** The solution wasn't a new algorithm; it was changing the business process (marketing targeting). A holistic MLOps view must encompass how the model is consumed by downstream teams.
    *   **Invest in "Strategic Inefficiency":** A budget for random exploration might seem inefficient, but it's the cost of buying unbiased data to prevent your entire system from becoming stale and biased. This "inefficiency" is one of the most strategic investments you can make.
-->
</section>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="ecom_propensity.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Real-Time Purchase Intent Scoring</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="adas_engine/ch13_reliability_capacity_maps.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Reliability, Capacity, Maps</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Deepak Karkala
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Customer Lifetime Value</a><ul>
<li><a class="reference internal" href="#how-i-built-a-customer-lifetime-value-model-for-an-e-commerce-business">How I Built a Customer Lifetime Value Model for an E-commerce Business</a><ul>
<li><a class="reference internal" href="#tldr-building-a-production-grade-clv-prediction-system"><strong>TLDR: Building a Production-Grade CLV Prediction System</strong></a><ul>
<li><a class="reference internal" href="#challenge"><strong>Challenge</strong></a></li>
<li><a class="reference internal" href="#my-role-solution"><strong>My Role &amp; Solution</strong></a></li>
<li><a class="reference internal" href="#impact"><strong>Impact</strong></a></li>
<li><a class="reference internal" href="#system-architecture"><strong>System Architecture</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-business-challenge-moving-from-hindsight-to-foresight">The Business Challenge: Moving from Hindsight to Foresight</a></li>
<li><a class="reference internal" href="#problem-framing-translating-business-needs-into-a-technical-blueprint">Problem Framing: Translating Business Needs into a Technical Blueprint</a><ul>
<li><a class="reference internal" href="#is-machine-learning-the-right-approach">Is Machine Learning the Right Approach?</a></li>
<li><a class="reference internal" href="#defining-the-core-ml-task-from-business-goals-to-a-predictive-model">Defining the Core ML Task: From Business Goals to a Predictive Model</a></li>
<li><a class="reference internal" href="#assessing-feasibility-risks-can-we-execute-this-vision">Assessing Feasibility &amp; Risks (Can We Execute This Vision?)</a></li>
<li><a class="reference internal" href="#defining-success-from-technical-metrics-to-business-impact">Defining Success: From Technical Metrics to Business Impact</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlops-end-to-end-project-planning-and-operational-strategy">MLOps End-to-End Project Planning and Operational Strategy</a><ul>
<li><a class="reference internal" href="#tech-stack">Tech Stack</a></li>
<li><a class="reference internal" href="#list-of-core-pipelines-workflows">List of Core Pipelines/Workflows</a></li>
<li><a class="reference internal" href="#project-management-and-stages">Project Management and Stages</a></li>
<li><a class="reference internal" href="#cross-functional-team-roles">Cross-Functional Team &amp; Roles</a></li>
<li><a class="reference internal" href="#versioning-and-governance-strategy">Versioning and Governance Strategy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-sourcing-and-discovery">Data Sourcing and Discovery</a></li>
<li><a class="reference internal" href="#data-engineering-and-pipelines-building-the-foundation-for-accurate-predictions">Data Engineering and Pipelines: Building the Foundation for Accurate Predictions</a><ul>
<li><a class="reference internal" href="#planning-the-data-ingestion-pipeline">Planning the Data Ingestion Pipeline</a></li>
<li><a class="reference internal" href="#tool-compute-choice-spark-emr-vs-other-frameworks">Tool &amp; Compute Choice: Spark/EMR vs. Other Frameworks</a></li>
<li><a class="reference internal" href="#data-ingestion-pipeline-implementation">Data Ingestion Pipeline: Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#feature-engineering-pipeline">Feature Engineering Pipeline</a><ul>
<li><a class="reference internal" href="#planning">Planning</a></li>
<li><a class="reference internal" href="#implementation">Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-development-iteration">Model Development &amp; Iteration</a><ul>
<li><a class="reference internal" href="#i-foundations-for-success"><strong>I. Foundations for Success</strong></a></li>
<li><a class="reference internal" href="#ii-the-core-iterative-loop"><strong>II. The Core Iterative Loop</strong></a></li>
<li><a class="reference internal" href="#iii-advanced-optimization"><strong>III. Advanced Optimization</strong></a></li>
<li><a class="reference internal" href="#iv-validation-and-governance"><strong>IV. Validation and Governance</strong></a></li>
<li><a class="reference internal" href="#applying-the-framework-to-the-clv-project"><strong>Applying the Framework to the CLV Project</strong></a></li>
<li><a class="reference internal" href="#a-step-by-step-experimental-journey"><strong>A Step-by-Step Experimental Journey</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ml-training-pipelines"><strong>ML Training pipelines</strong></a><ul>
<li><a class="reference internal" href="#plan"><strong>Plan</strong></a></li>
<li><a class="reference internal" href="#id1">Implementation</a></li>
<li><a class="reference internal" href="#ml-training-pipeline-ci-workflow"><strong>ML Training Pipeline CI Workflow</strong></a></li>
<li><a class="reference internal" href="#ml-training-pipeline-cd-workflow-plan"><strong>ML Training Pipeline CD Workflow Plan</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#inference-pipeline"><strong>Inference Pipeline</strong></a><ul>
<li><a class="reference internal" href="#high-level-strategy-choosing-the-deployment-pattern"><strong>1. High-Level Strategy: Choosing the Deployment Pattern</strong></a></li>
<li><a class="reference internal" href="#architectural-plan-components-and-tooling"><strong>2. Architectural Plan: Components and Tooling</strong></a></li>
<li><a class="reference internal" href="#core-pipeline-artifacts-to-be-implemented"><strong>3. Core Pipeline Artifacts to Be Implemented</strong></a></li>
<li><a class="reference internal" href="#testing-the-inference-pipeline-in-a-staging-environment"><strong>4. Testing the Inference Pipeline in a Staging Environment</strong></a></li>
<li><a class="reference internal" href="#ci-cd-for-the-inference-pipeline"><strong>5. CI/CD for the Inference Pipeline</strong></a></li>
<li><a class="reference internal" href="#id2">Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#monitoring-observability"><strong>Monitoring &amp; Observability</strong></a><ul>
<li><a class="reference internal" href="#guiding-philosophy-and-approach"><strong>1. Guiding Philosophy and Approach</strong></a></li>
<li><a class="reference internal" href="#tech-stack-for-monitoring-observability"><strong>2. Tech Stack for Monitoring &amp; Observability</strong></a></li>
<li><a class="reference internal" href="#detailed-monitoring-plan"><strong>3. Detailed Monitoring Plan</strong></a><ul>
<li><a class="reference internal" href="#a-data-quality-monitoring-the-foundation"><strong>a) Data Quality Monitoring (The Foundation)</strong></a></li>
<li><a class="reference internal" href="#b-data-prediction-drift-monitoring-proxy-for-performance"><strong>b) Data &amp; Prediction Drift Monitoring (Proxy for Performance)</strong></a></li>
<li><a class="reference internal" href="#c-model-performance-monitoring"><strong>c) Model Performance Monitoring</strong></a></li>
<li><a class="reference internal" href="#d-system-health-monitoring-operational"><strong>d) System Health Monitoring (Operational)</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#observability-debugging-plan"><strong>4. Observability &amp; Debugging Plan</strong></a></li>
<li><a class="reference internal" href="#alerting-strategy"><strong>5. Alerting Strategy</strong></a></li>
<li><a class="reference internal" href="#dashboard-design"><strong>6. Dashboard Design</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#continual-learning-production-testing-plan"><strong>Continual Learning &amp; Production Testing Plan</strong></a><ul>
<li><a class="reference internal" href="#guiding-philosophy-from-static-predictions-to-a-dynamic-learning-system"><strong>1. Guiding Philosophy: From Static Predictions to a Dynamic, Learning System</strong></a></li>
<li><a class="reference internal" href="#continual-learning-model-retraining-strategy"><strong>2. Continual Learning &amp; Model Retraining Strategy</strong></a></li>
<li><a class="reference internal" href="#production-testing-rollout-strategy-a-phased-approach"><strong>3. Production Testing &amp; Rollout Strategy: A Phased Approach</strong></a></li>
<li><a class="reference internal" href="#a-b-testing-framework-for-major-model-changes"><strong>4. A/B Testing Framework for Major Model Changes</strong></a></li>
<li><a class="reference internal" href="#automating-the-continual-learning-testing-cycle"><strong>5. Automating the Continual Learning &amp; Testing Cycle</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-b-testing">A/B Testing</a></li>
<li><a class="reference internal" href="#governance-ethics-the-human-element"><strong>Governance, Ethics &amp; The Human Element</strong></a><ul>
<li><a class="reference internal" href="#guiding-philosophy-building-a-trustworthy-and-compliant-system"><strong>1. Guiding Philosophy: Building a Trustworthy and Compliant System</strong></a></li>
<li><a class="reference internal" href="#comprehensive-model-governance-plan"><strong>2. Comprehensive Model Governance Plan</strong></a></li>
<li><a class="reference internal" href="#responsible-ai-rai-practices"><strong>3. Responsible AI (RAI) Practices</strong></a></li>
<li><a class="reference internal" href="#holistic-system-testing-production-readiness"><strong>4. Holistic System Testing &amp; Production Readiness</strong></a></li>
<li><a class="reference internal" href="#human-element-team-structure-user-centric-design"><strong>5. Human Element: Team Structure &amp; User-Centric Design</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#system-architecture-cost-performance-optimisations">System Architecture, Cost, Performance Optimisations</a><ul>
<li><a class="reference internal" href="#overall-system-architecture-diagram">Overall System Architecture Diagram</a></li>
<li><a class="reference internal" href="#sequence-diagram-batch-inference">Sequence Diagram: Batch Inference</a></li>
<li><a class="reference internal" href="#latency-potential-bottlenecks-and-optimizations">Latency, Potential Bottlenecks, and Optimizations</a></li>
<li><a class="reference internal" href="#estimated-monthly-cost">Estimated Monthly Cost</a></li>
<li><a class="reference internal" href="#throughput-estimates-performance-optimizations">Throughput Estimates &amp; Performance Optimizations</a></li>
<li><a class="reference internal" href="#a-throughput-estimates"><strong>a) Throughput Estimates</strong></a></li>
<li><a class="reference internal" href="#further-performance-optimizations">Further Performance Optimizations</a></li>
<li><a class="reference internal" href="#rationale-behind-design-choices">Rationale behind Design Choices</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=4e2eecee"></script>
    </body>
</html>